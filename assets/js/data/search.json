[ { "title": "Ktlint 도입하기", "url": "/posts/Ktlint_%EB%8F%84%EC%9E%85%ED%95%98%EA%B8%B0/", "categories": "Study, Kotlin", "tags": "develop, kotlin, lint", "date": "2025-10-24 00:00:00 +0900", "snippet": "Ktlint란?: Kotlin의 코드 스타일 검사 및 포맷팅 도구. 팀 내에서 일관된 코드 스타일을 유지하기 위해 사용된다. 공식 Kotlin 코딩 컨벤션을 기반으로 동작 Gradle 플러그인으로 쉽게 통합 가능 .editorconfig를 통해 프로젝트별 규칙 커스터마이징 가능왜 도입했는가? 일관된 코드 스타일: 팀원들마다 다른 코드 스타일을 통일 가독성 향상 및 코드 리뷰 시 스타일에 대한 논쟁을 줄일 수 있다 자동화된 포맷팅: 수동으로 스타일을 맞출 필요 없이 명령어 하나로 자동 포맷팅설정 방법1. build.gradle 설정Gradle 프로젝트에 ktlint 플러그인을 추가한다.plugins { id(&quot;org.jlleitschuh.gradle.ktlint&quot;) version &quot;11.0.0&quot;}ktlint { version.set(&quot;0.50.0&quot;) debug.set(false) verbose.set(true) android.set(false) outputToConsole.set(true) ignoreFailures.set(false)}2. .editorconfig 설정프로젝트 루트에 .editorconfig 파일을 생성하여 코드 스타일 규칙을 정의한다. (팀 내 컨벤션에 따라 커스터마이징)[*.{kt,kts}]# 들여쓰기 스타일indent_style = spaceindent_size = 4# 최대 라인 길이max_line_length = 120# import 구문 정렬ij_kotlin_imports_layout = *,java.**,javax.**,kotlin.**,^# 기타 규칙들ij_kotlin_allow_trailing_comma = trueij_kotlin_allow_trailing_comma_on_call_site = true++) Git Pre-commit Hook 설정.git/hooks/pre-commit 파일을 생성하여 커밋 전 자동으로 lint 검사를 실행하도록 설정한다. (프로젝트 모든 인원이 이 설정을 하도록 의미가 있음)#!/bin/sh######## KTLINT-GRADLE HOOK START ########CHANGED_FILES=&quot;$(git --no-pager diff --name-status --no-color --cached | awk &#39;$1 != &quot;D&quot; &amp;amp;&amp;amp; $NF ~ /\\.kts?$/ { print $NF }&#39;)&quot;if [ -z &quot;$CHANGED_FILES&quot; ]; then echo &quot;No Kotlin staged files.&quot; exit 0fi;echo &quot;Running ktlint over these files:&quot;echo &quot;$CHANGED_FILES&quot;diff=.git/unstaged-ktlint-git-hook.diffgit diff --color=never &amp;gt; $diffif [ -s $diff ]; then git apply -R $difffi./gradlew --quiet ktlintCheck -PinternalKtlintGitFilter=&quot;$CHANGED_FILES&quot;gradle_command_exit_code=$?echo &quot;Completed ktlint run.&quot;if [ -s $diff ]; then git apply --ignore-whitespace $difffirm $diffunset diffecho &quot;Completed ktlint hook.&quot;exit $gradle_command_exit_code######## KTLINT-GRADLE HOOK END ########실행 권한을 부여chmod +x .git/hooks/pre-commit사용법코드 스타일 검사./gradlew ktlintCheck프로젝트의 모든 Kotlin 파일에 대해 스타일 검사를 수행한다. 문제가 있으면 에러 메시지와 함께 어떤 파일의 몇 번째 라인에서 문제가 발생했는지 알려준다.자동 포맷팅./gradlew ktlintFormat검사를 통과하지 못한 코드를 자동으로 수정해준다. 대부분의 스타일 문제는 이 명령어로 해결 가능하다.긴급 커밋 (Hook 우회)git commit --no-verify -m &quot;긴급 수정&quot;Pre-commit hook을 우회하여 커밋할 수 있다. 하지만 가급적 사용하지 않는 것을 권장장점 일관성: 팀 전체가 동일한 코드 스타일을 따르게 되어 가독성이 향상된다 자동화: 수동으로 스타일을 체크하고 수정할 필요가 없다 사전 방지: Pre-commit hook을 통해 잘못된 스타일의 코드가 리포지토리에 올라가는 것을 방지 리뷰 효율성: 코드 리뷰 시 스타일에 대한 지적이 줄어들어 로직에 집중할 수 있다신경써야 할 것 초기 적용 시 수정량이 많을 수 있다: 기존 코드가 많은 프로젝트에 처음 도입하면 많은 파일이 수정될 수 있다 빌드 시간 증가: ktlint 포메팅이 꽤나 오래걸려서 번거롭긴함.. 와일드카드 임포트같은건 자동수정이 안돼 수동으로 해줘야 함.Reference) https://github.com/pinterest/ktlint https://github.com/JLLeitschuh/ktlint-gradle" }, { "title": "Callback 방식의 캐싱 구현으로 AOP의 한계 극복하기", "url": "/posts/Callback_%EB%B0%A9%EC%8B%9D%EC%9D%98_%EC%BA%90%EC%8B%B1_%EA%B5%AC%ED%98%84%EC%9C%BC%EB%A1%9C_AOP%EC%9D%98_%ED%95%9C%EA%B3%84_%EA%B7%B9%EB%B3%B5%ED%95%98%EA%B8%B0/", "categories": "Study, Spring boot", "tags": "spring, spring boot, 스프링, 스프링부트, redis, 레디스, cache, 캐시", "date": "2025-10-10 00:00:00 +0900", "snippet": " Spring의 @Cacheable 어노테이션은 편리하지만, 같은 클래스 내부에서 메서드를 호출할 때 AOP가 동작하지 않는다는 한계가 있다. 이를 해결하기 위해 callback 방식의 고차함수를 활용한 캐싱 로직을 구현했다. 이 방식은 AOP의 한계를 극복하면서도 캐싱 로직을 재사용 가능하게 만들어준다. @Cacheable의 한계 Spring의 @Cacheable은 AOP 기반으로 동작한다. AOP는 프록시 패턴을 통해 동작하기 때문에, 같은 클래스 내부에서 메서드를 호출할 때는 프록시를 거치지 않아 캐싱이 동작하지 않는다. e.g.) Service 클래스 내부에서 this.getCachedData()를 호출하면 @Cacheable이 적용되지 않음 문제 상황@Serviceclass UserService { @Cacheable(&quot;users&quot;) fun getUserById(id: Long): User { // DB 조회 } fun processUser(id: Long) { // 같은 클래스에서 호출 - 캐싱이 동작하지 않음! val user = this.getUserById(id) // ... }}Callback 방식의 캐싱 구현: 고차함수를 callback으로 전달받아, 캐시 미스 시에만 해당 로직을 실행하는 방식으로 구현한다.1. CacheDao 인터페이스 설계interface CacheDao { fun &amp;lt;T&amp;gt; cache( key: String, ttl: Duration?, typeRef: TypeReference&amp;lt;T&amp;gt;, callBack: () -&amp;gt; T?, ): T? fun &amp;lt;K, V&amp;gt; cacheBulk( keys: List&amp;lt;K&amp;gt;, keyMapper: (K) -&amp;gt; String, ttl: Duration?, typeRef: TypeReference&amp;lt;V&amp;gt;, callBack: (List&amp;lt;K&amp;gt;) -&amp;gt; Map&amp;lt;K, V&amp;gt;, ): Map&amp;lt;K, V&amp;gt;} cache(): 단일 키에 대한 캐싱 cacheBulk(): 여러 키에 대한 벌크 캐싱 callBack: 캐시 미스 시 실행될 로직을 고차함수로 전달받음2. 구현부 - cache() 메서드override fun &amp;lt;T&amp;gt; cache( key: String, ttl: Duration?, typeRef: TypeReference&amp;lt;T&amp;gt;, callBack: () -&amp;gt; T?,): T? { // 1. 캐시 조회 redisTemplate.opsForValue().get(key)?.let { raw -&amp;gt; return convertToValue(raw, typeRef) } // 2. 캐시 미스 - callback 실행 val computed = callBack.invoke() // 3. 결과를 캐시에 저장 computed?.let { val json = objectMapper.writeValueAsString(it) if (ttl != null) { redisTemplate.opsForValue().set(key, json, ttl) } else { redisTemplate.opsForValue().set(key, json) } } return computed}3. 구현부 - cacheBulk() 메서드override fun &amp;lt;K, V&amp;gt; cacheBulk( keys: List&amp;lt;K&amp;gt;, keyMapper: (K) -&amp;gt; String, ttl: Duration?, typeRef: TypeReference&amp;lt;V&amp;gt;, callBack: (List&amp;lt;K&amp;gt;) -&amp;gt; Map&amp;lt;K, V&amp;gt;,): Map&amp;lt;K, V&amp;gt; { if (keys.isEmpty()) return emptyMap() val keyToRedisKey: Map&amp;lt;K, String&amp;gt; = keys.associateWith(keyMapper) val redisKeys: List&amp;lt;String&amp;gt; = keyToRedisKey.values.toList() // 1. 캐시에서 일괄 조회 val redisRawValues: List&amp;lt;String?&amp;gt; = redisTemplate.opsForValue().multiGet(redisKeys) ?: emptyList() // 2. 캐시 히트된 데이터 처리 val redisHitMap: Map&amp;lt;K, V&amp;gt; = keyToRedisKey.keys .zip(redisRawValues) .filter { (_, rawValue) -&amp;gt; rawValue != null } .associate { (key, rawValue) -&amp;gt; key to objectMapper.readValue(rawValue!!, typeRef) } // 3. 캐시 미스된 키만 추출 val missedKeys: List&amp;lt;K&amp;gt; = keys.filterNot { redisHitMap.containsKey(it) } // 모두 캐시 히트 if (missedKeys.isEmpty()) { return redisHitMap } // 4. 캐시 미스 - callback 실행 (미스된 키만 전달) val callBackResults: Map&amp;lt;K, V&amp;gt; = callBack(missedKeys) // 5. 결과를 캐시에 일괄 저장 val redisKeyValueMap: Map&amp;lt;String, String&amp;gt; = callBackResults .mapNotNull { (key, value) -&amp;gt; val redisKey = keyToRedisKey[key] ?: return@mapNotNull null val jsonValue = objectMapper.writeValueAsString(value) redisKey to jsonValue }.toMap() if (ttl == null) { redisTemplate.opsForValue().multiSet(redisKeyValueMap) } else { redisKeyValueMap.forEach { (redisKey, jsonValue) -&amp;gt; redisTemplate.opsForValue().set(redisKey, jsonValue, ttl) } } return redisHitMap + callBackResults}사용 예시단일 캐싱@Serviceclass ProductService( private val cacheDao: CacheDao, private val productRepository: ProductRepository,) { fun getProduct(productId: Long): Product? { return cacheDao.cache( key = &quot;product:$productId&quot;, ttl = Duration.ofMinutes(10), typeRef = object : TypeReference&amp;lt;Product&amp;gt;() {}, ) { // 캐시 미스 시 실행될 로직 (DB 조회) productRepository.findById(productId) } }}벌크 캐싱@Serviceclass ProductService( private val cacheDao: CacheDao, private val productRepository: ProductRepository,) { fun getProducts(productIds: List&amp;lt;Long&amp;gt;): Map&amp;lt;Long, Product&amp;gt; { return cacheDao.cacheBulk( keys = productIds, keyMapper = { id -&amp;gt; &quot;product:$id&quot; }, ttl = Duration.ofMinutes(10), typeRef = object : TypeReference&amp;lt;Product&amp;gt;() {}, ) { missedIds -&amp;gt; // 캐시 미스된 ID들만 DB 조회 productRepository.findAllByIdIn(missedIds) .associateBy { it.id } } }}장점1. AOP 한계 극복 같은 클래스 내부에서 호출해도 캐싱이 정상 동작한다. 프록시를 거치지 않아도 되므로, 어디서든 사용 가능하다.2. 성능 최적화 cacheBulk(): 캐시 미스된 키만 callback으로 전달하여, 불필요한 DB 조회를 방지한다. e.g.) 100개 중 20개만 캐시 미스 → callback은 20개에 대해서만 실행 Redis의 multiGet, multiSet을 활용해 네트워크 왕복 횟수를 최소화한다.3. 유연성 callback을 통해 캐시 미스 시 실행할 로직을 자유롭게 정의할 수 있다. DB 조회뿐만 아니라, 외부 API 호출, 복잡한 계산 등 다양한 로직에 적용 가능하다.4. 재사용성 캐싱 로직이 CacheDao에 집중되어 있어, 중복 코드를 제거할 수 있다. 캐시 정책 변경 시 한 곳만 수정하면 된다.결론: Callback 방식의 캐싱 구현은 AOP의 한계를 극복하면서도 재사용 가능한 캐싱 로직을 제공한다. 특히 벌크 캐싱에서는 캐시 미스된 키만 선별적으로 처리함으로써 성능을 크게 향상시킬 수 있다. 고차함수를 활용한 이러한 패턴은 Spring의 선언적 캐싱이 적합하지 않은 상황에서 강력한 대안이 될 수 있다.Reference)https://docs.spring.io/spring-framework/reference/integration/cache.htmlhttps://docs.spring.io/spring-data/redis/docs/current/reference/html/" }, { "title": "Redis cluster 해시태그", "url": "/posts/Redis_cluster_%ED%95%B4%EC%8B%9C%ED%83%9C%EA%B7%B8/", "categories": "Study, Redis", "tags": "redis, 레디스", "date": "2025-09-05 00:00:00 +0900", "snippet": ": Redis cluster를 사용할 때 n개의 키에 multiGet을 하면, 각각의 키가 저장된 슬롯으로 n번의 get 호출이 가게 된다. 이후, redis 클라이언트에서 이를 조합하는데 성능이 많이 떨어지게 된다. hashTag를 사용하면 같은 해시를 갖는 키들은 하나의 슬롯에 저장되어 한번의 호출만으로 불러오는게 가능하다.Redis Cluster와 해시 태그 Redis Cluster는 데이터를 여러 노드에 분산해서 저장함으로써 높은 성능과 가용성을 제공한다. 데이터는 16,384개의 슬롯에 매핑되고, 각 노드는 이 슬롯의 일부를 담당한다. (예: 3 노드면 약 5천 개씩 담당) 기본적으로 Redis는 키(key)의 이름을 CRC16 해시 함수에 적용해서 어떤 슬롯에 저장할지 결정한다. 이렇게 하면 키가 클러스터 전체에 균등하게 분산된다.해시태그 사용의 장점 특정 키들을 동일한 노드, 즉 동일한 해시 슬롯에 저장하고 싶을 때가 있다. (특히 불가피하게 mGet을 사용해야 할 때) 이때 해시 태그(Hash Tag)를 사용한다. 해시 태그는 키의 일부를 중괄호 {}로 감싸는 방식으로 쓰며, Redis Cluster는 슬롯을 계산할 때 중괄호 {} 안의 문자열만 사용한다. e.g. user:{1000}:name과 user:{1000}:email은 {1000}이라는 동일한 해시 태그를 가지므로 항상 같은 해시 슬롯에 저장 Cluster 환경에서는 여러 키에 대한 연산(MGET, MSET, DEL 등)을 수행할 때, 해당 키들이 서로 다른 슬롯에 분산되어 있으면 redis 입장에서는 n번의 호출을 받게 된다.해시 태그 사용의 단점1. 핫스팟(Hotspot) 문제 데이터가 클러스터 전체에 고르게 분산되지 않을 수 있어, 해당 슬롯을 담당하는 노드에만 데이터와 트래픽이 집중되는 핫스팟(Hotspot)이 생긴다.2. 클러스터 확장성 저해 핫스팟이 생긴 노드는 클러스터 전체 처리량을 제한하는 병목 지점이 된다. 새로운 노드를 추가해도 핫스팟이 해결되지 않아, 사실상 클러스터의 장점 자체를 잃는다.3. 리샤딩(Resharding)의 어려움 리샤딩하는 시나리오를 생각해보면, 거대해진 특정 해시 슬롯은 옮기는 과정에서 많은 시간과 리소스를 소모하고, 클러스터 운영에도 부담을 준다.성능 테스트: 테스트 환경 - spring boot 환경에서 redis mGet을 50개씩 호출하는 환경에서 400 스레드로 부하를 주는 테스트를 했을때, 발생하는 차이 전자가 hashTag 없을 때, 후자가 hashTag 있을 때 mGet과 아닌것의 성능차이를 무시할수는 없을 것 같다. CPU가 올라간 원인은 redis client에서 mget 결과를 조합하는데 발생하는 비용때문인것으로 추정결론: Redis Cluster의 해시 태그는 멀티 키 연산을 가능하게 하는 강력한 기능이지만, 데이터 분산을 하지 못해 핫스팟을 유발할 수 있는 위험성을 가진다.사용하기 좋은 예 카디널리티(Cardinality)가 낮은 데이터에 사용: 태그 종류가 너무 많지 않고, 각 태그에 속한 데이터 크기가 예측 가능하고 거대해지지 않을 경우에 쓰는 게 안전하다. (속해있는 도메인에 대해 적절히 파악한 후 사용) e.g. rooms:roomId:users:userId 와 같은 key를 가질 때 {rooms:roomId}users:userId 으로 묶으면 적어도 같은 room에 있는 키 끼리는 한 슬롯에 모이게 된다. " }, { "title": "시작하세요! 도커 / 쿠버네티스 6장 쿠버네티스 시작하기", "url": "/posts/%EC%8B%9C%EC%9E%91%ED%95%98%EC%84%B8%EC%9A%94_%EB%8F%84%EC%BB%A4_%EC%BF%A0%EB%B2%84%EB%84%A4%ED%8B%B0%EC%8A%A4_6%EC%9E%A5_%EC%BF%A0%EB%B2%84%EB%84%A4%ED%8B%B0%EC%8A%A4_%EC%8B%9C%EC%9E%91%ED%95%98%EA%B8%B0/", "categories": "Study, Kubernetes", "tags": "kubernetes, 쿠버네티스", "date": "2022-08-12 00:00:00 +0900", "snippet": "쿠버네티스란? 도커 컨테이너, 스웜, 컴포즈와 같은 개념을 모두 사용 가능하다. 사실상 표준으로 사용되는 컨테이너 오케스트레이션 도구이다. 클라우드 환경에 적합한 오픈소스를 관리하는 Cloud Native(CNCF - 오픈소스 단체)에 속해있다. containerd, 프로메테우스 등이 CNCF 소속 장점 클러스터링, MSA구조의 컨테이너 배포, 장애 복구 등 운영에 필요한 오케스트레이션 기능을 지원한다. 구글, redhat을 비롯한 많은 오픈소스 진영에서 쿠버네티스에 기여하고 있다. 영속적 볼륨, 스케줄링, 장애 복구, 오토 스케일링, 서비스 발견, ingress 등의 기능들을 개발자가 직접 설정할 수 있다. 다른 클라우드 운영도구와 쉽게 연동특징 모든 리소스는 Object이다. kubectl api-resources를 통해 확인 가능하다. 대부분 리소스는 YAML로 관리한다. 여러 개의 컴포넌트가 컨테이너 형태로 구성되어 있다. -&amp;gt; 노드에 ssh 접속해서 docker ps로 확인 가능 마스터 노드 - API 서버, 컨트롤러 매니저, 스케줄러, DNS 서버 등 모든 노드 - 프록시(오버레이 네트워크 구성을 위한), 네트워크 플러그인 kubelet: 모든 노드에는 컨테이너 생성, 삭제, 마스터와 워커 노드간 통신 담당하는 에이전트인 kubelet이 실행된다. 이 kubelet은 CRI(Container Runtime Interface)와 통신한다. 도커 컨테이너의 경우 runC라는 런타임을 제어하는 containerd는 자체적으로 CRI를 내장하고 있어, kubelet과 통신 가능하다. 이 CRI를 구현하는 컨테이너라면 다른 컨테이너를 사용해도 사실상 무방하다.파드 컨테이너를 다루는 기본 단위. 하나 이상의 컨테이너로 구성 도커 네트워크 중 컨테이너 네트워크의 동작방식처럼 파드 내 컨테이너 간 리눅스 네임스페이스를 공유해, 서로 통신이 가능하다. 하나의 파드는 하나의 완전한 애플리케이션이어야 한다. e.g. 하나의 파드 내에 두개의 nginx 컨테이너를 띄우는 것은 적절하지 않다. 보통 파드 내 사이드카로 로그수집이나 설정 리로딩 프로세스를 띄우는 경우도 있다. 레플리카셋: Pod의 Lifecycle을 관리해주는 역할. 파드를 yaml로서만 관리하면 생성, 삭제와 같은 관리를 개발자가 직접해줘야 한다. 이러한 방식은 운영 단계에서 분명 한계점이 있는데, 레플리카셋은 이러한 한계점을 해결한다. 일정량의 동일한 파드가 항상 실행되도록 관리한다. 이미 일정량의 파드가 실행중이라도 설정을 변경하면 변경된 만큼 파드를 생성 or 삭제해준다. 노드 장애 발생 시 해당 노드의 파드를 다른 노드로 다시 실행한다.동작방식 레플리카셋은 라벨 셀렉터를 이용해 파드와 느슨하게 연결된다. ...spec: repolicas: 3 selector: matchLabels: app: my-nginx-pod # 레플리카셋의 라벨 셀렉터 template: metadata: name: nginx labels: app: my-nginx-pod # 파드의 라벨 라벨은 단순히 메타데이터로써 부가정보만 표시하는 것이 아니라, 리소스를 분류할 때도 사용된다. 이미 레플리카셋의 라벨 셀렉터에 셀렉팅 되는 파드가 있다면, 해당 파드를 포함해 생성해야 하는 숫자만큼 생성한다. 만약 파드의 라벨이 바뀌면 더이상 해당 레플리카 셋에 의해 관리되지 않는다. 디플로이먼트: 파드 + 레플리카셋을 정의한다. 레플리카셋의 슈퍼셋이다. 공식적으로 디플로이먼트 사용이 권장된다. 디플로이먼트를 통해 레플리카셋과 파드를 띄우면 각각 동일한 해시값을 갖는다. 이 해시값은 파드 템플릿으로부터 계산되어, 레플리카셋의 라벨 셀렉터에서 pod-template-hash라는 이름의 라벨값으로서 자동으로 설정된다.디플로이먼트를 사용하는 이유: 레플리카셋의 리비전을 남기고, 파드를 롤링업데이트하는 전략을 지정할 수 있다. 파드를 업데이트하면 롤링 업데이트가 수행되는데, 그러면 해당 파드들을 셀렉팅하는 레플리카셋도 새롭게 띄워진다. kubectl get replicasets 를 통해 확인하면, DESIRED, CURRENT 항목에 숫자가 입력된 레플리카셋(현재)과 숫자가 0인 레플리카셋(이전 버전)을 확인할 수 있다. 당연히 --to-revision=1 과 같은 옵션을 통해 롤백도 가능하다. 서비스apiVersion: v1kind: Servicemetadate: name: hostname-svcspec: ports: - name: port port: 8080 targetPort: 80 # 실제 파드 내에서 실행되는 port selector: app: webserver # 서비스와 매칭할 pod type: NodePort # 서비스 타입 파드는 클러스터 내에서 항상 접근 가능하지만, 파드 IP는 영속적이지 않아 매변 변하기 때문에 발견 가능한 방법이 필요한데, 서비스가 해결해준다. 외부에서 접근하는 경우, 도커에서는 컨테이너를 외부로 직접 노출해 접근했는데, k8s에서는 서비스를 통해서 접근해야한다. 서비스는 내부 DNS를 사용해 고유한 서비스 도메인 이름을 가질 수 있다. 파드 간 상호작용이 필요할때 파드 IP를 알 필요 없이 서비스 이름만 알면 된다. 요청받는 서비스는 각 파드들로 LB 해준다. 마찬가지로 라벨 셀렉터를 통해 파드와 매칭한다. 매칭이 되면 엔드포인트라는 오브젝트가 생성된다.종류: 각각 파드에 접근하는 방식이 다르다. ClusterIP: (쿠버네티스 내부에서만) ClusterIP를 프록싱해 파드에 접근하는 방식 NodePort: 모든 노드의 특정 포트를 개방하는 방식 클러스터 외부에서 각 파드가 존재하는 노드의 적절한 port로 접근 가능하다. ClusterIP의 기능을 포함하고 있기 때문에 마찬가지로 서비스의 CLUSTER-IP or DNS 이름으로 접근 가능하다. (내부 접근 가능) 그런데 실제 운영 환경에서 사용하기엔 여러가지 문제가 있다. (라우팅) 노드가 스케일링, 장애 등의 이유로 IP가 변경되면 클라이언트도 수정되어야 하기도 하고, SSL 문제도 잇따른다. LoadBalancer: 서비스 자체를 외부에 노출한다. 클라우드 플랫폼 환경에서 사용할 수 있다. 클라우드 플랫폼은 LoadBalancer 서비스에 EXTERNER-IP를 부여하는데, 이 주소 + 서비스 PORT로 파드에 접근이 가능하다. NodePort와 같은 방식으로 노드로도 접근이 가능하다. ExternalName: 외부 도메인으로 리다이렉트한다.ExternalTrafficPolicy 서비스는 기본적으로 externalTrafficPolicy가 Cluster로 설정된다. 이 경우 노드로 들어온 요청은 다른 노드의 파드로 리다이렉트 되는 경우가 있고, 이 때 네트워크 홉으로 인해 NAT가 발생하며 클라이언트 IP가 보존 불가해진다. externalTrafficPolicy를 Local로 설정하면 파드가 위치한 노드만 포트를 개방한다. 그런데 이 때는 트래픽이 몰리는 경우도 있을 수 있으므로 잘 판단해 선택해야한다.Reference)시작하세요! 도커 / 쿠버네티스" }, { "title": "시작하세요! 도커 / 쿠버네티스 4장 도커 컴포즈", "url": "/posts/%EC%8B%9C%EC%9E%91%ED%95%98%EC%84%B8%EC%9A%94_%EB%8F%84%EC%BB%A4_%EC%BF%A0%EB%B2%84%EB%84%A4%ED%8B%B0%EC%8A%A4_4%EC%9E%A5_%EB%8F%84%EC%BB%A4_%EC%BB%B4%ED%8F%AC%EC%A6%88/", "categories": "Study, Docker", "tags": "docker, 도커", "date": "2022-08-10 00:00:00 +0900", "snippet": ": 필요한 컨테이너들의 설정을 하나의 파일로 구성해 한번에 띄우도록 하는 것특징 도커에 내장되어있지 않아 별도로 설치해야한다. 생산성: 하나의 서비스가 여러개의 컨테이너로 구성되어있을 때 개발 환경을 위해 하나하나 띄우는 것은 생산성을 저하시킨다. 컴포즈를 통해 이러한 생상성 저하를 막을 수 있다. Dockerfile을 run할때 부여했던 옵션값들을 모두 컴포즈 yaml에 작성 가능하다.추가적인 기능 스케일링: docker-compose scale service=2 와 같은 형태로 스케일링이 가능하다. yaml 파일에 scale을 명시할 수도 있다. depends_on : 컨테이너간 의존관계와 condition을 설정해, 해당 컨디션이 만족할 때 띄우도록 할 수 있다.external 프로젝트 생성마다 네트워크, 볼륨을 생성하는 것이 아닌 (외부에) 이미 존재하는 네트워크, 볼륨을 먹일 수 있다. services: web: image: ubuntu:14.04 networks: - my_network networks: # 사용할 네트워크, 볼륨 my_network: external: true 스웜: 스웜모드로 생성하면 yaml에 명시한 컨테이너들의 묶음이 하나의 스택이 되고, 해당 컨테이너들은 클러스터에서 일괄 생성된다. 이 때는 컴포즈 yaml로 띄웠어도 docker-compose가 아닌 docker stack으로 제어한다. links, depends_on 와 같은 컨테이너 간 의존성 정의는 할 수 없다. 스웜 모드이기 때문에 클러스터 내 다른 호스트에 컨테이너가 생성될 수 있는데, 컨테이너간 의존성 정의는 한 호스트에 컨테이너가 생성되어야하기 때문이다.도커와 컨테이너 생태계 OCI: 컨테이너 기술이 특정 벤더 or 회사에 의존되지 않도록 중립의 컨테이너 표준을 정의 공통적으로 구현되어야 하는 런타임과 이미지 스펙의 표준을 정의한다. 도커: runC + containerd + 도커 엔진 runC: 컨테이너와 1:1 매칭되는, 런타임 역할 containerd: 컨테이너 프로세스, 이미지를 관리 도커 엔진: containerd와 통신해 runC를 사용할 수 있도록 하는 엔드유저용 도구 도커 컨테이너: 각각이 위와 같은 역할을 담당하기 때문에 runC와 containerd는 도커 엔진 없이 독립적으로 사용될 수 있다. 그래도 일반적으로는 도커 엔진과 함께 사용되는데, 따라서 일반적으로 도커 컨테이너라고 부른다.Reference)시작하세요! 도커 / 쿠버네티스" }, { "title": "시작하세요! 도커 / 쿠버네티스 3장 도커 스웜", "url": "/posts/%EC%8B%9C%EC%9E%91%ED%95%98%EC%84%B8%EC%9A%94_%EB%8F%84%EC%BB%A4_%EC%BF%A0%EB%B2%84%EB%84%A4%ED%8B%B0%EC%8A%A4_3%EC%9E%A5_%EB%8F%84%EC%BB%A4_%EC%8A%A4%EC%9B%9C/", "categories": "Study, Docker", "tags": "docker, 도커", "date": "2022-08-05 00:00:00 +0900", "snippet": "도커 서버 클러스터링의 이점: 새로운 컨테이너를 할당, 발견 작업, 스케줄링과 LB, HA 보장 등도커 스웜이란?: 도커 서버 클러스터링 중 하나. 배포된 컨테이너들 관리를 자동화하기 때문에 컨테이너 오케스트레이션이라고도 불린다. 스웜 클래식: 단일 접근점에 초점. 도커 ver 1.6~ 사용가능하나, 공식문서에 의하면 레거시이므로 스웜 모드를 사용하는 것이 좋다. 스웜 모드: 일반적으로 말하는 스웜. 클러스터링에 초점. 유동적으로 컨테이너 수 조절, 서버 발견, LB 등을 지원한다. 도커 스웜(스웜 모드)매니저 노드 워커 노드에 서비스를 배포하고 관리하는 역할. 스웜 명령어는 매니저 노드에서 가능하다. 1개의 리더와 n-1개의 매니저노드가 존재한다. 리더 장애 발생 시 리더를 재선출한다. 네트워크 파티셔닝, 투표를 위해 홀수개의 노드로 띄워놓는다. (Raft Consensus) 워커 노드의 역할도 수행할 수 있지만 구분해 사용하는 것이 권장.워커 노드: 매니저 노드의 명령을 받으며, 실제 서비스를 제공하기 위한 애플리케이션들을 띄워놓는다.서비스 서비스 내에는 1개 이상의 컨테이너(태스크)가 존재할 수 있다. 서비스에 설정한 레플리카 수만큼 컨테이너가 스웜 클러스터 내에 존재한다. 특정 노드가 다운되면 해당 노드에 존재하던 레플리카는 다른 노드에 새로운 컨테이너를 생성한다. 스웜 클러스터에 서비스가 배포되면 클러스터 내의 어떤 노드를 통해 접근해도 서비스로 접근이 가능하다. 이 때 접근될 컨테이너는 RR 방식으로 결정된다.롤링 업데이트: 무중단 배포를 위해 서버를 하나씩 재시작하고 삭제하는 매커니즘서비스 모드 replica mode: 레플리카셋의 수를 정의해 그만큼 컨테이너를 복제하는 모드. default 노드 장애 발생 시 매니저가 컨테이너를 생성해 자동으로 복구한다. 노드가 회복되어도 재균형(rebalancing)은 되지 않는다. 재균형을 위해서는 scale-in 후 scale-out을 수행해야한다. global: 모든 노드에 컨테이너를 하나씩 생성하는 모드. 스웜 클러스터를 모니터링하기 위한 에이전트 컨테이너 등을 생성할 때 적합하다. secret, config: 이미지에 설정을 정의할 수 있으나, 유연성을 위해 secret, config를 생성해 서비스에 적용시킨다.네트워크 ingress: 스웜 클러스터에 자동으로 등록되는 네트워크. 어떤 스웜 노드에 접근하더라도 컨테이너에 접근할 수 있도록 라우팅 메시 구성. (RR 방식) overlay network 드라이버를 사용한다: 여러 도커 데몬에 존재하는 컨테이너가 서로 통신 가능하다. 서비스 디스커버리: 오버레이 네트워크를 사용하는 서비스는 VIP(Virtual IP)를 갖고, 도커엔진의 내장 DNS 서버는 호스트 이름을 IP로 변환한다. 따라서, 새로운 서비스가 생성되어도 서비스의 주소를 알 필요 없이 호스트 이름을 통해 접근이 된다.볼륨 도커 볼륨 or 호스트 디렉터리 공유인지를 type을 명시해야한다. 호스트마다 볼륨을 맵핑해줘야 하는데 이 방법 보다는 서드파티 플러그인 혹은 nfs, dfs 등 persistenct storage를 사용하는 것이 좋아보인다.스택 ?: 컨테이너들을 하나의 yaml로 관리하며 한번에 띄우기 위한 목적으로 docker-compose를 사용하는데, 컴포즈 파일을 대상으로 docker stack deploy -c docker-compose.yml myStack과 같이 명령어를 주면 해당 컴포즈를 스웜으로 배포한다.노드 다루기 AVAILABILITY: Active(서비스 할당가능), Drain(할당 불가, 기존 서비스 이관), Pause(할당 불가, 기존 서비스 유지) 라벨링: labels, id, host,name 등 라벨을 추가해 서비스를 배포할 노드를 분류할 수 있다.Reference)시작하세요! 도커 / 쿠버네티스" }, { "title": "시작하세요! 도커 / 쿠버네티스 2장 도커 엔진 - 4. 도커 데몬", "url": "/posts/%EC%8B%9C%EC%9E%91%ED%95%98%EC%84%B8%EC%9A%94_%EB%8F%84%EC%BB%A4_%EC%BF%A0%EB%B2%84%EB%84%A4%ED%8B%B0%EC%8A%A4_2%EC%9E%A5_%EB%8F%84%EC%BB%A4_%EC%97%94%EC%A7%84_4_%EB%8F%84%EC%BB%A4_%EB%8D%B0%EB%AA%AC/", "categories": "Study, Docker", "tags": "docker, 도커", "date": "2022-08-04 00:00:00 +0900", "snippet": "도커 클라이언트와 도커 데몬 도커 클라이언트: Mac 기준 /usr/local/bin/docker, 리눅스 기준 /usr/bin/docker에 존재. 도커데몬의 API를 호출함으로써 유저가 CLI로 도커를 이용할 수 있도록 한다. /var/run/docker.sock Unix 소켓을 이용한다. 도커 서버(데몬 - dockerd): /usr/bin/dockerd (Mac에서는 도커 데스크탑에 존재). dockerd 명령어를 통해 도커 데몬을 포그라운드 형태로 직접 실행할 수 있다. --insecure-registry -&amp;gt; 레지스트리 컨테이너 구축 / --storage-opt -&amp;gt; 스토리지 백엔드 변경 등 다양한 도커 데몬 설정이 가능하고, 매번 직접 CLI로 칠 필요 없이 설정파일 DOCKER_OPTS에 입력해놓을 수 있다. k8s로 따지면 Podman에 대응된다고 보면 된다. 도커 데몬 제어: -H 해당 옵션과 함께 IP, port를 적어두면 원격 API인 Docker remote API로 도커를 제어할 수 있다. (HTTP 요청) 만일 remote docker daemon 주소만 적으면 해당 도커 데몬에 로컬에서 사용하던 unix 소켓이 비활성화 되어 로컬 CLI를 사용 할 수 없게 되니, 함께 입력하면 둘다 요청을 받아 처리할 수 있다. 각 언어별로 라이브러리들이 오픈소스 형태로 존재한다. 개발에 필요한 경우 이용할 수 있다. 도커 데몬에 보안 : –tlsverify: 기본적으로 도커에는 보안 연결이 설정돼있지 않는다. remote API를 사용할 때도 마찬가지이기 때문에 TLS를 적용해야한다.스토리지 드라이버 변경: –storage-driver: 도커는 스토리지 백엔드 기술을 이용해 컨테이너와 이미지를 저장 및 관리한다. Mac에서는 overlay2. 스냅샷의 개념이 이용된다: 원본은 읽기전용으로 사용하고 변경은 새로운 공간에 할당하기 CoW: 스냅샷 공간에 원본파일 복사 후 변경사항 쓰기. (write 오버헤드 2회) RoW: 원본 스냅샷을 freeze 시킨 뒤 스냅샷 공간에 변경된 사항 새롭게 할당받아 쓰기(write 1회) 이미지 레이어는 각 스냅샷에 해당한다. 컨테이너 레이어의 변경점을 커밋하면 변경사항(diff)가 스냅샷(commit)으로 생성되고 해당 diff는 하나의 이미지 레이어로서 존재한다.데몬 모니터링: 컨테이너 상태 뿐 아니라 도커를 PaaS로 제공하는 경우를 위해 도커 데몬 자체를 모니터링 할 수 있다. events: 컨테이너, 이미지, 볼륨 네트워크 관련 명령어 실행 결과를 모니터링 stats: 컨테이너 자원 사용량 모니터링 system df: 컨테이너, 이미지, 볼륨 사용량과 삭제함으로써 확보 가능한 공간 등 모니터링 -&amp;gt; prune 관련 CAdvisor: 호스트의 도커 관련 디렉터리를 모두 해당 컨테이너와 볼륨 공유한다. 리소스, 컨테이너 상태 등을 확인 할 수 있다. 호스트의 도커 리소스를 공유하는 것이기 때문에 단일 호스트 한정이다.Reference)시작하세요! 도커 / 쿠버네티스" }, { "title": "시작하세요! 도커 / 쿠버네티스 2장 도커 엔진 - 3. Dockerfile", "url": "/posts/%EC%8B%9C%EC%9E%91%ED%95%98%EC%84%B8%EC%9A%94_%EB%8F%84%EC%BB%A4_%EC%BF%A0%EB%B2%84%EB%84%A4%ED%8B%B0%EC%8A%A4_2%EC%9E%A5_%EB%8F%84%EC%BB%A4_%EC%97%94%EC%A7%84_3_Dockerfile/", "categories": "Study, Docker", "tags": "docker, 도커", "date": "2022-08-04 00:00:00 +0900", "snippet": ": 설치할 패키지, 소스코드, 실행해야할 명령어 등을 Dockerfile에 기록해놓고 해당 파일을 빌드해 도커 이미지를 만든다. CI/CD 도구를 이용해 자동화하기에도 편리하다. 빌드 과정에 필요한 작업들을 명확하게 명시할 수 있는 것도 장점 중 하나 인 것 같다. docker build -t imageName 으로 실행한다.빌드 과정 가장 먼저 빌드 컨택스트(Dockerfile 위치)를 읽어들인다. (빌드 시 가장 먼저 Sending build context to Docker daemon 가 출력된다.) 하위 디렉터리를 모두 포함하기 때문에 필요한 디렉터리만 포함될 수 있도록 빌드 컨택스트를 고려해야한다. 제외 할 파일은 .dockerignore을 사용한다. 각 명령어마다 Step이 존재한다. 각 Step마다 새로운 컨테이너를 생성하고, 커밋해 이미지화 하고, 해당 이미지를 베이스로 다음 명령어를 수행한다. 캐싱: 도커파일에서 명령어는 기본적으로 캐싱되어 같은 빌드를 할 때 재사용한다. COPY, RUN은 파일의 변경상태 또한 체크해준다. 앞쪽 명령어에서 캐싱이 끊기면 그 이후론 쭉 끊긴다. 따라서 순서가 중요하고, COPY RUN으로 캐싱이 끊길 거라고 예상이 된다면 COPY, RUN을 순서를 뒤쪽으로 배치하는 것도 좋은 방법이다. --no-cache: 같은 이미지레이어를 재사용 하는 것이기 때문에 git과 같은 원격에서 형상변경이 일어나도 재사용하게 된다. 이 때는 캐시를 사용하지 않도록 한다. --cache-from을 통해 특정 이미지를 캐시로 활용 할 수도 있다. &amp;lt;none&amp;gt;:&amp;lt;none&amp;gt; : 이미지 빌드 중 오류가 발생한 이미지멀티스테이지: 필요한 빌드 작업과 실제 사용할 컨테이너 작업을 분리해, 빌드 완료 시 최종적으로 필요한 파일만 추가할 수 있도록 한다. 이미지 크기를 줄일 수 있는 방법. 두번째 스테이지에서 COPY를 통해 첫번째 스테이지의 컨테이너 내부의 특정 경로만을 복사해 사용한다.Dockerfile 작성잘 작성하는 방법 \\ 역슬래시를 활용해 가독성을 높인다. 도커의 이미지 구조는 레이어 구조이기 때문에 각 레이어 변경사항을 모두 저장한다. 불필요한 용량을 줄이고자 RUN 명령어를 &amp;amp;&amp;amp;로 묶는 방법을 활용한다.FROM 새로운 빌드 스테이지를 초기화한다. 멀티 스테이지로 빌드할 경우 다음 스테이지의 베이스 이미지가 된다. docker hub, private registry, 로컬로 부터 불러와 사용될 수 있는 이미지가 인자가 된다.LABEL: 메타데이터를 key:value로 명시한다. inspect로 메타데이터 확인 가능하다.RUNRUN [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;] 컨테이너 내부 shell에서 직접 커맨드 하는 것과 같다. 이미지 빌드 과정에서 필요한 커맨드를 치기 위해 사용한다. JSON 배열 형태로 입력한다. RUN에 명시된 커맨드를 실행할 때 별도로 입력해야하는 경우(e.g. Y/N)라면 빌드가 실패한다.ENV docker build로 이미지 빌드시 빌더, 컨테이너로 보내줄 수 있는 variable를 보내준다. FROM busyboxENV user=rootARG user1ARG buildno ARG와 유사하다. ARG 사용 시 build 명령어를 통해 해당 변수를 추가로 받을 수도 있다. ${env_name:-value} -&amp;gt; 없을 시 value ${env_name:+value} -&amp;gt; 있을 시 valueWORKDIR: 명령어를 실행할 컨테이너 내부의 디렉터리. 멱등하기 때문에 여러번 입력하면 모두 반영된다. (cd와 같다.)EXPOSE: 노출 할 컨테이너의 port. run 하는 시점에 호스트와 바인딩해줘야 접근 가능하다.COPYCOPY [--chown=&amp;lt;user&amp;gt;:&amp;lt;group&amp;gt;] &amp;lt;src&amp;gt;... &amp;lt;dest&amp;gt;COPY [--chown=&amp;lt;user&amp;gt;:&amp;lt;group&amp;gt;] [&quot;&amp;lt;src&amp;gt;&quot;,... &quot;&amp;lt;dest&amp;gt;&quot;] 여기서 src는 호스트의 빌드 컨택스트(Dockerfile이 위치한 디렉터리), dest는 컨테이너의 file system 위 예시처럼 다수의 파일도 복사 가능Add: Copy와 비슷하게 사용. .tar나 네트워크 상의 경로도 추가 가능하다. 필요한 경우가 아니라면 로컬 컨텍스트의 명확히 특정 파일을 받을 수 있는 COPY 사용이 권장된다.CMD 이미지를 컨테이너로 띄우는 시점에 실행할 커맨드. run 시점에 또다른 CMD를 입력하면 Dockerfile의 커맨드는 덮어씌워진다.ENTRYPOINT: CMD와 유사하다. ENTRYPOINT는 커맨드를 인자로 받아 사용할 수 있는 스크립트 역할을 할 수 있다. ENTRYPOINT가 있으면 CMD는 단지 entrypoint의 인자 역할만 한다.JSON 배열과 일반 형식의 차이점 일반 형식의 경우 CMD, ENTRYPOINT를 사용할 때 기본적으로 /bin/sh -c가 앞에 추가된다. /bin/sh 사용을 하지 않으려면 JSON 배열 형태로 옵션을 부여해야한다.Reference)시작하세요! 도커 / 쿠버네티스https://docs.docker.com/engine/reference/builder/#fromhttps://spring.io/guides/gs/spring-boot-docker/" }, { "title": "메인 컨테이너 종료 시 사이드카 컨테이너 종료하기", "url": "/posts/%EB%A9%94%EC%9D%B8_%EC%BB%A8%ED%85%8C%EC%9D%B4%EB%84%88_%EC%A2%85%EB%A3%8C%EC%8B%9C_%EC%82%AC%EC%9D%B4%EB%93%9C%EC%B9%B4_%EC%BB%A8%ED%85%8C%EC%9D%B4%EB%84%88_%EC%A2%85%EB%A3%8C%ED%95%98%EA%B8%B0/", "categories": "Study, Kubernetes", "tags": "kubernetes, 쿠버네티스", "date": "2022-07-27 00:00:00 +0900", "snippet": ": 파드 내 메인 컨테이너가 종료하는 경우 사이드카도 종료할 수 있도록 Lifecycle을 맞춰주는 방법 파드에 멀티 컨테이너를 띄우는 경우, 메인 컨테이너가 종료되면 sidecar 또한 더이상 필요 없어지는 경우가 있다.(보통 로그용 컨테이너) 특히나 cronjob의 경우, 사이드카가 종료되지 않으면 job이 completed 되지 않고 not ready 상태에 머무르게 된다. 이 경우 해당 cronjob은 성공했다 할지라도, 다음 cronjob이 실행되지 않게된다. 파드에서는 두 컨테이너 모두 그냥 컨테이너일 뿐이라 별도의 방법이 없는 듯하다.Volume을 통해 상태체크: 파드 내 공유 볼륨을 두고, 폴링 방식으로 상태를 체크하기main container ... - name: main-container image: ... command: [ &quot;/bin/sh&quot;, &quot;-c&quot; ] args: - | sh run.sh # Do something main container should do ... touch /status/completed # Add completed status volumeMounts: - mountPath: /status name: main-container-statussidecar container ... - name: sidecar-container image: ... command: [ &quot;/bin/sh&quot;, &quot;-c&quot; ] args: - | while ! test -f /status/completed; do echo &#39;Waiting for the main container completed&#39; sleep 10 done # Polling volume /status/ echo &#39;Main container completed&#39; exit 0 volumeMounts: - mountPath: /status name: main-container-status readOnly: truevolume ... volumes: - name: main-container-status emptyDir: { } # Use volume emptyDirTrouble shooting shell이 사용가능한 이미지여야 한다. shell이 지원되지 않는 이미지인데 이 작업을 위해 debug 이미지를 사용하기에는 이미지 크기도 너무크고 다른 방법이 없을지 고려해보는게 좋을 것 같다. 해당 이미지에 기본 command가 존재하는지를 파악해야한다. 컨테이너가 기본적으로 수행하는 커맨드를 오버라이드하면 의도와는 다른 동작을 하게된다.Reference)https://stackoverflow.com/questions/59777620/how-can-i-allow-a-sidecar-container-to-terminate-within-a-kubernetes-deploymen" }, { "title": "시작하세요! 도커 / 쿠버네티스 2장 도커 엔진 - 2. 도커 이미지", "url": "/posts/%EC%8B%9C%EC%9E%91%ED%95%98%EC%84%B8%EC%9A%94_%EB%8F%84%EC%BB%A4_%EC%BF%A0%EB%B2%84%EB%84%A4%ED%8B%B0%EC%8A%A4_2%EC%9E%A5_%EB%8F%84%EC%BB%A4_%EC%97%94%EC%A7%84_2_%EB%8F%84%EC%BB%A4_%EC%9D%B4%EB%AF%B8%EC%A7%80/", "categories": "Study, Docker", "tags": "docker, 도커", "date": "2022-07-25 00:00:00 +0900", "snippet": ": 모든 도커 컨테이너는 읽기전용인 도커 이미지를 기반으로 생성된다. run, create, pull 명령어를 수행하면 가장 먼저 호스트 머신에서 해당 이미지를 찾고, 없으면 도커 허브에서 검색한 뒤 내려받는다. docker search {image} 로 검색도 가능하다. 누구나 배포할 수 있다. 이미지 중에서도 docker official image 딱지가 붙은 공식 이미지를 사용하는게 웬만하면 좋다. 도커 허브 이미지는 docker.io/ubuntu와 같이 prefix가 붙는다. 필요한 경우 컨테이너 형태로 사설 레지스트리를 내부에 띄워놓고, 사내망에서 사용하는 이미지들을 배포 및 관리 할 수 있다. 생성: 실행중인 컨테이너를 commit하거나 Dockerfile을 빌드하면 이미지로 만들 수 있다. 커밋의 경우 컨테이너 내에서의 작업 내용이 유지된다.이미지 구조 inspect 명령어의 Layers 항목을 보면 각 이미지의 레이어들을 볼 수 있다. git에서 각 커밋들간의 diff를 저장하는 것과 유사한 개념으로, 도커에서 commit을 통해 생성한 이미지는 변경된 layer(diff) 하나만 다르다. 이미지를 삭제하면 Untagged, Deleted 등의 로그가 찍히는데 전자는 이미지의 이름을 삭제한 것이고(이 때 이미지 이름이 &amp;lt;none&amp;gt;이 된다 -&amp;gt; 댕글링 이미지), 후자는 이미지 레이어가 실제로 삭제됨을 뜻한다.이미지 추출과 배포 추출: 이미지를 .tar 와 같은 형태의 파일로 추출하는 방법 save, load 커맨드를 통해 컨테이너 메타데이터를 포함한 파일로 추출, 로드가 가능하고, export, import 커맨드를 통해 컨테이너 파일시스템을 그대로 추출, 로드한다. 이미지 레이어 구조가 아닌 단일파일 배포이기 때문에, 여러 버전의 이미지를 추출하면 불필요하게 중복된 이미지 용량을 차지한다. 배포: push와 pull을 이용하는 방법. -&amp;gt; 효율적 도커 허브를 이용하기: 도커 허브에 가입해 repository를 생성한 뒤 배포 사설 레지스트리 이용하기 사설 레지스트리 배포 registry 이미지를 받아, 내부망에 먼저 배포해야한다. 레지스트리 컨테이너는 기본적으로 도커 볼륨을 사용하도록 설정 되어있다. 도커 데몬은 기본적으로 https를 사용하지 않는 레지스트리 컨테이너에 접근하지 않도록 한다. 인증서를 사는 방법 외에도 해결 방법이 있다. --insecure-registry 옵션을 사용해 http 레지스트리 컨테이너에 접근을 허용한다. nginx 서버를 두는 방법 - 자체 인증서를 발급해 TLS를 적용하는 방법 레지스트리 컨테이너의 ip로 인증서를 생성한다. 해당 컨테이너를 바라볼 nginx에 crt, key config를 적용한다. 각 사용자들(외부)은 nginx와 통신하고, nginx는 외부에 노출되지 않는 레지스트리 컨테이너와 통신한다. 인터페이스가 없기 때문에 rest api를 어느정도 익혀야 사용이 편리하다. Reference)시작하세요! 도커 / 쿠버네티스" }, { "title": "시작하세요! 도커 / 쿠버네티스 2장 도커 엔진 - 1. 도커 컨테이너", "url": "/posts/%EC%8B%9C%EC%9E%91%ED%95%98%EC%84%B8%EC%9A%94_%EB%8F%84%EC%BB%A4_%EC%BF%A0%EB%B2%84%EB%84%A4%ED%8B%B0%EC%8A%A4_2%EC%9E%A5_%EB%8F%84%EC%BB%A4_%EC%97%94%EC%A7%84_1_%EB%8F%84%EC%BB%A4_%EC%BB%A8%ED%85%8C%EC%9D%B4%EB%84%88/", "categories": "Study, Docker", "tags": "docker, 도커", "date": "2022-07-24 00:00:00 +0900", "snippet": "도커 이미지와 컨테이너: 가장 기본 단위이자, 도커 엔진의 핵심 두가지. 이미지: 여러 계층으로 된 바이너리이며 읽기 전용으로 불변이다. {저장소이름}/{이미지이름}/{태그} 형태 컨테이너: 이미지를 실행한 형태. 이미지의 종류에 따라 알맞은 설정과 파일을 갖는다.도커 컨테이너: 도커 이미지 위에 얇은 컨테이너 레이어를 생성하면서 인스턴스가 된다. docker run을 통해 컨테이너를 생성하고 실행한다. -i (상호입출력), -t (tty 활성화) 옵션을 주면 생성과 동시에 컨테이너 내부로 들어간다. (== attach 명령어) run = create + start 명령어 끝에 COMMAND를 입력할 수 있다. 이 경우 이미지에 내장된 커멘드를 덮어쓴다. 우분투 이미지에 echo ~~ 커맨드를 주면, 내장 커맨드인 /bin/bash를 덮어쓰기 때문에 커맨드를 실행하고 컨테이너가 종료되는 모습을 볼 수 있다. -p: 포트를 지정한다. 옵션을 통해 포트바인딩이 가능하다. 예를 들어, -p 80:8080 과 같은형태는 80의 호스트 포트와 컨테이너 내부의 8080포트를 바인딩한다. -d : detached 모드로 컨테이너 실행 -&amp;gt; 이 경우 별도의 사용자 입력 없이 컨테이너 내의 프로그램이 포그라운드로 실행된다. 따라서, 별도의 포그라운드 프로그램이 없으면 컨테이너는 종료된다. 우분투 컨테이너에서 exit으로 컨테이너를 나가면 포그라운드이던 /bin/bash 가 종료되므로 컨테이너가 종료되는 것. mysql을 attached 모드로 실행하면 포그라운드로 동작하는 로그를 확인할 수 있다. 이 때 exit으로 빠져나와도 포그라운드 프로그램이 존재하기 때문에 컨테이너는 유지된다. --link: 다른 서비스에 서비스명만으로 접근할 수 있다. ps, stop, rm 등등 다양한 명령어와 옵션을 익혀야한다. 도커의 철학: 한 컨테이너당 한 프로세스. 컴포넌트간 독립성을 유지할 수 있고, 버전관리와 모듈화가 용이해진다.tty? 텔레타입 라이터: 과거의 전신기. 메시지 타이핑을 통한 입력장치로 사용되었는데, 이러한 유래로 현대에서도 일반적으로 Unix 체계에서의 터미널을 의미. 터미널에서 tty를 입력하면 현재 커널과 연결된 가상 터미널장치를 확인 가능하다. 탭이나 화면을 분리해서 tty를 입력해보면 각각이 다른 터미널 장치와 연결되는 것을 볼 수 있다.foreground, background: 앞과 뒤에서 실행되는 프로세스들. 터미널에서 vi를 실행하거나 htop 을 통해 모니터링을 하다가 ctrl + z를 누르면 해당 프로세스들을 백그라운드로 보내고 포그라운드(터미널)로 돌아간다. 이 때 fg 를 통해 다시 가장 최근의 백그라운드 프로세스를 포그라운드로 불러올 수 있고, jobs를 통해 목록을 확인 할 수 있다.도커 볼륨: stateful한 컨테이너는 종료되면 내부의 변경 사항들 또한 유실되는데, 이 변경 사항들을 유지하기 위해 볼륨을 사용한다. 따라서 컨테이너는 stateless한 컨테이너가 된다. 호스트 볼륨 공유: {호스트의 공유 디렉터리}:{컨테이너의 공유 디렉터리}의 형태로 볼륨을 맵핑해준다. e.g. /home/wordpress_db:/var/lib/mysql로 볼륨을 지정해주면 컨테이너 종료 후에도, 컨테이너의 /var/lib/mysql 디렉터리 변경사항이 호스트의 /home/wordpress_db에 반영되어있다. 마운트: 경로가 겹친다면 호스트의 디렉터리를 컨테이너의 디렉터리에 덮어씌운다. 볼륨 컨테이너: --volumes-from 옵션을 설정하면 이미 -v 옵션이 설정되어있는 다른 컨테이너의 볼륨을 공유받을 수 있다. 도커 볼륨: docker volume 명령을 사용해, 도커 엔진이 볼륨을 관리하도록 한다. {볼륨 이름}/{컨테이너의 공유 디렉터리} 형태로 볼륨을 맵핑해준다. 호스트 머신의 특정 경로 (/var/lib/docker/volumes) 경로에서 확인 가능하다. 이 경로는 볼륨을 inspect해보면 알 수 있다. 도커 네트워크 외부에서 컨테이너와 통신하기 위해 도커 엔진은 컨테이너마다 veth(virtual eth 네트워크 인터페이스), docker0 브릿지를 호스트에 생성한다. 이 docker0를 이용하거나 네트워크 드라이버를 이용하면 된다. 컨테이너 내부에서 ifconfig 를 입력해보면 eth0(외부와 통신할 수 있는 네트워크 인터페이스), lo 네트워크 인터페이스를 확인할 수 있다. docker0 브리지 네트워크는 172.17.0.x IP 대역을 차례대로 할당한다. 네트워크 드라이버: 브리지, 호스트, 논, 컨테이너브리지 기본적으로 컨테이너 생성 시 자동으로 연결되는docker0 브리지를 활용하도록 설정되어있다. docker network connect, disconnect를 통해 컨테이너에 수동적으로 붙이고 뗄 수 있다. --net-alias : 특정 호스트 이름에 여러 컨테이너를 붙인다. 이 때 RR 방식으로 각 컨테이너에 LB된다. --link 옵션과 비슷하다. 내장 DNS 서버를 통해 가능하다. 호스트: 호스트의 네트워크환경 그대로 사용한다. 이 경우 컨테이너 내부의 애플리케이션을 별도 포트포워딩 없이 그대로 사용 가능하다.논: 외부와 연결이 단절된다.컨테이너 --net container:{container_id} 옵션을 통해 다른 컨테이너 네트워크 환경을 그대로 공유한다. 컨테이너 간 리눅스 네트워크 네임스페이스를 공유하도록 해 동일한 네트워크 환경을 갖게 되기 때문에 가능하다. k8s에서 파드 내 메인과 사이드카 컨테이너 간에도 리눅스 네임스페이스를 공유해, 별도 설정 없이 통신이 가능하다. 컨테이너 로깅 도커는 컨테이너의 stdOut과 stdErr를 별도 호스트 머신에 메타데이터 파일로 저장한다. docker logs 로 확인 가능하다. 컨테이너를 inspect해보면 LogPath를 확인 할 수 있다. 로그 수집을 위한 드라이버들이 존재한다. syslog: 로그를 보낼 서버에 rsyslog 컨테이너를 띄워 내부의 설정을 해둔 뒤, 클라이언트 호스트에서 syslog로 보내는 방법이 가능하다. fluentd: JSON 포맷을 지원하며, AWS S3, HDFS, Mongodb 등 다양한 저장소에 저장할 수 있는 오픈소스 도구이다. conf로 fluentd 설정을 해야한다. match를 통해 태그별로 설정을 다르게 가져갈 수 있다. 자원 할당 제한 컨테이너를 inspect 해보면 Quota 등 리소스를 확인할 수 있다. 자원 할당 제한이란 메모리, CPU 등 리소스를 정해두어, 호스트에 문제가 발생하는 일이 없도록 한다. 컨테이너 내 ps aux 명령어를 통해 할당된 리소스 확인이 가능하다.Reference)시작하세요! 도커 / 쿠버네티스" }, { "title": "시작하세요! 도커 / 쿠버네티스 1장 - 도커란?", "url": "/posts/%EC%8B%9C%EC%9E%91%ED%95%98%EC%84%B8%EC%9A%94_%EB%8F%84%EC%BB%A4_%EC%BF%A0%EB%B2%84%EB%84%A4%ED%8B%B0%EC%8A%A4_1%EC%9E%A5_%EB%8F%84%EC%BB%A4%EB%9E%80/", "categories": "Study, Docker", "tags": "docker, 도커", "date": "2022-07-08 00:00:00 +0900", "snippet": ": 일반적으로 도커 엔진 혹은 도커 관련 모든 프로젝트를 의미한다.가상 머신과 도커 컨테이너기존의 방식 하이퍼바이저를 이용해 가상 머신에 운영체제를 설치해 사용하던 방식. 따라서 각 게스트 운영체제는 다른 게스트 운영체제와 완전히 독립된 공간과 시스템 자원을 할당받아 사용한다. (VMware, VirtualBox 등) 게스트 운영체제를 사용하기 위한 라이브러리, 커널을 포함해 이미지 크기가 크다는 단점이 있다.도커 컨테이너 리눅스 자체 기능인 chroot, 네임스페이스, cgroup을 사용해 프로세스 단위로 Resource(CPU, Disk, memory, network) 사용량을 제한하고, 호스트의 커널을 공유한다. 컨테이너 안에는 애플리케이션 구동에 필요한 라이브러리 및 실행파일만 존재한다. -&amp;gt; 기존에 비해 이미지 크기 작다.도커를 사용하는 이유 개발, 배포의 편리함: 격리된 공간을 사용하기 때문에 독립된 개발 환경을 보장받으며, 배포를 위해서는 도커 이미지만 공유하면 된다. 독립성과 확장성: 서비스가 복잡해지면서 모놀리스 -&amp;gt; MSA가 필요해지는데, 이 때 MSA 구조에서 여러 모듈이 독립된 형태로 구성되어 관리가 쉬워진다.도커 엔진 리눅스 운영체제 위에서 시스템 자원(커널)을 공유받으면서 실행된다. 따라서, 리눅스에서 도커를 사용하는 것이 가장 권장된다. 윈도우, Mac을 사용하기 위해선 Docker desktop을 사용해야 한다. 윈도우용 Docker desktop은 Hyper-V 가상화 기술을, Mac용 Docker desktop은 xhyve 기술을 이용한다. 이 때 Docker desktop에서 커널은 리눅스킷의 커널을 따르게 된다. 이 밖에, 실제 리눅스 환경과 동일하게 구성하기 위해서는 VMware 위에 리눅스를 구성한 뒤 docker를 사용하거나 ec2 위에서 사용하는 방법이 있다.Reference)시작하세요! 도커 / 쿠버네티스" }, { "title": "Homebrew 오류 제거", "url": "/posts/Homebrew_%EC%98%A4%EB%A5%98_%EC%A0%9C%EA%B1%B0/", "categories": "Study, Develop", "tags": "develop, mac_os", "date": "2022-04-28 00:00:00 +0900", "snippet": "문제 상황: 파이썬 필요 모듈 install 과정에서 아래와 같은 에러 발생~~~fatal error: &#39;Foundation/Foundation.h&#39; file not found#import &amp;lt;Foundation/Foundation.h&amp;gt;^~~~~~~~~~~~~~~~~~~~~~~~~해결: 주로 m1 관련 이슈이긴 했으나, Mac의 /Library/Developer/CommandLineTools 를 업데이트하라는 솔루션 발견 후 수행 brew doctor 을 통해 검사 brew update, brew upgrade --greedy, brew cleanup, brew autoremove 수행하고 해결 안되는 것은 제시된 방안대로 직접 해결 brew doctor 결과수행 후 side effect bundler 삭제되는 이슈: bundler는 실제로 사용하고 있던 건데 위의 과정에서 삭제된 것으로 보인다. gem install bundler 수행해 해결 키체인 없어지는 이슈: 깃 토큰 연결한 키체인이 없어짐 -&amp;gt; 다시 입력Reference)https://developer.apple.com/forums/thread/107785" }, { "title": "리팩터링 12장. 상속 다루기", "url": "/posts/%EB%A6%AC%ED%8C%A9%ED%84%B0%EB%A7%81-12%EC%9E%A5-%EC%83%81%EC%86%8D_%EB%8B%A4%EB%A3%A8%EA%B8%B0/", "categories": "Study, Develop", "tags": "develop, refactoring", "date": "2022-04-22 00:00:00 +0900", "snippet": ": 객체지향의 가장 중요한 요소 중 하나인 상속에 관련된 리팩터링들. 대부분의 경우 상속을 잘못 사용하기 쉽다.1. 메서드 올리기: 두 서브클래스의 메서드가 같은 일을 수행한다면 슈퍼클래스의 공통된 메서드로 올려 중복을 제거한다. 보통 함수 매개변수화(리터럴을 매개변수로 받기)를 수행한 후에 수행이 가능하기도 하다. 서브클래스의 필드가 필요한 상황이라면 먼저 필드 올리기를 수행한다. 두 메서드의 세부 내용이 다르다면 템플릿 메서드를 고려한다.2. 필드 올리기: 같은 역할을 수행하는 필드들을 슈퍼 클래스로 올려 중복을 제거한다.3. 생성자 본문 올리기: 생성자에서 공통된 부분을 슈퍼 클래스로 올려 중복을 제거한다. 만약 서브 클래스에서 값을 세팅한 후에 처리해야하는 중복 로직이라면 그 부분을 함수로 추출하고, 슈퍼 클래스로 올린다.4. 메서드 내리기: 특정 서브클래스 하나와만 관련된 메서드는 슈퍼클래스에서 서브클래스로 내린다. 어떤 서브클래스가 해당 메서드를 구현해야하는지 정확히 알아야 그 클래스에만 해당 메서드를 구현할 수 있다. 그렇지 않으면 다형성(모든 곳에 구현)으로 구현해야한다. 5. 필드 내리기: 특정 서브클래스에서만 사용되는 필드는 해당 서브클래스로 옮긴다.6. 타입 코드를 서브클래스로 바꾸기: 타입 코드 필드로 대상을 분류해야 할 경우가 있다. 그런데 이 대상들에게 타입을 통한 구분 이상의 것이 필요하다면 이 리팩터링을 수행하면 된다. 다형성이 필요한 경우 특정 타입에서만 필요한 필드나 메서드가 있는 경우7. 서브클래스 제거하기: 더이상 서브클래스가 서브클래스의 역할을 잘 수행하지 못한다고 판단되면 슈퍼클래스의 필드로 대체해 제거한다.8. 슈퍼클래스 추출하기: 비슷한 일을 수행하는 두 클래스가 보이면 비슷한 부분을 공통의 슈퍼 클래스로 옮긴다. 객체지향의 상속은 현실세계의 분류체계로도 힌트가 되지만, 그렇지만은 않은 공통 요소가 발견되었을 때도 상속이 적용되기도 한다.9. 계층 합치기: 상속 구조가 시간이 지나면서 슈퍼, 서브클래스간 큰 차이가 없다면 둘을 하나로 합친다.10. 서브클래스를 위임으로 바꾸기: 서브클래스를 위임클래스로 바꾸고, 슈퍼 클래스에서 전달하도록 리팩터링한다. 위임 = 조합 + 전달 상속보다는 조합을 사용하라 - 상속보다 조합이 권장되는 이유? C++ 과 다르게, Java, JavaScript에서는 다중상속이 불가능하다. 다시 말해, 하나의 속성을 기준으로 상속을 한다면 다른 속성에 대한 상속은 포기해야한다. e.g. ‘나이’를 기준으로 상속을 한다면 ‘직업’ 기준으로의 상속은 포기해야한다. 상속은 캡슐화를 깨트리기도 하고, 슈퍼클래스의 변경으로 의도치 않은 서브클래스 로직변경이 일어날 수 있다. 상속받지 않고 객체를 필드로 갖도록 하면, 실제 객체 구현체가 아니라 객체의 인터페이스를 갖도록 할 수 있다. 이렇게 하면 DI받고 싶은 실제 구현체를 필요에 따라 다르게 DI받을 수도 있다. e.g. 기존 클래스는Set, 전달 클래스는 ForwardingSet, 새로운 클래스는 InstrumentedSet public class InstrumentedSet&amp;lt;E&amp;gt; extends ForwardingSet&amp;lt;E&amp;gt; { private int addCount = 0; public InstrumentedSet(Set&amp;lt;E&amp;gt; s) { super(s); } @Override public boolean add(E e) { addCount++; return super.add(e); } @Override public boolean addAll (Collection&amp;lt;? extends E&amp;gt; c){ addCount += c.size(); return super.addAll(c); }} public class ForwardingSet&amp;lt;E&amp;gt; implements Set&amp;lt;E&amp;gt; { private final Set&amp;lt;E&amp;gt; s; public add(E e) { return s.add(e); } public addAll(Collection&amp;lt;? extends E&amp;gt; c) { return s.addAll(c); }} (조합) 전달 클래스 내부에서 기존 클래스가 새로운 클래스의 구성요소로 쓰인다. (전달) 서브클래스의 인스턴스 메서드 내에서 (전달)슈퍼 클래스의 메서드를 호출하여 인스턴스를 전달해 쓴다. 다시 말해, 슈퍼 클래스의 기능 일부를 빌려온다. (전달 메서드) 이 때 (전달)서브 클래스들의 메서드들은 전달 메서드가 된다. 11. 슈퍼클래스를 위임으로 바꾸기: 슈퍼클래스와의 상속관계를 끊고 서브클래스에 슈퍼 클래스 객체를 필드에 저장해두고 필요한 기능만 위임하도록 한다. 보통의 경우 서브 클래스는 슈퍼 클래스의 모든 기능을 사용해야하고, (리스코프 치환 원칙) 슈퍼 클래스가 사용되는 모든 곳을 서브 클래스로 치환해도 동작에 이상이 없어야한다. 위와 같은 경우라면, (혹은 제대로 된 상속관계여도) 슈퍼/서브 관계로 강하게 연결된 결합에선 슈퍼클래스의 변경으로 서브클래스의 메서드가 망가지는 경우가 있으므로 위임으로 바꾸면 좋다. 이 때 기존의 서브클래스들의 메소드들은 모두 전달 메소드로 수정해야한다는 번거로움이 있긴 하다. e.g. 자바의 stack // Beforepublic class Stack&amp;lt;E&amp;gt; extends Vector&amp;lt;E&amp;gt; { // ..} 자바의 Stack은 리스트를 상속받고 있는데, 리스트의 기능 중 스택에 적용되지 않는 것들이 많다. // Afterpublic class Stack&amp;lt;E&amp;gt; { Vector&amp;lt;E&amp;gt; v; // ..} 위와 같이 위임으로 리팩터링한다면 일부 필요한 기능만 가져가되, 결합관계를 끊어 낼 수 있을 것 같다. Reference)리팩터링 2판" }, { "title": "리팩터링 11장. API 리팩터링", "url": "/posts/%EB%A6%AC%ED%8C%A9%ED%84%B0%EB%A7%81-11%EC%9E%A5-API_%EB%A6%AC%ED%8C%A9%ED%84%B0%EB%A7%81/", "categories": "Study, Develop", "tags": "develop, refactoring", "date": "2022-04-19 00:00:00 +0900", "snippet": ": 모듈간 통신이나 함수간 호출에서 연결부 역할을 하는 것이 API이다. 인터페이스가 복잡할 때 이 장의 리팩터링을 적용하면 전반적인 API가 이해하기 쉬워진다.1. 질의 함수와 변경 함수 분리하기: 질의(값 반환)하는 부분과 상태를 변경하는 부분을 분리한다. side effect 없이 값 반환만 해주는 함수를 추구할수록 언제 호출해도 문제가 발생하지 않기 때문에 개발자가 신경써야하는 부분이 줄어든다. 명령-질의 분리 원칙: 질의 함수는 Side effect가 없어야 한다. 즉, 질의 함수와 변경 함수는 분리되어야 한다.2. 함수 매개변수화하기: 함수 로직이 같고 리터럴만 다르다면, 그 다른 값을 매개변수로 받아 공통된 함수 하나로 처리한다. 리팩터링 전과 후를 비교했을 때, 무엇이 더 이해하기에 명확한 코드인가를 기준으로 판단해야 할 것 같다. 만약 매개변수로 넘기는 값에 따라 로직이 달라진다면, 그 매개변수를 알고 있다가 로직에 적용하며 코드를 이해해야한다. 3. 플래그 인수 제거하기: 플래그 인수로 로직이 제어가 되는 구조라면 해당 함수를 어떻게 호출해야하는지 알기 어렵고, 전해지는 리터럴이 무슨 의미인지 명확하게 전달하기 어렵다. 플래그 인수가 둘 이상이라면 모든 조합의 함수를 만들기보다 플래그 인수를 써야할 수도 있다. 그런데, 이런 경우 함수의 역할이 너무 크지 않은지 고민을 해봐야한다.4. 객체 통째로 넘기기: 레코드의 값을 여러개 넘길바에 레코드 자체를 넘긴다. 장점: 함수가 필요로하는 데이터가 다양해져도 API는 바뀔 필요 없고, 매개변수가 짧아져서 함수가 이해하기 쉬워진다. 별도의 모듈이라 해당 레코드에 의존하지 않도록 해야한다면 그냥 데이터들을 전달해준다. 데이터 더미들을 전달해주는 공통 부분이 많다면, 데이터들을 하나의 객체로 만들어주고, 그 데이터들을 다루는 로직을 객체의 로직으로 바꾼다.5. 매개변수를 질의 함수로 바꾸기: 호출자가 값을 결정해 매개변수로 전달하는 대신 피호출자가 값을 결정하도록 하는 리팩터링 참조 투명성: 같은 값을 넣으면 항상 같은 결과를 반환한다. 함수 내부의 특정 표현식을 그 표현식의 결과로 치환해도 프로그램의 동작에는 영향이 없다. 이게 가능하려면 해당 함수 외부의 영향을 전혀 받지 않아야한다.순수함수: 함수 f(x)가 모든 x에 대해 참조에 투명하면 함수 f는 순수함수이다.6. 질의 함수를 매개변수로 바꾸기: 값을 결정하는 책임을 호출자가 갖고 피호출자에게 전달하도록 하는 리팩터링 (전역 변수) 만약 함수가 참조 투명성을 보장하지 못하거나 (의존 관계) 제거하기를 원하는 원소를 참조하는 경우, 호출자가 값을 결정하는 책임을 가지도록 한다. 이 리팩터링을 수행하면, 보통 해당 함수는 전보다 다루기 어려워지지만, 참조 투명하도록 메서드를 개선할 수 있다는 장점이 있다. -&amp;gt; 테스트도 용이해진다.매개변수 vs 질의 함수: “결합도를 풀어내되 매개변수를 복잡하게 하기 vs 수많은 결합을 유지하기’’ 에서 적절한 균형을 찾아야 하는 문제7. 세터 제거하기: 세터를 없애, 인스턴스 생성 시점 외에는 필드가 변경될 가능성을 아예 제거한다. 필요한 경우: 너무 세터를 남발하는 경우, 생성자를 활용하지 않고 생성 후에 세터들을 호출해 객체를 완성하는 경우8. 생성자를 팩터리 함수로 바꾸기 장점: 적절한 이름을 가질 수 있다. 서브 클래스를 반환할 수 있다. 꼭 생성자를 호출하지 않고 그냥 인스턴스를 반환할 수도 있다.9. 함수를 명령으로 바꾸기: 복잡한 함수를 위한 객체를 만들고, 그 객체의 메서드를 수행하도록 한다. 필드를 이용하고 메서드를 잘게 나누어 복잡한 로직을 이해하기 쉽게 만들 수 있다. 하나만의 메서드를 갖는 이 객체를 전달하고, 반환한다는 측면에서 일급함수의 특징을 어느정도 얻을 수도 있다.10. 명령을 함수로 바꾸기: 명령(객체)로 바꾼 함수는 분명 복잡도가 줄어든다는 장점이 있지만, 로직이 비교적 간단한 편이라면 굳이 함수를 객체로 만드는 것 자체가 오버엔지니어링일 수 있다. 이 때는 명령을 함수로 바꿔준다.11. 수정된 값 반환하기: 값을 새롭게 갱신하는 함수인 경우, 여러 곳에서 사용될 수 있는 값을 바꾸려 하지 말고, 수정된 값을 반환하도록 한다. 이렇게 하면, 해당 함수를 호출하는 호출부에서는 값이 새롭게 갱신될 것임을 개발자가 인지할 수 있다. 단 한번 갱신이 필요할만한 값들에 이 리팩터링이 유용하게 사용된다.12. 오류 코드를 예외로 바꾸기: 에러 코드를 일일이 코드로 검사해 처리하기보다는 에러 대신 예외를 throw해, 적절한 핸들러가 처리할때까지 콜스택을 타고 위로 올라가도록 한다. 이러한 종류의 예외는 프로그램의 정상 동작 범주에 들지 않는 에러 때에만 쓰여야 한다. 즉, 예외를 던지는 코드를 프로그램 종료 코드로 치환한다 하더라도 프로그램은 여전히 정상 동작 해야한다.13. 예외를 사전확인으로 바꾸기: 문제가 될 수 있는 부분을 함수 호출 전에 or 함수 내에서 검사해, 어느정도 예상이 가능한 예외를 로직으로 처리한다.Reference)리팩터링 2판" }, { "title": "리팩터링 10장. 조건부 로직 간소화", "url": "/posts/%EB%A6%AC%ED%8C%A9%ED%84%B0%EB%A7%81-10%EC%9E%A5-%EC%A1%B0%EA%B1%B4%EB%B6%80_%EB%A1%9C%EC%A7%81_%EA%B0%84%EC%86%8C%ED%99%94/", "categories": "Study, Develop", "tags": "develop, refactoring", "date": "2022-04-12 00:00:00 +0900", "snippet": ": 조건부 로직은 필연적인 요소이지만, 쉽게 프로그램을 복잡해보이게 만든다. 이 장의 리팩터링을 적용하면 이러한 로직들을 보다 이해하기 쉬운 코드로 바꿀 수 있다.1. 조건문 분해하기: 복잡한 조건절은 해당 코드의 목적이 무엇인지 파악하기 어렵게 만든다. 조건절과 작업들을 함수로 추출해주면 코드 의도가 확실히 전달된다.2. 조건식 통합하기: 같은 결과를 수행하는 조건절을 통합한다. 관련 코드를 모으면서 하려는 일이 명확해지고, 보통의 경우 함수 추출까지 이어지면서 의도를 파악하기 쉬운 코드가 된다. 같은 결과를 수행하면 || 로 묶일 가능성이 크고, if문 중첩이라면 &amp;amp;&amp;amp; 로 묶일 가능성이 크다. 논리연산자로 묶여 더 복잡해보인다면 이 때 함수추출을 고민한다.3. 중첩 조건문을 보호 구문으로 바꾸기: early-return의 형태로 바꾸기 정상 조건: if-else가 모두 정상인 형태. if, else 에 같은 무게를 두어 둘다 중요함을 나타낸다. 만약 이러한 경우인데 early return로 바꾸었을 때 중복 코드가 나오게 되는 경우가 있다. 그러한 경우 오히려 if-else코드가 명확할 것 같다. 비정상 조건: (보호 구문) 비정상인 경우 바로 함수에서 빠져나온다. 이 케이스에선 조건을 반대로 만들어 더 간결해지는 경우도 있다. 함수 진입점과 반환점이 하나여야한다?: 하나일 때 더욱 명확하다면 하나로, 그렇지 않다면 (e.g. 보호 구문의 경우) 더욱 명확하도록 early return 형태로 변경하는 것이 맞아보인다.4. 조건부 로직을 다형성으로 바꾸기: 클래스와 다형성 활용하기. 팩터리 함수를 정의해 적절한 서브클래스의 인스턴스를 반환해준다. 무조건적인 다형성 활용은 당연히 오버엔지니어링 일 수 있고, 핵심은 ‘공통 switch 로직이 중복으로 있는가?’ 인 것 같다. 특히, 해당 부분이 ‘다형성이 맞는가?’ 를 생각해야한다. 데이터만 다르고, 실제 동작 자체는 각각이 다를바가 없는 경우도 있다. 기본 동작을 슈퍼 클래스로, 변형 동작들을 서브클래스로 만드는 방법도 있다.5. 특이 케이스 추가하기: 특정 값을 확인한 후 같은 동작을 수행하는 코드를 객체로 위임하기. 특히, null check에서 같은 특이 케이스를 반환해야 하는 경우가 많다. 이 때 특이 케이스 객체를 통해 반환하도록 한다. (aka. 특이 케이스 패턴, 널 객체 패턴, ..)6. 어서션 추가하기: 항상 해당 조건이 참이라고 가정하는 조건부 문장. 만약 어서션에 걸린다면 개발자가 로직을 짰음을 알려준다. 다른 개발자에게 어떤 상태여야함을 알려주는 소통 도구가 되기도 한다. 테스트 코드: 어서션과 같은 역할을 한다. 따라서 테스트 코드가 존재한다면 어서션은 불필요할 수 있다.어서션(error)과 catch 어서션은 Error를 유발하기 때문에 제대로되지 않은 어서션은 위험할 수 있다. 자바에서는 exception을 확장한 Throwable만 catch가 가능하다. 따라서 어서션은 “어떠한 외부에 입력에 따라서도 유발되는 것이 아닌, 개발자의 실수로만 유발될 수 있는” 조건에 다는 것이 좋다.7. 제어 플래그를 탈출문으로 바꾸기: flag 역할을 하는 boolean 변수를 없애고 break, continue 를 통한 제어를 적극 활용한다.Reference)리팩터링 2판" }, { "title": "리팩터링 9장. 데이터 조직화", "url": "/posts/%EB%A6%AC%ED%8C%A9%ED%84%B0%EB%A7%81-09%EC%9E%A5-%EB%8D%B0%EC%9D%B4%ED%84%B0_%EC%A1%B0%EC%A7%81%ED%99%94/", "categories": "Study, Develop", "tags": "develop, refactoring", "date": "2022-04-11 00:00:00 +0900", "snippet": ": 데이터 구조에 집중한 리팩터링들.1. 변수 쪼개기: 한 변수는 하나의 역할만 수행하도록 한다. 한 변수에 두번 이상 대입이 이뤄진다면 해당 변수는 여러 가지 역할을 수행한다는 신호이다.2. 필드 이름 바꾸기 제일 중요한 부분. 무슨 데이터로 구성되는지를 보면 프로그램을 이해하는데 도움이 된다. 넓은 범위로 참조되고 있다면 1. 캡슐화를 이용하거나 2. 새로운 이름의 속성을 추가하고, 값을 복제해 하나둘씩 새로운 속성을 참조하도록 변경한다.3. 파생 변수를 질의 함수로 바꾸기: 사이드 이펙트가 많을 수 있는 가변 데이터를 최대한 없애거나 유효범위를 좁힌다.// Beforepublic String getFoo() { return this.foo;}public void setBar(String a) { this.bar = a; this.foo += this.bar;}// Afterpublic String getFoo() { return this.foo + this.bar;}public void setBar(String a) { this.bar = a;} foo 속성이 가변되는 범위를 줄임으로써 예상치 못한 사이드이펙트를 방지한다. 위의 상황에서는 getFoo() 호출 전에 항상 setBar() 호출이 선행되어야 한다는 전제조건이 있다. 이러한 전제조건은 개발자가 한눈에 파악하기 어려우며, 이러한 이유때문에 이 리팩터링은 대부분 필연적으로 테스트가 따라야한다.4. 참조를 값으로 바꾸기: 같은 인스턴스를 참조하던 것을 새로운 VO 인스턴스를 생성하도록 바꾸기 값 객체(VO)로 다룬다. 내부 객체 속성을 바꾸지 않고 새로운 객체로 생성하도록 하면 불변이라는 특징을 갖도록 할 수 있고, 사이드 이펙트를 줄일 수 있다. 분산 시스템, 동시성 시스템에서 유용하다. 5. 값을 참조로 바꾸기: 새로운 VO 인스턴스를 생성하던 것을 같은 인스턴스를 참조하도록 바꾸기 공유되는 데이터를 갱신할 일이 없다면 (싱글턴처럼) 같은 인스턴스를 참조하든 새롭게 생성하든 사실 문제는 없다. 후자의 경우 메모리 낭비가 있을 수 있지만, 그로 인해 문제가 되는 경우는 드물다. 공유되는 데이터를 갱신할 일이 있다면, 참조로 바꿔 여러 클라이언트에서 공통으로 접근하도록 하는게 좋다. 휴먼 에러는 언제든 있을 수 있고 따라서 데이터 일관성은 언제든 깨질 수 있기 때문이다.6. 매직 리터럴 바꾸기 상수를 적극적으로 활용한다. 그런데, 상수로 변경함으로써 얻는 이득이 없다고 판단되면 그냥 raw data로 사용하는게 나을 수도 있다. 주로 비즈니스적인 숫자나 값들이 상수로 다뤄지면 좋을 것 같다. // badpublic static final int ONE = 1; // goodpublic static final int NAME_LENGTH_LOWERBOUND = 1; Reference)리팩터링 2판" }, { "title": "리팩터링 8장. 기능 이동", "url": "/posts/%EB%A6%AC%ED%8C%A9%ED%84%B0%EB%A7%81-08%EC%9E%A5-%EA%B8%B0%EB%8A%A5_%EC%9D%B4%EB%8F%99/", "categories": "Study, Develop", "tags": "develop, refactoring", "date": "2022-04-02 00:00:00 +0900", "snippet": ": 어떠한 요소를 다른 컨텍스트(클래스, 모듈 혹은 코드 라인)로 옮기는 방식의 리팩터링.1. 함수 옮기기 모듈성을 높이기 위해 연관된 요소들끼리 묶는다. -&amp;gt; 모듈을 잘 분리하면 응집도가 높은 코드가 되고 캡슐화가 좋아진다. 프로그램 언어마다 모듈화 수단이 다르다. 자바의 경우 객체지향의 패러다임을 가지며, 따라서 핵심 모듈화 컨택스트 단위는 클래스이다. 리팩터링하고자하는 프로그램의 이해도가 높을수록 요소들을 잘 묶는 방법을 알 수 있다. 2. 필드 옮기기 데이터 구조가 주어진 문제에 적합하게 잘 설계되어있다면 보통 동작 코드는 단순하고 직관적인 코드가 된다. 데이터 구조는 곧 클래스의 필드들이기 때문에 각 클래스에는 필요한 필드들로 잘 구성되어있어야 한다. 그런데, 초기 설계에서 적절한 데이터 구조를 가져가도록 구성하는 것이 쉽지 않다. 객체지향이 어려운 이유 중 하나이며, 잘못됨을 깨달을 때 항상 수정을 해 개선해야한다.3. 문장을 함수로 옮기기: 특정 함수를 호출하는 부분 전후로 특정 코드가 항상 반복되는 경우, 해당 문장을 함수 내부로 옮길 수 있을지를 고민한다. 이 때는 해당 문장이 그 함수의 일부분이라는 확신이 있어야한다. 이렇게하면 수정이 필요할 때 해당 메서드만 고치면 된다.4. 문장을 호출한 곳으로 옮기기 초기에는 한 가지 일만 수행하던 함수가 둘 이상의 일을 수행하게 변할 수 있다. SRP가 깨지는 상황이 되며, 코드의 응집도는 낮아진다. 이 경우 문장을 호출한 곳으로 옮기는 리팩터링을 적용한다. 5. 인라인 코드를 함수 호출로 바꾸기 인라인 코드를 함수 호출로 바꾸면 네이밍을 통해 해당 코드 호출의 목적을 보다 명확히 알 수 있다. 수정이 필요할 때 함수 한군데만 수정하면 된다. 이 때 모든 호출부가 수정된 코드를 원하는지를 확인해야하지만 보통은 그런 경우가 많지 않다. 만약 그런 경우라면 함수의 목적이 원래의 인라인 코드와 목적이 다른 경우이다. (우발적 중복) 이 때라면 별도의 함수로 두고 네이밍을 다르게 두는게 맞아보인다.6. 문장 슬라이드하기: 주로 다른 리팩터링의 준비단계로, 관련 코드를 한군데로 모으는 작업이다. 주의해야 할 점은 side effect가 존재하는 코드는 좀더 주의를 기울이고, 꼭 테스트를 하면서 리팩터링을 해야한다.7. 반복문 쪼개기 한 반복문 내에서 두가지 일을 수행한다면 해당 함수는 서로 다른 일들이 수행되고 있을 확률이 높다. 대개 반복문을 쪼개고 난 시점에는 함수 추출하기를 수행할 수 있고, 그 후 파이프라인으로 바꾸기를 수행할 수 있다. 최적화에 대한 고민 : 대부분의 경우 n번의 loop를 2 * n번으로 바꾼다고해서 성능이 달라지는 경우는 드물다. 리팩터링을 끝낸 후 벤치마크 테스트를 해 비교를해도 된다. 그 시점에 다시 합치는 것은 쉬운 일이다.8. 반복문을 파이프라인으로 바꾸기: filter, map 등의 연산을 통해 논리 흐름을 표현할 수 있어 코드를 이해하기에 좋아보인다. 또, 최근에는 많은 언어들이 함수형 프로그래밍을 지향하면서 Side effect를 줄이는 방식의 개발을 지향하는데, 그러한 측면에서도 가능하다면 최신의 방식을 택하는 것이 적합해보인다.9. 죽은 코드 제거하기: deprecated되고 해당 코드의 클라이언트가 없다는 확신이 있으면 과감히 지우면 된다. 혹시나 미래에 해당 코드가 필요하다면 형상관리 툴을 통해 히스토리를 보면 된다.Reference)리팩터링 2판" }, { "title": "리팩터링 7장. 캡슐화", "url": "/posts/%EB%A6%AC%ED%8C%A9%ED%84%B0%EB%A7%81-07%EC%9E%A5-%EC%BA%A1%EC%8A%90%ED%99%94/", "categories": "Study, Develop", "tags": "develop, refactoring", "date": "2022-03-20 00:00:00 +0900", "snippet": ": 캡슐화가 잘 되어있을수록 모듈 각각은 내부가 다른 모듈에게 노출되지 않는다. 이 때 캡슐화의 단위는 클래스, 모듈, 심지어 함수도 될 수가 있다. 이 장의 리팩터링을 적용하면 많은 경우 캡슐화를 개선할 수 있다.1. 레코드 캡슐화하기 무엇이 저장된 값이고, 무엇이 계산된 값인지 바깥에서 알 필요가 없고, 데이터를 더 의미있는 단위로 값을 제공해 줄 수 있게 된다. // beforeperson = { firstName: &quot;foo&quot;, lastName = &quot;bar&quot; }; // afterclass Person { // .. get name() { return this.firstName + &quot; &quot; + this.lastName; }} 2. 컬렉션 캡슐화하기 컬렉션 자체를 getter로 제공하기보다 각 요소에 대한 add~~(), remove~~() 를 제공해준다. 이렇게 하면 클라이언트가 실수로 컬렉션 (혹은 가변 데이터)를 바꿀 가능성을 줄일 수 있다. 그런다고 컬렉션을 제공하지 않도록하는 것은 여러모로 손해일 수 있다. 이러한 방법 중 하나로 읽기 전용을 제공하는 방법이 있다. (e.g) 복제 혹은 stream() 만 제공하는 방식) public Stream&amp;lt;Person&amp;gt; stream() { return this.persons.stream();} 코드 일관성: 보통 팀 규칙으로 이런걸 정할텐데, 새로운 팀원은 이러한 규칙을 파악하는데 어려움이 있을 수 있으니 일관성 있게 코드를 작성해야한다. 3. 기본형을 객체로 바꾸기 데이터를 표현하는 변수를 클래스화한다. 프로그램 몸집이 커질수록 더더욱 유용하게 된다. 저자는 단순 출력 이상의 기능이 필요해지는 순간 클래스화한다고 한다.4. 임시 변수를 질의 함수로 바꾸기 임시 변수를 함수로 추출해내면 많은 경우 불필요한 의존관계, 코드 중복을 줄일 수 있다. // Beforeconst name = this.firstName + &quot; &quot; + this.lastName; // Afterget name() { this.firstName + &quot; &quot; + this.lastName; } 이 때의 질의함수는 한번만 계산하고 그 뒤에는 읽는 역할만 해야한다. 변경이 발생했는데 재사용이 된다면, 어디서 변경이 일어났는지 알아내기 어려울 수 있다. 5. 클래스 추출하기 함께 변경되는 데이터 뭉치 끼리 분리하면서 클래스 몸집을 작게 유지한다.6. 클래스 인라인하기 클래스 역할이 줄어들어 더이상 필요 없을때 or 재배분하고 싶을 때 합쳤다가 다시 분리한다.7. 위임 숨기기 A 객체의 필드가 가리키는 B 객체의 메서드를 호출하려면 클라이언트는 B를 알아야한다. 해당 객체의 인터페이스가 바뀌면 이 것을 사용하는 모든 클라이언트의 코드가 바뀌어야한다. 객체간 결합도 측면: 객체간 결합도가 높다는 뜻. 보통 이러한 경우의 불필요한 결합도는 끊기 쉬운 경우가 많다. c.f) 롬복의 @Delegate 어노테이션을 사용하면 특정 메서드를 다른 클래스로 위임 할 수 있다 8. 중개자 제거하기 너무 디미터 법칙을 따르다보면, 어느새 클라이언트와 맡닿는 A 서버 객체가 위임의 역할만 수행하고 있을 수 있다. 그렇게 느낄때마다 제거한다. 보통 시스템이 바뀌면 ‘적절함’의 기준도 바뀐다. 그냥 지금 리팩터링이 필요하면 하면 된다. 9. 알고리즘 교체하기 복잡하거나 예전 방식의 알고리즘을 개선하기. 이 작업에 들어가기 전에, 교체하기 전의 알고리즘을 하나의 메서드로 나누는게 좋다. 거대한 알고리즘일수록 파악하고 교체하기가 어려우니, 간소화 작업은 필수인 것 같다.Reference)리팩터링 2판" }, { "title": "변수 네이밍", "url": "/posts/%EB%B3%80%EC%88%98_%EB%84%A4%EC%9D%B4%EB%B0%8D/", "categories": "Study, Develop", "tags": "develop", "date": "2022-03-15 00:00:00 +0900", "snippet": "고민?String name;int age;boolean isMale;List&amp;lt;String&amp;gt; names; // AList&amp;lt;String&amp;gt; nameList; // B 이름만 보고도 타입을 유추할 수 있는 변수가 있는가하면, 리스트의 경우 A, B 둘다 괜찮아보이긴 하다. 기존 코드가 B로 작성되어있다. 일관성을 지키는게 좋은가.헝가리안 표기법: 좋은 IDE가 제공되기 이전 시대에 변수, 함수 네이밍에서 데이터 타입을 접두사로 명시하는 코딩 규칙. lAccountNum : l을 통해 long 타입 명시 arru8NumberList : arru8을 통해 8비트 unsigned 배열 명시 (array of unsigned 8-bit integers) bReadLine(bPort,&amp;amp;arru8NumberList) : 바이트를 반환하는 함수 strName : 스트링 타입 명시헝가리안 표기법은 물리적인 타입뿐 아니라 변수의 목적도 드러낸다. rw : row us : 보안적으로 unsafe한 변수현대적인 네이밍: 아래의 이유로 굳이 옛날의 헝가리안 표기법처럼 변수, 함수명에 타입을 쓰지 않아도 된다는 의견이 많다. 언어가 발전하면서 현대에 사용되는 언어들은 타입 시스템이 굉장히 좋다. 좋은 IDE가 많다.결론 names와 같은 복수형에서는 리스트 or 배열인 경우가 많다. 일반적으로 복수형이라면 리스트라고 이해하는게 맞아보인다. set이나 map과 같은 자료구조가 사용된다면 그 때 더 구체적으로 네이밍해도 좋을 부분인 것 같다. 리팩토링 관점에서도 개발을 진행하면서 점진적인 리팩토링을 하는 것은 맞아보인다. 코드 일관성도 중요하지만 어차피 나중에 다 바꾸기로 합의가 된 부분이라면 새로 개발하는 코드에서는 불편해하지 말고 그냥 결정한대로 개발하는게 좋을 것 같다.Reference)https://en.wikipedia.org/wiki/Hungarian_notationhttps://stackoverflow.com/questions/10996681/good-name-for-a-list-variable-in-java" }, { "title": "리팩터링 6장. 기본적인 리팩터링", "url": "/posts/%EB%A6%AC%ED%8C%A9%ED%84%B0%EB%A7%81-06%EC%9E%A5-%EA%B8%B0%EB%B3%B8%EC%A0%81%EC%9D%B8_%EB%A6%AC%ED%8C%A9%ED%84%B0%EB%A7%81/", "categories": "Study, Develop", "tags": "develop, refactoring", "date": "2022-03-13 00:00:00 +0900", "snippet": ": 가장 기본적이고, 제일 많이 사용되는 리팩터링 기법들.1. 함수 추출하기 무슨 일을 하는지 파악이 어렵다고 판단된다면 함수로 추출하고, 무슨 일을 수행하는지 적절히 네이밍한다. 값을 변경하는 경우 값을 반환하도록 하거나 적절히 문장 슬라이드 등을 이용해본다. Call stack과 같은 성능적인 부분을 생각하지 않는다. 오히려 함수가 짧아질수록 캐싱이 더 쉬워져서 컴파일러가 최적화하는데 유리할 때가 많다고 한다.2. 함수 인라인하기: 함수 본문이 추출한 네이밍만큼 명확한 경우 그냥 인라인한다. 인라인이 불가능한지를 판단해보고 해야한다.(슈퍼 클래스의 경우 등)3. 변수 추출하기: (표현식에 이름을 붙인다) 표현식이 너무 복잡해 로직을 한번에 이해하기 어려운 경우 표현식을 변수로 추출해 쪼개면 관리하기도, 이해하기도 편해진다.4. 변수 인라인하기: 변수명이 원래의 표현식과 크게 다를바 없는 경우 인라인한다.5. 함수 선언 바꾸기 함수 네이밍, 시그니처 변경 등이 있다. 함수는 시스템의 구성 요소를 조립하는 연결부 역할을 한다. 함수를 잘 정의할수록 시스템 변경이 수월해진다. 간단한 절차: 함수 시그니처를 변경하고 사용하는 곳을 적절히 변경한다. 마이그레이션 절차: 변경하고자 하는 함수를 새롭게 정의하고 원래의 함수 내에서 새 함수를 호출하도록 구현한 뒤, 해당 함수를 인라인하는 과정으로 리팩터링 외부에서 사용되는 경우: versioning을 통해 하위호환을 지원한다. 새로운 버전의 함수를 만들고, 기존의 것을 deprecated 시킨 뒤 모든 클라이언트가 새 버전을 사용한다고 확신이 될 때 deprecated를 삭제한다.6. 변수 캡슐화하기 함수를 사용하면 데이터를 직접 다루기보다, 대체로 호출할 수 있게 된다. 데이터에 접근하는 하나의 통로로 더 데이터를 다루리가 쉬워진다. 캡슐화가 좋은 이유가 이런 이유이다. 데이터로 그냥 다루면 (특히 전역 데이터와 같이 데이터 유효범위가 넓은 경우) 해당 데이터를 참조하는 모든 부분을 신경써야한다.7. 변수 이름 바꾸기: 변수 이름은 항상 잘 지어야한다.8. 매개변수 객체 만들기: 일종의 DTO를 만드는 것. 데이터 항목 여러개가 항상 같이 붙어다니는 경우, 이 데이터들을 객체로 만들고 데이터에 공통으로 적용되는 동작들을 추출해 이 클래스의 메서드로 만들어주면 추상화 관점에서도 좋다.9. 여러 함수를 클래스로 묶기// Beforefunction foo1(bar) { // ..}function foo2(bar) { // ..}function foo3(bar) { // ..}// ----// Afterclass Foo { foo1() { // .. } foo2() { // .. } foo3() { // .. }} 해당 함수들이 공유하는 공통환경을 더 명확히 표현할 수 있고, 클래스와 관련한 연산들을 해당 클래스의 새로운 메서드로 뽑아낼 수도 있다.10. 여러 함수를 변환 함수로 묶기: 데이터를 전달받아 도출하는 로직을 변환 함수로 만들어둔다면 도출 로직의 중복을 줄일 수 있다. 단, 데이터가 변경되는 경우라면 클래스로 분리해주는게 좋다.11. 단계 쪼개기 두 대상을 다루는 모듈을 두가지 모듈로 나누어 한 모듈은 다른 모듈의 상세 내용을 기억하지 않아도 되도록 나눈다. 컴파일러는 컴파일을 하기 위해 텍스트 토큰화, 구문트리 만들기 등의 단계를 통해 실행 가능한 형태로 컴파일한다.Reference)리팩터링 2판" }, { "title": "리팩터링 4장. 테스트 구축하기", "url": "/posts/%EB%A6%AC%ED%8C%A9%ED%84%B0%EB%A7%81-04%EC%9E%A5-%ED%85%8C%EC%8A%A4%ED%8A%B8_%EA%B5%AC%EC%B6%95%ED%95%98%EA%B8%B0/", "categories": "Study, Develop", "tags": "develop, refactoring", "date": "2022-03-09 00:00:00 +0900", "snippet": "테스트의 가치(자가 테스트, 자동화 테스트): 직관만으로 테스트의 가치를 체감하긴 어렵다. 그러나, 컴파일때마다 테스트하는 것을 습관화하면 마지막 테스트 이후 현재 변경 부분에 대한 버그임을 명확하게 알 수 있고 결국 생산성이 향상된다. 핵심은 가장 작은 단위인 유닛 테스트이다. 아키텍처 평가 기준으로 Testability(테스트 용이성)를 활용하는 사례도 많다고 한다. 테스트하기 쉽게 만들수록 테스트를 잘 작성할 수 있게 되고, 이는 생산성과 직결되는 문제이기 때문인 것 같다.TDD란? (Test driven development) 테스트 - 코딩 - 리팩터링을 한 cycle로 개발하는 개발 방법. 처음에는 테스트를 모두 실패한다. 만들어놓은 테스트를 기반으로 코딩을 하고, 모든 테스트가 통과하는 시점이 개발이 완료되는 시점이다.테스트 작성 BDD의 given - when - then 패턴을 적극 활용하면 좋다. setup - exercise - verify 혹은 arrange - act - assert 라는 표현도 있다. 유닛 테스트 하나당 검증 하나정도로 작성하면 장점이 있다. 만약 한 유닛 테스트에서 5~6개 검증이 있다면 앞쪽 검증을 통과 못하면 뒷쪽 검증은 실행조차 못한다. 테스트 하나당 검증 하나로 작성하면 한번에 모든 실패 원인을 파악하기 편하다. Edge case를 생각해보고 그 부분을 집중적으로 테스트한다. 사실 이러한 케이스는 어떤 메서드 혹은 클래스의 겉보기 동작이 아니기 때문에 리팩터링 후에 edge case에 대한 동작이 변하는지는 크게 신경쓰지 않아도 된다고 한다.테스트 범위 단순히 커버리지를 올리겠다고 Getter, Setter나 UI, 영속성, 외부와의 통신부분까지 테스트할 필요는 없다. 핵심 비즈니스로직, 가장 우려가 되는 부분 등을 중점적으로 작성한다. 커버리지는 테스트가 되지 않은 영역을 찾는데 도움이 되고, 테스트 품질과는 크게 상관 없다. 완벽하게가 아니라 불완전하더라도 일단 핵심적인 부분만이라도 테스트하는 것이 훨씬 생산성 측면에서 이득이다.Fixture: 테스트에 필요한 객체나 데이터 각 유닛테스트끼리 상호작용하게 하는 공유 fixture를 작성하면 안된다. 이렇게 되면 테스트의 순서에 따라 결과가 달라지는 경우가 있다. 만약 공유 fixture가 필요한 상황이라면 immutable하게 만들거나 주의를 기울여서 fixture자체를 변경하지 않아야한다.Reference)리팩터링 2판" }, { "title": "리팩터링 3장. 코드에서 나는 악취", "url": "/posts/%EB%A6%AC%ED%8C%A9%ED%84%B0%EB%A7%81-03%EC%9E%A5-%EC%BD%94%EB%93%9C%EC%97%90%EC%84%9C_%EB%82%98%EB%8A%94_%EC%95%85%EC%B7%A8/", "categories": "Study, Develop", "tags": "develop, refactoring", "date": "2022-03-05 00:00:00 +0900", "snippet": "1. 기이한 이름: 가장 어려운 부분 중 하나. 네이밍이 좋을수록 세부내용을 볼 필요성이 줄어들 수 있다.2. 중복 코드: 같은 코드가 여러군데서 반복된다면 하나의 메서드로 추출할 수 있다. 이렇게 하면 항상 그 메서드는 일관된 동작을 할 것을 보장한다.3. 긴 함수 함수가 길수록 이해하기 어렵기 때문에 메서드 추출을 생각해야한다. 임시변수를 질의 함수로 만들거나 줄이고 문장을 슬라이드해 연관코드끼리 묶어버리면 추출이 더 쉬워진다. 초기에는 서브루틴을 호출하는 비용이 커서 한 함수에 몰아넣었다면 최근의 언어들은 이러한 비용이 없다시피한다. 잘 만들어진 코드일수록 코드가 잘 분리되어있다. 메서드 분리에는 항상 좋은 네이밍이 필요하다.4. 긴 매개변수 목록: 매개변수가 복잡할수록 코드 이해가 어렵다. DTO를 만들거나 객체를 통째로 넘기는게 더 이해하기 좋은 코드이다.// beforefoo(john.id, john.name, john.email);// afterfoo(john);5. 전역 데이터: 버그 발생 시 어디서 전역 데이터가 변경되는지 파악하기 어렵고 thread-safety도 고려해야한다. 꼭 전역적으로 다뤄야하고 mutable 해야 한다면, 캡슐화해 하나의 객체로 만들고, 접근 제어자를 적극 활용하는 방법이 있다.6. 가변 데이터 Immutability: 함수형 패러다임의 장점 중 하나로, side effect가 발생하지 않도록 불변하게 만드는 것은 큰 이점이 있다. 변수를 캡슐화하거나, 변경이 있는 코드를 따로 분리하고, setter 없애기, 변하는 값을 중첩 객체로 바꾸기 등의 작업을 통해 가변 데이터를 좀더 안전하게 만들 수 있다.7. 뒤엉킨 변경: 하나의 모듈이 서로 다른 이유로 변경되는 일이 많은 경우이다. 일반적으로 SRP를 지키지 않은 경우에 해당한다. 같은 맥락의 코드들로 모으고 모듈을 분리해 SRP를 지킬 수 있도록 리팩토링한다.8. 산탄총 수술: 뒤엉킨 변경의 반대. 같은 맥락의 코드들이 나뉘어져있어, 하나의 변경이 여러 클래스의 변경을 야기하는 경우에 해당한다. 이 경우 관련 코드끼리 뭉쳐야하는데, 하나의 모듈 크기가 커지는 것에 대해 거부감이 들더라도 두려워하지 않아야한다.9. 기능 편애: 모듈 내부와는 최대한으로 소통하고, 외부와는 최소한으로 소통해야한다. 모듈 내부보다 외부와 소통하는 것이 많다면, 해당 메서드의 위치를 다시 고민해봐야 한다.10. 데이터 뭉치 데이터 서너개가 여러 로직에서 항상 함께 사용되는 데이터들이 있다. 이 데이터들을 하나의 객체 내부의 중첩객체로 만들면 코드가 훨씬 간결해진다. 구분하는 방법은 “데이터들 중 하나를 없애도 가능한 데이터들인가?”를 고민해보면 된다.11. 기본형 집착: 의미있는 비즈니스 로직들을 기본형과 로직으로만 처리하지말고 객체로 만들어서 사용하는 것이 좋다.12. 반복되는 switch문: 단순히 switch문이 사용되었다고해서 무조건 다형성으로 바꿔야하는 것은 아니지만, switch가 여러군데서 사용된다면 고민해봐야한다. 왜냐하면 조건절이 하나 늘때마다 여러 switch를 모두 바꿔줘야하기 때문이다.13. 반복문: 일급 함수의 특징을 갖는 언어가 많아져 반복문을 stream으로 처리하는 것이 더욱 트렌드가 되었다. side effect 방지, 가독성 등 여러 장점이 있다.14. 성의 없는 요소: 메서드가 하나뿐인 클래스라던지, 본문 코드를 그대로 쓰는게 더 나은 함수 등등 역할이 거의 없는 함수나 클래스 등이 있다. 만들다보니 그렇게 된 경우도 있고 리팩토링하면서 역할이 줄어든 경우도 있다. 이 경우 그냥 합치는걸 고민해보면 된다.15. 추측성 일반화: 나중에 필요할 것이라고 추측해 만든 코드가 실제로 사용되지 않는 경우이다. 과감히 테스트 케이스를 날리고 죽은 코드를 제거하면 된다.16. 임시 필드: 특정 상황에서만 쓰이는 필드들을 클래스로 추출하거나 유효하지 않을 때를 위한 대안 클래스를 만든다.17. 메시지 체인: 기차 충돌이 발생하고 디미터 법칙이 깨진 코드이다. 캡슐화의 개념이 깨지게 되면 객체 내부구조가 밖으로 노출된다.객체 내부구조를 묻기보다 객체에게 메시지를 보내 무언가를 시켜라18. 중개자 제거하기: 메시지 체인과 반대로, 디미터 법칙을 너무 신봉하는 경우 중간에서 전달만 하는 중개자가 생기기 마련이다. 중개자를 없애고 직접 호출하도록 리팩토링한다.19. 내부자 거래 모듈 사이에 결합도가 증가하는 경우이다. 이 경우 한 모듈이 변경되면 다른 모듈에서도 변경이 발생할 확률이 높다. 해결: 여러 모듈의 공통 도메인을 제3의 모듈로 빼던가 디미터 법칙을 활용해 다른 모듈이 중간자 역할을 하도록 de-coupling한다.20 거대한 클래스 클래스 역할이 커질수록 필드가 커지고 중복 코드가 생길 가능성이 높다. 해결 접두어가 접미사가 같은 필드들끼리 추출한다. 클라이언트들이 거대 클래스를 이용하는 패턴을 파악해 단서를 얻을 수도 있다. 21. 서로 다른 인터페이스의 대안 클래스들: 클래스를 유연하게 교체할 수 있도록 만들기 위해 인터페이스화한다. 인터페이스를 일치시키기 위해서는 메서드 시그니처를 바꾸거나 함수 옮기기를 수행한다. 상속도 고민해본다.22. 데이터 클래스 데이터 클래스: 데이터 필드와 getter / setter로만 이루어진 클래스. Kotlin에서는 실제로 이러한 용도의 클래스가 구현되어있다. 아무 일도 수행하지 않는 데이터 클래스가 있다는 것은 필요한 동작이 엉뚱한 곳(클라이언트 코드)에 정의되어있다는 뜻일 수도 있다.23. 상속 포기: 부모 클래스로부터 일부만 상속받고싶어하는 경우가 있을 수 있다. 과감히 상속을 없애는 방안을 고민해봐야한다.24. 주석: 주석이 필요하단 생각이 들면 일단 메서드 추출이나 네이밍 변경을 고민해본다. 확실하지 않은 부분이나 앞으로 할 것들을 주석으로 달아놓으면 좋다.Reference)리팩터링 2판" }, { "title": "리팩터링 2장. 리팩터링 원칙", "url": "/posts/%EB%A6%AC%ED%8C%A9%ED%84%B0%EB%A7%81-02%EC%9E%A5-%EB%A6%AC%ED%8C%A9%ED%84%B0%EB%A7%81_%EC%9B%90%EC%B9%99/", "categories": "Study, Develop", "tags": "develop, refactoring", "date": "2022-03-02 00:00:00 +0900", "snippet": " 리팩터링이란 작업 전과 후가 같은 동작을 수행하도록하는 Restructuring의 특수한 하나의 형태이다.리팩터링을 하는 이유 (소프트웨어 설계) 규칙적인 리팩터링은 코드 구조를 지탱해준다. 중복 코드가 제거되고, 코드는 항상 고유한 일을 수행함을 보장할 수 있다. (가독성) 소프트웨어를 이해하기 쉬워진다. 내 코드의 의도를 더 명확히 드러내도록 개선할 수 있다. 버그를 쉽게 찾을 수 있다, 생산성 개선 등리팩터링 진행 준비를 위한 리팩터링: 코드베이스 변경 직전에 최선의 구조로 변경하는 리팩터링 이해를 위한 리팩터링: 레거시를 분석할 때 or 복잡한 로직을 이해할 때 깊은 수준까지 로직을 이해하는데 도움이 된다. 계획된 리팩터링과 수시로 하는 리팩터링리팩터링 작업 분리: 계획된 리팩터링과 수시로 하는 리팩터링을 수행하면서 팀에 맞는 방식을 도출해내기 작업 방식 차이: 계획된 리팩터링(커밋분리)를 통해 각 task 별 차이점을 인지하고 현재 어떤 작업에 초점을 두어야 할 지 확실히 할 수 있는 반면에 시간낭비일 수 있다. 수시로 하는 리팩터링은 생각날때마다 조금씩 변경을 줄 수 있다. (계획된 리팩터링) 형상 관리: 작은 단위의 리팩터링 작업을 통해 다른 사람이 히스토리를 명확히 알 수 있다.Extreme Programing(XP): CI(Continuous Integration) + 리팩토링(Test) XP: 통합(merge) 기간이 길어질수록 단위가 커지고, 많은 곳에서 리팩토링된 코드를 통합하는데 더 큰 어려움이 따른다. 이러한 측면에서 지속적 통합은 리팩토링과 연계되면 좋다. test: 리팩터링 대상의 동작이 일관되어야하고, 신뢰성을 위해서 test case가 필요. 테스트가 없는 경우, 안전하다고 검증된 몇 가지 리팩터링 기법만 사용하는 경우도 있다. (e.g. 자동 리팩토링) Reference)리팩터링 2판" }, { "title": "리팩터링 1장. 리팩터링 첫번째 예시", "url": "/posts/%EB%A6%AC%ED%8C%A9%ED%84%B0%EB%A7%81-01%EC%9E%A5-%EB%A6%AC%ED%8C%A9%ED%84%B0%EB%A7%81_%EC%B2%AB%EB%B2%88%EC%A7%B8%EC%98%88%EC%8B%9C/", "categories": "Study, Develop", "tags": "develop, refactoring", "date": "2022-02-22 00:00:00 +0900", "snippet": "리팩터링이란?: 겉으로 드러나는 기능은 그대로 두고, 내부 구조를 개선하는 것. 공학 설계의 관점에서 설계를 한 후 기능을 만드는 것이 일반적이지만, 리팩터링의 관점에서는 기능을 만든 후, 설계를 좋은 구조로 정리해 이해하기 쉽고 변화에 유연한 좋은 코드를 만드는 작업이다.코드 리팩터링을 위한 작업 테스트 작성: 신뢰성 측면에서, 이전과 같은 기능을 수행하는지 테스트를 통해 변경한 코드에 휴먼에러가 없는지 확인한다. 형상관리: 변경(리팩터링)때마다 커밋을 하면 변화를 추적하기 편하고, 혹시 모를 상황에 롤백 할 수 있다.다양한 리팩터링 방법: 기본적인 리팩터링 기법부터 캡슐화, 기능 이동, 다형성 등 다양한 방법이 있다. 각각의 사용법을 이해하고 사용했을 때의 장점을 생각해보고 적용하면 좋을 것 같다. 함수 추출하기, 함수 인라인하기(변수 선언 제거), 함수 선언 바꾸기(이름, 시그니처), 네이밍 더 명확하게 변경하기 함수 추출 인텔리제이 단축키: option + command + M 문장 슬라이드하기 (관련 코드를 한 곳으로 뭉치기), 함수 옮기기(모듈 관점), 단계 쪼개기(코드 분리) 등 관련 코드가 한 군데 모아져있으면 임시 변수를 질의 함수로 바꾸기가 수월해진다. 리팩터링 예시임시 변수를 질의 함수로 바꾸기 (변수를 함수화하기)// beforepublic void foo() { int total = prices[priceId] * amount;}// afterpublic void foo() { int total = Price.getTotal(priceId);}// -- Price.javapublic static void getTotal(int priceId) { return prices[priceId] * amount;} 지역변수를 객체의 메서드로 만들면 좋아질 때가 많다.조건부 로직을 다형성으로 바꾸기// Beforepublic void foo() { switch(Ticket.type) { // .. }}// Afterpublic interface LottoNumberGeneratable { List&amp;lt;LottoTicket&amp;gt; generate(int numberCount);}public class AutoLottoNumberGenerator implements LottoNumberGeneratable { @Override public List&amp;lt;LottoTicket&amp;gt; generate(int numberCount) { // .. }}public class ManualLottoNumberGenerator implements LottoNumberGeneratable { @Override public List&amp;lt;LottoTicket&amp;gt; generate(int numberCount) { // .. }}성능 저하와 리팩터링: 책에서는 일단 성능 저하를 고려하지 않고 리팩터링하는 것을 권장한다. 예시를 보니 그 과정에서 해결되는 경우도 더러 있고 실제로 성능차이는 미미해보인다. 성능이 중요한 곳이라면 리팩터링 후 성능차이를 분석해보고 성능을 높여나가는 방향이 좋을 것 같다. 시스템에 대해 잘 알더라도 대부분의 추측은 틀린 경우가 많을 것이기 때문에 프로파일링을 통해 정확한 성능 측정이 필요하다.책 예시의 성능저하 인라인 하기: 재사용이 있더라도 immutable한 변수인 경우에 인라인해 임시 변수를 없애는 것을 예시로 든다. 코드 슬라이딩: 관련 코드를 한군데로 뭉치기 위해 중첩문을 나누었을 때 수행되는 for loop 수가 증가함에도 코드를 슬라이딩하고, 결국 메서드 분리를 한다.Reference)리팩터링 2판" }, { "title": "환경별로 Spring 설정 구성하기 (on-profile)", "url": "/posts/%ED%99%98%EA%B2%BD%EB%B3%84%EB%A1%9C-spring-%EC%84%A4%EC%A0%95-%EA%B5%AC%EC%84%B1%ED%95%98%EA%B8%B0/", "categories": "Study, Spring boot", "tags": "spring boot, 스프링 환경설정", "date": "2022-01-19 00:00:00 +0900", "snippet": " 개발을 진행하다가 배포 때가 되면 아래와같이 dev, prod, local 등 다양한 환경을 구성하는 배포전략이 필요할 때가 온다. 일단 환경설정 구성을 위와같이 나누려면 (application.properties에서는) #--- 를 통해 구분해주고, on-profile 로 각각 네이밍을 해줘야한다. 주의할 점은 #--- 구분자를 위와같이 설정 line 바로 밑 line에 해줘야 인식한다. application.yml에서는 그냥 --- 공통 부분은 윗쪽으로 빼주고 프로필을 설정안하면 된다. 그냥 실행해보면 아무 설정도 먹지 않고 default로 실행된다. Intellij에서 default를 설정할 수 있다. config에 들어가서 아래와같이 값을 먹여줄 수 있다. 꼭 on-profile 관련된 것이 아니라도 *acrive -&amp;gt; active main에서 시스템 전체에 먹일 수도 있다. 이게 더 간단하고 좋아보인다. 일단 서로 다른 환경에서 일관성을 가질수가 있다. 터미널에서 실행하는 경우 아래와같이 CLI 옵션을 줄 수도 있다. " }, { "title": "자바의정석 - 14장 스트림", "url": "/posts/%EC%9E%90%EB%B0%94%EC%9D%98%EC%A0%95%EC%84%9D_14_%EC%8A%A4%ED%8A%B8%EB%A6%BC/", "categories": "Study, Java", "tags": "java, stream, functional programming, 함수형 프로그래밍, fp", "date": "2022-01-09 00:00:00 +0900", "snippet": ": 데이터 소스를 추상화하고 자주 사용되는 메서드들을 정의해 놓은 것특징 Side effect: 기존 데이터 소스를 변경하지 않는다. 따라서 stream을 사용하면 여러 스레드가 동시접근해도 임계영역 문제를 줄일 수 있다. 일회용: 한번 사용하면 스트림이 닫혀서 재사용 불가능하다. 필요하면 스트림을 다시 생성해야한다. 데이터 소스 추상화 : 데이터 소스가 무엇이던 같은 방식으로 다룰 수 있다. 원래같으면 List 정렬에는 Collections.sort(), Array 정렬에는 Arrays.sort() 사용해야한다. 지연 연산(lazy evaluation): 최종 연산이 수행되기 전까지는 중간 연산이 수행되지 않는다. 최종 연산이 수행되어야 비로소 스트림의 요소들이 중간 연산을 거쳐 최종 연산에서 소모된다. List&amp;lt;String&amp;gt; names = Arrays.asList(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;); lists.stream().map(name -&amp;gt; { System.out.println(name); // * return name.toUpperCase();}); 위 코드에서 map()이라는 중간 연산만 존재하고 최종 연산이 없기 때문에 * 출력문은 수행되지 않는다. 오토박싱 &amp;amp; 언박싱의 데이터 소스의 요소를 기본형으로 다루는 스트림 (IntStream, LongStream, DoubleStream)이 제공된다. 오토박싱과 언박싱: int -&amp;gt; Integer, Integer -&amp;gt; int 병렬 스트림: 스레드 병렬 처리를 지원한다. parralel() 로 병렬 처리, sequential()로 병렬 처리하지 않도록.스트림 생성 Collection.stream() , Stream.of(T... values) 과 같이 생성 기본형 스트림(박싱되어있는 스트림)이 일반 스트림보다 보편적으로 좋다. e.g) IntStream이 Stream&amp;lt;Int&amp;gt;보다 좋다. 해당 타입의 값으로 작업하는데 유용한 메서드들이 포함되어있다. 중간 연산인 mapTo() 를 통해 기본형 스트림으로 변경해준다. iterate(), generate(): 람다식을 매개변수로 받아, 이 람다식에 의해 계산되는 값들을 요소로하는 무한 스트림을 생성 Stream&amp;lt;Double&amp;gt; randomStream = Stream.generate(Math::random);Stream&amp;lt;Double&amp;gt; oneStream = Stream.generate(() -&amp;gt; 1)); IntStream evenStream = Stream.iterate(0, n -&amp;gt; n + 2); // A. 에러IntStream evenStream = Stream.iterate(0, n -&amp;gt; n + 2).mapToInt(Integer::valueOf);Stream&amp;lt;Integer&amp;gt; stream = evenStream.boxed(); // IntStream -&amp;gt; Stream&amp;lt;Integer&amp;gt; A : iterate(), generate() 에 의해 생성된 스트림을 기본형 스트림 타입의 참조변수로 다룰 수 없다. Optional 객체 생성: Optional.of() or Optional.ofNullable() 객체 값 가져오기: optionalObj.get(). Null이면 NPE 발생하기 때문에 orElse() 로 값 대체 or orThrow() isPresent() 를 통해 조건식 가능. ifPresent() 를 사용하면 더 간결하다. ifPresent()는 findAny(), findFirst() 같은 최종 연산과 잘 어울린다.중간 연산 연산 결과가 스트림이다. 스트림 자르기 (앞) skip(), (뒤) limit(), 요소 걸러내기 filter(), distinct(), 조회 peek(): 스트림 중간에 로그 찍기 용도 등. flatMap(): Stream&amp;lt;T[]&amp;gt; -&amp;gt; Stream&amp;lt;T&amp;gt;최종 연산 연산 결과가 스트림이 아니다. loop forEach(), 조건 검사 ~~~Match(), find~~~(), 통계나 연산count(), sum(), average(), max(), min() 등 리듀싱: reduce(). 스트림의 요소를 줄여나가면서 연산을 수행하고 최종 결과 반환한다. 매개변수 타입이 BinaryOperator&amp;lt;T&amp;gt;이다. 처음 두 요소를 가져와 연산을 수행하고 그 결과를 가지고 다음 요소와 연산한다. count(), sum(), max(), min()은 내부적으로 리듀싱을 사용한다. collect: 스트림의 요소를 수집하는 최종 연산. reducing과 유사하다.Collectors 메서드 스트림을 컬렉션, 배열로 변환: toList(), toSet() 등 통계: counting(), summingInt(), averaginInt(), maxBy(), minBy() 리듀싱: reducing() 문자열 결합: joining() 구분자, 접두사, 접미사 지정도 가능하다. 그룹화와 분할: groupingBy(), partitioningBy(). 이 두 가지가 collect() 가 필요한 가장 큰 이유이다. 둘은 분류를 Function으로 하느냐, Predicate로 하느냐의 차이만 있을 뿐 동일하다. groupingBy(): 특정 요소를 기준으로 그룹화. partitioningBy(): 지정된 조건에 일치하는 그룹과 아닌 그룹 두가지로 분할. Predicate를 매개변수로 받는다. 두 개의 그룹으로 나눠야 한다면 당연히 PartitioningBy()를 사용하는 것이 빠르다. stream.collect(summingInt(Foo::getNumber)); // -- 아래 두 방식은 동일한 결과 stream.map(Foo::getNumber).reduce(0, Integer::sum);stream.collect(reducing(0, Foo::getNumber, Integer::sum)); // --- 그룹화와 분할 예시 Map&amp;lt;Boolean, Long&amp;gt; stuNumBySex = stuStream .collect(partitioningBy(Student::isMale));Map&amp;lt;Integer, List&amp;lt;Student&amp;gt;&amp;gt; stuByClass = stuStream .collect(groupingBy(Student::getClass));Map&amp;lt;Integer, Map&amp;lt;Integer, List&amp;lt;Student&amp;gt;&amp;gt;&amp;gt; stuByGradeAndClass = stuStream .collect(groupingBy(Student::getGrade, groupingBy(Student:getClass) )); Collector 구현: “컬렉터를 작성한다” == “Collector 인터페이스를 구현한다.” supplier(), accumulator(), combiner(), finisher(), characteristics() 중 앞 네 개는 함수형 인터페이스이다. 따라서 해당 부분에 람다식을 작성하면 된다. 앞의 세 개 인터페이스는 reduce 인터페이스에서도 등장하는 개념이다. 따라서, 내부적으로 처리하는 과정이 리듀싱과 같다. 그룹화와 분할, 집계 등에 collector가 유용하게 쓰이고, 병렬화에 있어서도 collect()가 유리하다.Reference)자바의 정석 3판" }, { "title": "자바의정석 - 14장 람다식", "url": "/posts/%EC%9E%90%EB%B0%94%EC%9D%98%EC%A0%95%EC%84%9D_14_%EB%9E%8C%EB%8B%A4%EC%8B%9D/", "categories": "Study, Java", "tags": "java, lambda", "date": "2022-01-09 00:00:00 +0900", "snippet": ": 메서드를 하나의 식(expression)으로 표현한 것. 그래서 변수처럼 사용이 가능해진다. JEDK1.8에 추가된 문법. 자바에 함수형 패러다임을 갖도록 한 문법. 자바에서는 기본적으로 메서드를 만들려면 클래스를 만들고, 객체도 생성해야하는데, 이 모든 과정을 생략 가능하게 해준다.함수형 인터페이스: 람다식을 변수로 받을 수 있는 참조변수 @FunctionalInterface를 사용해 함수형 인터페이스임을 알린다. 단 하나의 abstract 메소드만을 가질 수 있다. 그래야 람다식과 인터페이스의 메서드가 1:1로 연결될 수 있기 때문이다. (default, static 제외) Comparator 내부를 확인해보면 디폴트 메소드를 제외하고는 compare 라는 메서드 하나 있다. (equals() 는 Object 클래스로부터 받은 것) @FunctionalInterfacepublic interface FooInterface { int plus(int a, int b);} // --- 아래와같이 사용 FooInterface f = (x, y) -&amp;gt; x + y; // Aint result = f.plus(5, 3); // BFooInterface f = new FooInterface() { @Override public int plus(int a, int b) { return 0; }}; A와 B는 같다. 함수형 인터페이스를 구현하는 public int~~ 부분을 람다식으로 줄여준 버전이 A 람다와 클로저: 코드를 실행하는 런타임은 자유변수를 “어떤 박스에 넣고 잠가서” 나중에 함수가 실제로 실행할 때, 사용할 수 있도록 만든다. 함수는 변수가 선언된 바깥 부분의 코드가 이미 실행되고 사라진 한참 후에 실행될지도 모른다. 그럼에도 불구하고 해당 변수의 당시의 상태를 기억하는 클로저의 성질 덕분에 람다에서 외부 변수 참조가 가능하다.java.util.function java.util.function 패키지에 일반적으로 쓰이는 형식의 메서드가 구현되어있으니, 매번 새롭게 정의하지 말고 이 패키지의 인터페이스를 활용할 것이 권장된다. 이 패키지에 존재하는 함수형 Interface들은 컬렉션 프레임워크에서 몇 메서드들의 매개변수로 받고있다.인터페이스들 Function&amp;lt;T, R&amp;gt; : apply() 메서드를 사용하는 가장 일반적인 함수. 매개변수 하나, 리턴값이 있다. Predicate&amp;lt;T&amp;gt; : test() 메서드 사용. boolean을 반환한다는 점이 Function과 다르다. 조건식을 람다식으로 표현하는데 꽤 많이 사용되는 편 Consumer&amp;lt;T&amp;gt;, BiConsumer&amp;lt;T, U&amp;gt; : accept() 메서드를 사용. 매개변수가 1 or 2개인 것이 다르다. 이름 그대로 사용하는 것이라서 반환값이 없다. Supplier&amp;lt;T&amp;gt; : get() 이름 그대로 공급자. consumer와 반대로 매개변수가 없고 반환값만 있다. UnaryOperator&amp;lt;T&amp;gt;, BinaryOperator&amp;lt;T&amp;gt; : 매개변수와 반환형이 일치 T -&amp;gt; T. Binary는 매개변수를 두개 받는다. 이외에도 DoubleToIntFunction, ToIntFunction&amp;lt;T&amp;gt; 등 지네릭이 아닌 기본형(래퍼클래스)을 다루는 Function 들도 존재한다.합성 수학에서 f(g(x)) 하는 것처럼, 함수형 인터페이스를 합성할 수 있다. Function&amp;lt;String, Integer&amp;gt; f = x -&amp;gt; 5;Function&amp;lt;Integer, String&amp;gt; g = x -&amp;gt; x.toString();Function&amp;lt;String, String&amp;gt; h = f.andThen(g); // g.compose(f) Predicate&amp;lt;Integer&amp;gt; p = i -&amp;gt; i &amp;gt; 100;Predicate&amp;lt;Integer&amp;gt; q = i -&amp;gt; i &amp;lt; 200;Predicate&amp;lt;Integer&amp;gt; r = i -&amp;gt; i % 2 == 0; Predicate&amp;lt;Integer&amp;gt; all = p.and(q.or(r)); 메서드 참조 (A::b): String::equals 과 같은 더 간결한 문법도 람다식에 해당한다. ‘클래스이름::메서드이름’ 혹은 ‘참조변수::메서드이름‘의 방식으로 가능하다 () -&amp;gt; new myClass();(a, b) -&amp;gt; new myClass(a, b); x -&amp;gt; new int[x]; // 위의 expression이 아래로 가능myClass::new; int[]::new; Reference)자바의 정석 3판자바 개발자를 위한 함수형 프로그래밍" }, { "title": "커밋의 상태와 .git", "url": "/posts/%EC%BB%A4%EB%B0%8B%EC%9D%98_%EC%83%81%ED%83%9C%EC%99%80_.git/", "categories": "Study, Git", "tags": "git, git파일, commit", "date": "2022-01-07 00:00:00 +0900", "snippet": "Commit: 커밋을 하는 것 == 파일 전체에 대한 것(스냅샷)을 저장한 것 .git/objects 에 저장된 모습을 보면 커밋들은 00, 01 .. hash값의 dir + 파일로 이루어져있다. 결국 파일 전체 하나(스냅샷)를 가리키는 것. 추후 gc로부터 하나의 델타로 변경된다. 하나의 브랜치 또한 하나의 커밋에 대한 참조. -&amp;gt; 수백개의 branch로 관리되어도 성능 저하되지 않는 이유 Git의 상태: 작업 디렉토리, 스테이지, head 커밋은 상황에 따라 위에 보여지는 하나의 같은 파일을 가리키게 된다. Clean한 상태: 작업 디렉토리 == 스테이지 == HEAD 커밋 Modified: 작업 디렉토리 != 스테이지 == 헤드커밋 add한 상태: 작업 디렉토리 == 스테이지 != 헤드커밋 커밋한 상태: Clean한 상태CLI로 확인 git ls-files --stage, git ls-tree HEAD 를 찍어보면, stage에 올라온 파일과 HEAD가 참조하는 파일이 같음을 확인할 수 있다..git/: git의 저장소, git으로 관리하는 커밋, 설정 등이 들어있다. log, remote 정보, branch 등의 참조가 있다. 이 config에서 수정해주면 git config --list 에서 보이는 설정들이 변경된다.Reference) Honux 라이브 강의" }, { "title": "자바의정석 - 12장 Generics", "url": "/posts/%EC%9E%90%EB%B0%94%EC%9D%98%EC%A0%95%EC%84%9D_12_Generics/", "categories": "Study, Java", "tags": "java, generics", "date": "2022-01-01 00:00:00 +0900", "snippet": " 객체의 타입을 컴파일 시에 체크해 같은 타입이라는 것만 보장하고, 타입 안정성을 높인다. 타입 체크와 형변환을 생략가능하게 한다. e.g) List에 타입을 명시하지 않으면 다양한 타입의 객체를 한 리스트에 담을 수 있는데, 이걸 하나로 제한한다. class Box { Object item; void setItem(Object item) { this.item = item; } Object getItem() { return item; }} // -- Generics class Box&amp;lt;T&amp;gt; { T item; void setItem(T item) { this.item = item }; T getItem() { return item; }} 타입 &amp;lt;T&amp;gt;, ArrayList&amp;lt;E&amp;gt;, Map&amp;lt;K, V&amp;gt; 등 다양한 타입 변수 네이밍을 사용한다. 컴파일 타임에 체크한다. 위의 예시에서 Box&amp;lt;String&amp;gt; b = new Box&amp;lt;String&amp;gt;(); 라고 선언하면, 타입 T가 컴파일시에 String으로 변환된다. static 멤버: 모든 객체에 대해 동일하게 동작해야한다. 따라서, static에는 지네릭스가 적용 불가능하다. 가능하면 Raw 타입을 사용하지 않고 지네릭을 사용한다. List -&amp;gt; List&amp;lt;Object&amp;gt; JDK 1.5부터 지네릭스가 도입되어, 지네릭스를 사용할 것을 권장하지만 일단은 하위 호환을 위해 raw 타입을 허용해 놓은 것. raw 타입을 사용하면 타입 안정성을 잃는다. 용어 Box&amp;lt;T&amp;gt; : Generic 클래스 “T Box” or “T의 Box” T: 타입 변수. String으로 선언하게 되면 “매개변수화 된 타입”이 된다. Box: 원시 타입, 로(Raw) 타입상속 관계의 GenericsBox&amp;lt;Fruit&amp;gt; appleBox = new Box&amp;lt;Apple&amp;gt;(); // 에러Box&amp;lt;Apple&amp;gt; appleBox = new FruitBox&amp;lt;Apple&amp;gt;(); // OK. 다형성List&amp;lt;String&amp;gt; list = new ArrayList&amp;lt;String&amp;gt;(); // OK. 다형성// ----void add(Apple apple) { } // 이와같은 메서드가 있을 때Box&amp;lt;Apple&amp;gt; appleBox = new Box&amp;lt;Apple&amp;gt;();appleBox.add(new Apple()); // OK.appleBox.add(new Grape()); // 에러. Apple 객체(혹은 자식 객체)만 추가 가능appleBox.add(new GreenApple()); // OK. 자식 객체라면 가능extends: 제한된 Generic 일반적인 지네릭스는 타입 안정성은 얻지만, 여전히 모든 타입이 가능하다. &amp;lt;T extends Fruit&amp;gt; 과 같은 선언을 통해 특정 타입의 (Fruit 타입의) 자손들까지만 대입할 수 있도록 제한할 수 있다. interface라도 implements 키워드 대신에 extends를 사용한다. 클래스 Fruit의 자손이면서 Eatable 인터페이스도 구현해야한다면 &amp;lt;T extends Fruit &amp;amp; Eatable&amp;gt; 와일드 카드 static 메서드에는 지네릭을 사용할 수 없는데, 그렇다고 여러 타입의 매개변수를 갖도록 재선언하는 것은 중복을 만든다. 따라서 아래와 같이 선언 static Applebox add(FruitBox&amp;lt;? extends Fruit&amp;gt; box) { // ..} &amp;lt;? extends T&amp;gt;: T와 그 자손들만 가능 &amp;lt;? super T&amp;gt;: T와 그 조상들만 가능 &amp;lt;?&amp;gt;: 모든 타입 가능. == &amp;lt;? extends Object&amp;gt; Generic 메서드: 메서드 한정 지역적 Generic 선언으로 복잡도를 낮춘다. 메서드 한정이므로 static 변수에도 사용 가능하다. 이펙티브 자바에서는 Generic 메소드가 사용이 가능한 부분이라면 무조건 이걸 사용하는 것을 권장한다. static void printAll(ArrayList&amp;lt;? extends Product&amp;gt; list, ArrayList&amp;lt;? extends Product&amp;gt; list2) { // ..} // 위의 내용을 지네릭 메서드로 변환하면 static &amp;lt;T extends Product&amp;gt; void printAll(ArrayList&amp;lt;T&amp;gt; list, ArrayList&amp;lt;T&amp;gt; list2) { // ..} Reference)자바의 정석 3판" }, { "title": "절차지향과 객체지향", "url": "/posts/%EC%A0%88%EC%B0%A8%EC%A7%80%ED%96%A5%EA%B3%BC_%EA%B0%9D%EC%B2%B4%EC%A7%80%ED%96%A5/", "categories": "Study, OOP", "tags": "oop, 객체지향", "date": "2021-12-20 00:00:00 +0900", "snippet": ": 비즈니스 로직을 처리하는 두가지 패턴 비교 (스프링 관점) view나 persistence layer를 이야기하는 것이 아니고, Domain layer를 구성하는 여러가지 방법론 중 절차지향과 객체지향에 관한 것정답이 정해져있는 것이 아니라 상황에 맞게 트레이드 오프를 따져야 하고, 변화에 더욱 초점을 두려면 객체지향적으로 리팩토링하는 절차가 필요하다.Transaction Script(function, logic 중심): 트랜잭션 단위로 스크립트를 작성하는 것. 절차지향적이다. 보통 이 방식은 ERD(데이터베이스)를 먼저 구성하기 마련이다. 이후, 자연스럽게 테이블과 클래스가 1:1로 맵핑되고, “DB에 무엇이 저장될 것인가?”의 관점으로 클래스의 프로퍼티가 구성된다. 중앙 집중식 제어 스타일: 한군데에서 모든 제어를 다 한다. 구현이 쉽고 단순해 읽기 편하고, 따라서 개발자들에게 익숙하다. 유지보수 측면에서 어려워질 수 있다.도메인 모델(비즈니스 객체 자체 중심): 객체지향 설계에 가깝다. CRC card - Candidate(객체), Responsibility(책임), Collaborator(협력). 종이 한장으로 표현하면 편하다. 기준이 없어 애매할 수 있다. 어떠한 책임이 누구에게 있는가?는 항상 모호한 기준일 수 있다. 위임식, 분산식 제어 스타일: 절차지향의 중앙집중식 제어 스타일과는 다르게 모든 것을 객체로 찢어놓는다. 오히려 읽기 어렵다. 그러나 유지보수에는 더 도움이 될 수 있다.Reference)객체지향의 사실과 오해 조영호님 강의" }, { "title": "자바의정석 - 09장 java.lang 패키지와 유용한 클래스", "url": "/posts/%EC%9E%90%EB%B0%94%EC%9D%98%EC%A0%95%EC%84%9D_09_java.lang_%ED%8C%A8%ED%82%A4%EC%A7%80_%EC%9C%A0%EC%9A%A9%ED%95%9C%ED%81%B4%EB%9E%98%EC%8A%A4/", "categories": "Study, Java", "tags": "java, java.lang", "date": "2021-12-20 00:00:00 +0900", "snippet": ": 자바 프로그래밍에 가장 기본이 되는 클래스들이 모여있는 패키지. 별도로 import하지 않아도 사용 가능하다. (e.g. String, System, ..)Object: 모든 클래스의 최고 조상 클래스 equals: 주소값으로 객체 비교. Object는 최고 조상 클래스이기 때문에 다른 class를 정의할 때 equals를 오버라이딩해 사용 가능 e.g. String class에서 문자열 내용만 같다면 같도록 오버라이딩 hashCode(): 해싱 기법에 사용되는 해시함수를 구현한 것. equals() 와 같은 결과를 가져가야 하기 때문에 이것 또한 오버라이딩 객체를 출력해보면 “클래스@해시코드”의 형태로 출력 finalize(): GC에 의해 소멸될 때 자동적으로 호출된다. notify(), notifyAll() : 객체 자신을 사용하려고 기다리는 쓰레드를 하나만 or 모두 깨운다. wait(): 다른 쓰레드가 noti하기까지 현재 쓰레드를 무한히 or 지정된시간(timeout)동안 기다리게 한다. clone(): 인스턴스 값 복제이기 때문에 참조타입의 인스턴스 변수가 있다면 복제한 인스턴스 변경이 원래 인스턴스에 영향을 줄 수 있다. 해당 클래스가 Clonable() 인터페이스를 구현해야 사용가능. 공변 반환타입을 사용하면 자식 타입으로 형변환 가능 얕은 복사 깊은 복사: 얕은 복사는 값만 복제해 객체는 공유하는 것, 깊은 복사는 객체까지 복제. public Circle deepCopy() { Object obj = null; try { obj = super.clone(); } catch () {} Circle c = (Circle)obj; // 값만 복제, Point 객체는 공유 c.p = new Point(this.p.x, this.p.y); // Point 인스턴스 새롭게 할당} getClass(): 클래스 객체 getter. -&amp;gt; class com.company.Foo 객체 얻어온다. 클래스당 하나만 존재 클래스로더에 의해 메모리에 올라갈 때 객체가 자동으로 생성 ```java// 세가지 방법Class cObj = new Card().getClass();Class cObj = Card.class;Class cObj = Class.forName(“Card”); String Immutable class. +와 같은 연산을 수행하면 기존걸 변경하는 것이 아니라 새로운 String 인스턴스를 생성한다. 문자열 리터럴: 컴파일 시 클래스 파일에 저장된다. String s = &quot;abc&quot;; // 문자열 리터럴 &quot;abc&quot;의 주소를 s 변수에 할당String s2 = new String(&quot;abc&quot;); // 새로운 String 인스턴스 생성 equals(): Object의 해당 함수를 오버라이딩. (==와는 다르다) join(), concat(), compareTo(), endsWith(), equalsIgnoreCase(), indexOf(), trim() 등 getBytes(): 인코딩 StringBuffer, StringBuilder immutable한 String과 다르게 미리 buffer 크기를 설정해놓고 그 크기 내에서는 변경이 가능하다. 버퍼 크기를 초과하면 새롭게 할당하는 방식 equals() 오버라이딩 X, toString() 오버라이딩 O(String으로 변환)StringBuilder: StringBuffer는 Thread safe하도록 동기화되어 있는데, 성능을 떨어트릴 수 있다. StringBuilder는 동기화를 제거한 버전이다. 멀티 스레드 환경에서는 상황에 맞게 개발자가 동기화를 해줘야한다.Math round() : 첫째자리에서 반올림해서 Long으로 돌려준다. ~~Exact() : 오버플로우 발생 시 ArithmeticException 발생Wrapper 클래스 기본형을 객체로 변환해주는 클래스. Integer, Boolean, Character, Byte, Short, Long, Float, Double 등 숫자 관련 wrapper들은 조상으로 Number를 갖는다. Integer.parseInt(), Boolean.parseBoolean() 등을 통해 문자열 -&amp;gt; 기본형으로 변환 Integer.valueOf(), Byte.valueOf() 등을 통해 문자열 -&amp;gt; 래퍼 클래스로 변환그 외 유용한 클래스Objects 기본적으로 모두 static 메소드 isNull vs requireNonNull 아래의 두 문장은 같은 일을 한다. if(Objects.isNull(obj)) throw NullPointException(&quot;Must not be null&quot;); // requireNonNull로 간단히 처리 가능 Objects.requireNonNull(obj, &quot;Must not be null&quot;); Objects.equals() -&amp;gt; 널체크까지 처리. 기존: if(a != null &amp;amp;&amp;amp; a.equals(b)) deepEquals(): 깊은 비교(다차원) 이외의 다양한 오버라이딩 기타 Random Math.Random() == new Random().nextDouble() Random으로 사용하면 seed값 설정 가능. 같은 seed로 난수생성시 항상 같다. Regex: 정규표현식 관련 Scanner: 화면, 파일, 문자열과 같은 입력 소스로부터 문자 데이터를 읽어오는 것 Scanner s = new Scanner(System.in);s.nextBoolean();s.nextLine();// 등등 여러가지 next~메소드 존재 StringTokenizer: 구분자로 파싱해 토큰들을 얻어냄 BigInteger: Int 배열을 사용해 long보다 큰 값을 다룰 수 있도록 Reference)자바의 정석 3판" }, { "title": "객체지향 개론 2. 설계", "url": "/posts/%EA%B0%9D%EC%B2%B4%EC%A7%80%ED%96%A5_%EA%B0%9C%EB%A1%A0_2_%EC%84%A4%EA%B3%84/", "categories": "Study, OOP", "tags": "oop, 객체지향", "date": "2021-12-19 00:00:00 +0900", "snippet": ": 객체지향적 설계란 응집도, 결합도, 캡슐화의 측면에서 변경이 쉽도록 짜는 것이다. 설계는 항상 두가지 사용자를 다 염두해야 한다. 기능을 사용하는 사람, 코드를 건드는 사람 설계의 트레이드오프 (절차지향) 심플하게 만들 것인가? (객체지향) 복잡하더라도 변경에 유연하게 만들 것인가? 객체지향적, 개발론적인 모든 원칙들은 변경에 관련된 것이다. e.g) SOLID 등 다양한 디자인 패턴의 목적은 변경을 감추는 것 변경하기 쉬운 설계: 1. 높은 응집도, 2. 낮은 결합도, 3. 캡슐화팁 TDD로 개발을 해보면, 메시지를 날리는 것을 중심적으로 설계하게 된다고 한다. TDD는 테스트방법이 아닌 설계방법. 프레임워크(바뀌지 않는 것) 코드를 잘 보면 객체지향이 잘 적용되어있다. e.g) 스프링응집도: 모듈(클래스) 내부 요소들이 서로 관련 있는 정도. 다르게 말하면, 응집도란 모듈 내부 요소들이 함께 변경되는 정도이다. 변경 관점에서 보아야 한다. 높은 응집도 - 모듈 전체가 동일한 이유로 변경된다. 변경될 이유가 하나여야 한다. -&amp;gt; SRP 만족. (SRP는 응집도에 대한 이야기) 낮은 응집도 - 모듈이 다양한 이유로 변경된다. -&amp;gt; 단적인 예로 merge 과정에서 conflict가 자주 발생한다.결합도: 한 모듈이 다른 모듈에 의존하는 정도. 다른 모듈에 대해 알고 있는 지식의 양 결합도가 강하다, 느슨하다로 표현 변경 관점에서 보아야한다. 느슨한 결합도: 구현(내부)이 변경될 때 함께 변경되지 않는다. 안정적인 추상화(자주 바뀌지 않는 것)에 의존 == 인터페이스에 의존 싱글턴: 하나의 오브젝트가 전역적으로 쓰이기 때문에 결합도가 높다. 구현과 추상화 구현과 추상화의 분리 구현 - 자주 변경되는 불안정한 부분. 자주 바뀌면 인터페이스라도 구현이다. 추상화 - 자주 변경되지 않는 안정적인 부분. 인터페이스를 구현했는데 이게 자주바뀌면 아무 의미없다. e.g) 한 클래스 내에선 다 구현이라고 할 수 있다. getter / setter로 전달해주는 것과 속성을 public으로 노출하는 것은 큰 차이 없다. 캡슐화: 인터페이스를 외부에 공개하고 자주 변하는 데이터를 인터페이스 뒤로 감춰놓는 것 상태와 행동을 하나로 묶어놓는 것 단순히 getter setter로 묶어놓는 것이 아니라 인터페이스로 노출한다는 관점 타입 캡슐화: 자주 변하는 객체의 타입을 추상화 뒤로 캡슐화 e.g) Movie의 입장에서 DiscountPolicy 타입이 숨겨진다. (AmountDiscount인지 PercentDiscount인지 숨겨진다.) DIP(의존성 역전 원칙) : 상위 모듈(Movie)과 하위 모듈(AmountDiscount과 PercentDiscount) 모두 추상화(DiscountPolicy)에 의존 컴포지트 디자인 패턴: 갯수가 변하는 것을 감춘다.(캡슐화) 객체지향 설계가 적합할 때?: 복잡성을 알고리즘에서 분리하고 객체 간의 관계로 만들 수 있다. 유효성 검사, 계산, 파생 등이 포함된 복잡하고 끊임없이 변하는 비즈니스 규칙을 구현해야 한다면 객체 모델을 사용해 비즈니스 규칙을 처리하는 것이 현명하다. - 마틴 파울러대부분 처음부터 객체지향적으로 잘 설계하는 것은 절대 불가능하다. 요구사항이 어떻게 변경될 지 모르기 때문이다. 리팩토링이 필수: 변경이 발생할 때마다 변경하기 쉬운 코드로 변경하는 것 일단 절차지향적으로 작성하고, 변경이 발생해 응집도가 낮아지고, 결합도가 높아지는 시점마다 객체지향적으로 바꾸기.Reference)객체지향의 사실과 오해 조영호님 강의" }, { "title": "객체지향 개론 1. 메시지", "url": "/posts/%EA%B0%9D%EC%B2%B4%EC%A7%80%ED%96%A5_%EA%B0%9C%EB%A1%A0_1_%EB%A9%94%EC%8B%9C%EC%A7%80/", "categories": "Study, OOP", "tags": "oop, 객체지향", "date": "2021-12-18 00:00:00 +0900", "snippet": ": 핵심 키워드는 메시지. 객체에게 메시지를 날려 무언가를 처리하기를 요구한다.객체지향적 관점이란?: 시스템을 객체들이 모여있는 덩어리로 시스템을 바라보는 관점. 함수형에서는 시스템을 함수의 집합체로 바라보고, 절차지향에서는 시스템을 프로세스와 데이터의 집합체로 바라본다. 객체지향에서는 객체들끼리 모여 시스템을 만들기 때문에, 객체는 다른 객체와 연결되어있다. (클래스 관점에서의 의존과는 다르다.)책임-주도 설계: 역할, 책임, 협력: 협력을 위한 문맥(애플리케이션 기능) 안에서 책임을 수행할 역할(객체) (추상화) 선택 객체에 할당할 책임이 설계를 주도하는 원칙 과정: 책임과 메시지를 선택(정의)하고, 책임에 적합한 역할(객체)를 찾는다. 메시지를 받은 객체는 그 메시지를 처리할 메서드를 구현하고, 메서드가 필요한 상태를 정의한다. 이 순서대로라면, 설계에서 메서드와 상태를 먼저 결정해버리면 안된다. 책임 -&amp;gt; 메시지 -&amp;gt; 역할(객체) -&amp;gt; 메서드 -&amp;gt; 상태1. 협력: 한 객체가 다른 객체에게 메시지를 전송해 무언가를 요청하고 응답을 받는다. 객체간 협력을 설계하는 법: “이 시스템에 어떤 객체들이 필요하고, 어떻게 협력해야한다.” 를 먼저 생각한다.메시지와 메서드의 차이점 메서드는 메시지를 처리하는 하나의 방법이다. e.g) 다형성: 한 메시지에 대해 각각의 다른 객체들은 다르게 행동하는 것(메서드) 템플릿 메소드 패턴: 어떤 메소드가 수행될지는 메시지를 받은 객체에 의해 런타임에 결정된다.객체간 협력의 두가지 측면 컴파일 측면: 시스템의 컴파일타임 측면 (단순히 클래스 사이에서의 관계) 코드 설계 중심: 사용자에게 어떠한 가치를 제공할 수 있는지를 고민 첫번째 클라이언트 중심: 실제 사용자 중심 설계이다. 사실상 코딩의 첫번째 목적이기 때문에 일단 먼저 중요하긴하다. 런타임 측면: 런타임에 객체들이 어떻게 협력할지에 대한 측면. (객체지향적 관점) 기능 설계 중심: 개발자가 변경하기 쉬운 품질 좋은 코드 두번째 클라이언트 중심: (동료)개발자 중심 설계이다. 이게 충족되더라도, 첫번째 클라이언트를 만족시키지 못하면 안된다. 2. 책임: 받은 메시지를 수행하는 것. 메시지를 수행하기 위해서는 수행하는 메소드가 있어야 한다. 메소드에 필요한 상태도 있다. 메소드: 메시지를 수행 할 수 있다. 상태: 메소드를 수행하기 위한 상태를 들고 있다.3. 역할: 책임들의 집합. 책임들로 추상화된 객체정리: 객체지향의 핵심 클래스보다 객체가 중요하다. 객체보다 객체가 담는 메시지가 중요하다. 상태보다 행동이 중요하다. 메시지와 메서드이 분리는 유연한 설계의 기반이다. 애플리케이션은 정적인 클래스로 구성되긴 하지만, 메시지만을 통해서도 정의가 될 수 있다.Reference)객체지향의 사실과 오해 조영호님 강의" }, { "title": "자바의정석 - 08장 예외처리", "url": "/posts/%EC%9E%90%EB%B0%94%EC%9D%98%EC%A0%95%EC%84%9D_08_%EC%98%88%EC%99%B8%EC%B2%98%EB%A6%AC/", "categories": "Study, Java", "tags": "java, exception", "date": "2021-12-17 00:00:00 +0900", "snippet": "Error 심각한 오류이다. 시스템적인 문제이고, try... catch와 같은 예외처리로는 복구가 불가능하다. e.g) OutOfMemory, StackOverflow 등 Exception과의 차이 스택오버플로우와 같은 Error는 일단 발생하면 복구할 수 없다.(서버 재실행 등 필요) 그러나, Exception은 발생하더라도 복구가 가능하다. 따라서, 개발자가 개발 단계에서 에러처리에 신경써야 하는 것은 Exception이다. Checked Exception 발생 시 더 특정상황에서의 unchecked exception을 발생시켜 에러메시지를 명확히 전달 Exception try... catch: 프로그램의 비정상 종료를 막고, 정상적인 실행상태를 유지하고자 예외처리. 예외를 처리하지 못하면, 처리되지 못한 예외(Uncaught exception) 발생으로 JVM의 예외처리기가 받아서 예외의 원인을 화면에 출력 printStackTrace(): 콜스택의 메서드 정보와 예외 메시지 띄우기 getMessage(): 예외클래스의 인스턴스에 저장된 메시지를 얻을 수 있다. 프로그래머가 throw 할 수 있다. 만약 Exception을 throw했는데 catch가 없으면 컴파일이 되지 않는다. RuntimeException은 throw하면 컴파일은 되고, 런타임에 에러가 발생한다. java API 문서를 보면, 각 API가 어떤 exception을 throw할 수 있는지 명시해놓았으니, 문서를 보고 적절히 예외처리를 하면 된다. try-with-resources: try의 괄호 안에 객체 생성 문장을 넣으면, try를 벗어나는 순간 자동적으로 객체 close가 발생한다. 이 경우 finally로 명시적으로 close해줄 필요가 없어진다. try (FileInputStream fis = new FileInputStream(&quot;score.dat&quot;); DataInputStream dis = new DataInputStream(fis)) { // ...} Exception클래스들 - Checked Exception 컴파일 단계에서 걸린다. - 코드 흐름상 발생 할 수 있는 에러 반드시 예외처리 해야한다. 예외 발생시 롤백 하지 않음 복구가 가능하기 때문(현실적으로는 많지 않음 -&amp;gt; SQL Exception의 경우) FIleNotFoundException, ClassNotFoundException 등RuntimeException 클래스들 - Unchecked Exception 런타임 시점에 발견된다. 프로그래머의 실수에 의해 발생한다. 반드시 에러 처리해야 하는 것은 아니다. 예외 발생시 롤백해야함 NullPointException, IllegalArgumentException, ClassCastException, ArithmeticException(divide by zero, 오버플로우) 등Reference)자바의 정석 3판https://subhashprogrammingclasses.in/exception-handling-in-java/https://madplay.github.io/post/java-checked-unchecked-exceptionshttps://cheese10yun.github.io/checked-exception/" }, { "title": "자바의정석 - 11장 컬렉션 프레임워크 5. Properties, Collections", "url": "/posts/%EC%9E%90%EB%B0%94%EC%9D%98%EC%A0%95%EC%84%9D_11_%EC%BB%AC%EB%A0%89%EC%85%98_%ED%94%84%EB%A0%88%EC%9E%84%EC%9B%8C%ED%81%AC_5_Properties_Collections/", "categories": "Study, Java", "tags": "java, collections, properties", "date": "2021-12-15 00:00:00 +0900", "snippet": "Properties: Key-Value (String, String) 형태로 무언가를 저장하고자 할 때 사용한다. 데이터를 txt, xml 등의 외부 파일로부터 읽고 쓰는 편리한 기능 제공한다. 그래서 간단한 입출력은 Properties를 사용한다. 외부 파일에서 K-V는 ‘=’로 연결된 형태여야 한다. HashTable을 상속받아 구현해, Map의 특성(저장순서 유지 X)을 갖는다. 컬렉션 프레임워크 이전의 구버전이라, Iterator가 아닌 Enumeration을 사용한다. Properties prop = new Properties(); prop.setProperty(&quot;timeout&quot;, &quot;30&quot;);prop.setProperty(&quot;language&quot;, &quot;kr&quot;);prop.setProperty(&quot;size&quot;, &quot;10&quot;); println(prop.getProperty(&quot;timeout&quot;));println(prop.getProperty(&quot;language&quot;));println(prop.getProperty(&quot;size&quot;)); Collections: Arrays가 배열 관련 메서드를 제공하는 것처럼, Collections는 컬렉션과 관련된 메서드를 제공한다. 동기화 Vector, HashTable 같은 JDK1.2 이전의 구버전 클래스들은 기본적으로 동기화가 되어있다. -&amp;gt; performance 저하 ArrayList, HashMap과 같은 컬렉션들은 필요한 경우에만 동기화를 한다. List&amp;lt;Integer&amp;gt; list = Collections.synchronizedList(new ArrayList&amp;lt;&amp;gt;());Set&amp;lt;Integer&amp;gt; set = Collections.synchronizedSet(new HashSet&amp;lt;&amp;gt;()) 불변 컬렉션: List&amp;lt;Integer&amp;gt; list = Collections.unmodifiableList(new ArrayList&amp;lt;&amp;gt;()); 싱글턴: Collections.singletonList(new ArrayList&amp;lt;&amp;gt;()); 한 종류의 객체만 저장하는 컬렉션 아래와 같이 컬렉션에 모든 종류의 객체를 저장할 수 있다. List&amp;lt;Object&amp;gt; list = new ArrayList&amp;lt;&amp;gt;();list.add(&quot;string&quot;);list.add(1); 대부분의 경우 보통 한 종류의 객체만 저장하기도 하고, 해당 종류의 객체만 저장되도록 strict하게 제한할 때 사용한다. List&amp;lt;String&amp;gt; list = Collections.checkedList(new ArrayList&amp;lt;&amp;gt;(), String.class); generics를 사용하면 아래와 같이 한 종류의 객체만 저장하도록 구현 가능하나, 하위호환성을 위해 이 메소드가 지원된다. class Foo&amp;lt;T&amp;gt; { List&amp;lt;T&amp;gt; list = new ArrayList&amp;lt;T&amp;gt;(); void add(T item) { list.add(item); } // ...} Reference)자바의 정석 3판" }, { "title": "자바의정석 - 11장 컬렉션 프레임워크 4. Map", "url": "/posts/%EC%9E%90%EB%B0%94%EC%9D%98%EC%A0%95%EC%84%9D_11_%EC%BB%AC%EB%A0%89%EC%85%98_%ED%94%84%EB%A0%88%EC%9E%84%EC%9B%8C%ED%81%AC_4_map/", "categories": "Study, Java", "tags": "java, map, collection", "date": "2021-12-15 00:00:00 +0900", "snippet": "HashMap Hashtable의 새로운버전. 따라서 HashMap이 권장된다. Map을 구현하기 때문에 Map의 특성을 갖는다. (저장순서 유지 X). Hashing 하기때문에 검색에 있어 뛰어난 성능을 보인다. HashMap 내부에 Entry(Key, Value로 이루어진 internal class)를 구현하고, 이 Entry를 HashMap의 배열로 갖는다. map.entrySet()로 K-V 쌍을 가져오거나, map.keySet(), map,values()를 통해 K-V를 각각 읽어 올 수 있다. 한 key에 대응하는 value는 하나이다. 한 key에 복수에 데이터를 저장하는법: HashMap의 value로 HashMap을 다시 저장하면 된다. 꺼낼때도 반대로 꺼내오면 된다. // 그룹에 전화번호 추가static void addPhoneNo(String groupName, String name, String tel) { addGroup(groupName); HashMap group = (HashMap)phoneBook.get(groupName); group.put(tel, name);} // 그룹을 추가하기(초기에)static void addGroup(String name, String tel) { if(!phoneBook.containsKey(groupName)) { phoneBook.put(groupName, new HashMap()); }} 해싱 배열과 링크드리스트의 조합. 배열 하나에 하나의 bucket. 하나의 bucket은 링크드리스트 실제로 HashMap에서는 Object 클래스에 정의된 hashCode() 를 해시함수로 사용한다. String의 경우 Object로부터 상속받은 hashCode() 를 사용하기때문에 같은 글자에 대해서는 같은 해시코드를 얻는다. 따라서, equals() 를 통해 같은 객체인지도 비교해 같은 객체인 것을 판별한다. -&amp;gt; hash 제약조건이 있는 이유 TreeMap: Map에서 순차적으로 값을 저장하기 위해 쓰인다. 범위검색이나 정렬이 필요한 경우 사용한다. 일반적인 검색의 경우 HashMap이 TreeMap보다 뛰어나기 때문에 보통은 HashMap을 사용한다.Reference)자바의 정석 3판" }, { "title": "자바의정석 - 11장 컬렉션 프레임워크 3. Set", "url": "/posts/%EC%9E%90%EB%B0%94%EC%9D%98%EC%A0%95%EC%84%9D_11_%EC%BB%AC%EB%A0%89%EC%85%98_%ED%94%84%EB%A0%88%EC%9E%84%EC%9B%8C%ED%81%AC_3_Set/", "categories": "Study, Java", "tags": "java, set, collection", "date": "2021-12-13 00:00:00 +0900", "snippet": ": Set 인터페이스의 구현체는 크게 HashSet과 TreeSet으로 나눠서 생각하면 된다.HashSet: Set을 구현하는 가장 대표적인 컬렉션. 일반적인 Set 중복된 요소를 추가하고자 한다면 추가되지 않고 false가 반환된다. 내부적으로 HashMap을 이용해 만들어져있고, hashing을 통해 구현되어있다. HashMap을 이용한 방법: K-V에서 V를 PRESENT라는 상수(dummy value)로 생성 시점에 초기화해놓고, add 시점에 key값에 해당하는 PRESENT가 존재하는지 아닌지를 따져 중복을 검증한다. load factor: default는 0.75. 75%만큼 채워졌을 때 용량이 두배로 늘어난다. HashSet(int initialCapaticy, float loadFactor) 저장 순서를 유지하고자 한다면 LinkedHashSet 이용 활용 예: Lottoclass HashSetLotto { public static void main(String[] args) { Set&amp;lt;Integer&amp;gt; set = new HashSet&amp;lt;&amp;gt;(); while(set.size() &amp;lt; 6) { int randomNumber = (int) (Math.random() * 45) + 1; set.add(new Integer(randomNumber)); } List&amp;lt;Integer&amp;gt; list = new LinkedList&amp;lt;&amp;gt;(set); Collections.sort(list); System.out.println(list); }} int vs Integer: int는 원시타입이라 산술 연산이 가능하고 non-null이다. Integer는 Wrapper객체라 null을 처리할 수 있어 SQL에 용이하고 산술연산을 하려면 언박싱해야한다.Hash 커스터마이즈 HashSet 내부적으로 equals(), hashCode() 호출한다. 따라서, 중복 기준을 다르게 하려한다면 equals(), hashCode()를 목적에 맞게 오버라이드 해야한다. JDK1.8부터는 hash()hash 조건 동일한 객체에는 여러번 hash()를 호출해도 동일한 int값을 반환해야한다. equals()를 통해 true가 나왔다면 hash()를 호출했을 때 결과가 같아야한다. equals() 를 통해 false가 나왔어도 hash()에서 같은 값이 나올 수는 있다(충돌). 그러나, 성능을 위해서 되도록이면 다르게 나오도록 해싱을 잘해야한다.TreeSet: Set중에서 순차적으로 값을 저장하기 위해 쓰인다. 범위검색이나 정렬이 필요한 경우에 이것을 사용한다. 이진탐색트리(BST) 중 Self-balancing 특성을 갖는 레드블랙트리로 데이터를 저장하는 컬렉션이다. 일반적인 검색의 경우 HashMap이 TreeMap보다 뛰어나기 때문에 보통은 HashSet을 사용한다. TreeSet에 저장하는 Object가 Comparable을 구현하던가 혹은 Comparator를 제공해서 두 객체를 비교할 방법을 알려줘야 한다.활용 예: Lottoclass TreeSetLotto { public static void main(String[] args) { Set&amp;lt;Integer&amp;gt; set = new TreeSet&amp;lt;&amp;gt;(); while(set.size() &amp;lt; 6) { int randomNumber = (int) (Math.random() * 45) + 1; set.add(new Integer(randomNumber)); } System.out.println(list); }} TreeSet이 Node 추가, 삭제 시점에 알아서 정렬해주기 때문에 List에 넣어 정렬하는 과정이 필요없다.Reference)자바의 정석 3판" }, { "title": "자바의정석 - 11장 컬렉션 프레임워크 2. Iterator, Arrays, Comparable", "url": "/posts/%EC%9E%90%EB%B0%94%EC%9D%98%EC%A0%95%EC%84%9D_11_%EC%BB%AC%EB%A0%89%EC%85%98_%ED%94%84%EB%A0%88%EC%9E%84%EC%9B%8C%ED%81%AC_2_Iterator_Arrays_Comparable/", "categories": "Study, Java", "tags": "java, iterator, arrays, comparable, collection", "date": "2021-12-13 00:00:00 +0900", "snippet": "Iterator: 컬렉션에 저장된 요소들에 접근하는 기능을 하는 Interface Collection 인터페이스는 Iterator 인스턴스를 반환하는 메소드를 갖고있다. 자식 List, Set에도 구현되어있고 각각의 iterator는 자식마다 특성에 맞게 다르게 구현되어있다. 원소간 이동 전에 항상 has~~() 메소드를 통해 다음 원소가 존재하는지를 확인해야한다. 객체지향적: Collection 공통 인터페이스를 정의해 컬렉션의 요소를 읽어오는 방법을 표준화하고, 재사용성 극대화한다. 예를 들어, 아래의 코드에서 new ArrayList(); 부분만 변경하면 다른 컬렉션의 iterator를 사용 할 수 있다. public interface Collection&amp;lt;E&amp;gt; extends Iterable&amp;lt;E&amp;gt; { Iterator&amp;lt;E&amp;gt; iterator();} // --- 사용 예시 List list = new ArrayList(); // 다른 컬렉션으로 변경할 때는 이 부분만 고치면 된다. Iterator it = list.iterator();while(it.hasNext()) { System.out.println(it.next());} 사용하지 않는 메소드에 에러 넣기 선택적 기능: 상위 인터페이스의 모든 메소드를 구현하지 않아도 된다. 이 때 호출하는 쪽에서 소스를 까보지 않고도 동작하는 이유를 파악할 수 있도록 에러라도 throw하도록 구현하는 것이 좋다. 생성자를 막아놓는 클래스에서도 마찬가지. public void remove() { throw new UnsupportedOperationException();} java API 문서에 remove() 상세를 보면, 메소드가 지원 되지 않는 하위 Iterator는 UnsupportedOperationException 을 throw한다고 적혀있다. Arrays copyOf(), copyOfRange(): 배열의 전체 or 일부를 복사해 새로운 배열을 만들고 반환한다. e.g. Arrays.copyOf(arr, arr.length) , Arrays.copyOfRange(arr, 2, 4) fill(), setAll() : 배열의 모든 요소를 지정된 값으로 채운다. setAll()은 함수형 인터페이스를 구현한 객체를 매개변수로 전달받는다. e.g. Arrays.fill(arr, 9), Arrays.setAll(arr, () -&amp;gt; (int) (Math.random() * 5) + 1) -&amp;gt; 함수형 인터페이스가 들어갈 곳에 람다식을 넣은 것 sort() : 배열을 정렬할 때 사용 binarySearch(): 배열을 검색할 때 사용한다. 단, 정렬이 되어있어야 이진탐색이 가능하다. e.g. Arrays.binarySearch(arr, 2) toString(), deepToString(): 다차원 배열에서는 deepToString() 사용 equals(), deepToEquals(): 다차원 배열에서는 deepEquals() 사용. 다차원배열을 equals()로 비교하게 되면 결국에 내부의 배열 주소값을 비교하는 형태가 되기 때문에 항상 false를 얻는다. parrallelXXX(): 여러 쓰레드(프로세스)가 작업을 나누어 처리하도록 한다. spliterator(): 여러 쓰레드가 작업을 처리할 수 있도록 하나의 작업을 여러 작업으로 나눠주는 Spliterator를 반환해준다. stream(): 컬렉션을 stream으로 변환해준다. asList(): 리스트로 변환 Comparator와 Comparable: Comparable은 기본 정렬기준을 구현하는데 사용, Comparator는 기본 정렬기준 외에 다른 기준으로 정렬하고자 할 때 사용static void sort(Object[] a); // 객체 배열에 저장된 객체에 구현(implement)한 Comparable에 의한 정렬static void sort(Object[] a, Comparator c); // 지정한 Comparator에 의한 정렬class Descending implements Comparator { public int compare(Object o1, Object o2) { if (o1 instanceof Comparable &amp;amp;&amp;amp; o2 instanceof Comparable) { Comparable c1 = (Comparable) o1; Comparable c2 = (Comparable) o2; return c2.compareTo(c1); // 순서 변경 // return c1.compareTo(c2) * -1; // 기본 정렬방식의 역으로 } }}Reference)자바의 정석 3판" }, { "title": "자바의정석 - 11장 컬렉션 프레임워크 1. List", "url": "/posts/%EC%9E%90%EB%B0%94%EC%9D%98%EC%A0%95%EC%84%9D_11_%EC%BB%AC%EB%A0%89%EC%85%98_%ED%94%84%EB%A0%88%EC%9E%84%EC%9B%8C%ED%81%AC_1_List/", "categories": "Study, Java", "tags": "java, list, 리스트, collection", "date": "2021-12-13 00:00:00 +0900", "snippet": "컬렉션 프레임워크란?: List, Set, Map으로 구성된 컬렉션들을 사용하기 위해 표준화된 설계 java.util 패키지에 포함되어있다. jdk 1.2부터 제공되었다. 이전 버전의 도구들이 하위호환성을 위해 여전히 남아있다. 따라서, 지금부터 작성하는 곳에는 이 프레임워크를 사용하는 것이 좋다. 이전 버전과는 주로 동기화, 설계 측면에서 차이가 있다. 동시성: concurrency를 얻기 위해 많은 콜렉션 프레임워크는 동기화가 안되어있어서 성능이 더 좋을 수 있다. 그러나, 개발자는 임계영역에 대한 동기화를 고려하며 로직을 작성해야한다. stream과 같은 함수형 패러다임을 위주로 작성하게 되면 side effect를 줄일 수 있어 동시성에 대한 연계가 좋아보인다. java collection의 핵심 인터페이스 List(리스트) 중복 허용O, 저장순서 유지O ArrayList, LinkedList, Stack, Vector, Queue Set(집합) 중복 허용X, 저장순서 유지X HashSet, TreeSet Map(K-V) Key 중복 허용X, Value 중복 허용O, 저장순서 유지X HashMap, TreeMap, Hashtable, Properties List, Set과 저장방식이 다르다. List, Set은 Collection 공통조상을 갖는다. ArrayList: Vector 클래스의 신버전인 배열. 기능적인 측면에서는 유사하고 vector와 다르게 동기화가 안되어있다. 배열 크기는 변경 불가능하다. 크기를 변경하려면 새로 만들어서 할당하는 방식을 사용해서 필연적으로 용량 변경에는 오버헤드가 있다. 메모리상 연속적으로 데이터가 저장되어있다. 단순하게 인덱스가 n인 데이터의 주소 = 배열의 주소 + 데이터의 크기 * n로 인덱스 n의 원소값을 읽을 수 있다.배열의 크기 변경 trimToSize()를 호출하면 size 만큼의 capacity로 새로운 배열을 생성해, 주소값을 변수에 할당한다. 기존 배열은 나중에 gc에 의해 제거된다. 벡터의 경우 setSize를 호출했을 때 capacity보다 작다면 size를 늘리고 null로 채워주지만, capacity보다 크다면 위의 방법과 같이 새로운 배열을 만든다.일반적으로 ArrayList를 List타입으로 선언하는 이유ArrayList() 를 LinkedList()로 변경하게 되어도, 참조변수의 타입이 List이므로 List에 정의되지 않은 멤버는 사용하지 않았을 것이 보장된다. 만약 ArrayList를 참조변수로 선언했다면 ArrayList에만 정의되어있는 멤버를 호출했을 수 있기 때문에 선언문 이후의 모든 문장들을 검토해야한다.LinkedList: ArrayList는 크기 변경이 불가능하고, 데이터 추가 삭제에 많은 시간이 걸린다. LinkedList는 배열의 단점을 보완하기 위한 것이다. 양방향 linked list도 있다. 코틀린에서는 default가 양방향이다. 메모리상 불연속적으로 데이터가 저장되어있다. 따라서, 조회 시 n번째 데이터까지 차례대로 따라가야 원하는 값을 얻을 수 있다. 기본적으로 조회, 삭제, 생성 모두 O(N) 의 비용이 발생한다고 보면 된다. 바로 위의 특징 때문에 새로운 배열을 생성하지 않는다는 전제하에, 맨 앞, 맨 뒤 원소를 추가 / 삭제하면 그냥 인덱스로 접근하는 ArrayList가 더 빠를 수 있다. 중간값의 경우는 LinkedList가 훨씬 빠르다.Stack, Queue Stack: 리스트의 맨 뒤 원소를 제거하는 스택은 ArrayList가 더 빠르기도 하고 적합하다. Class로 구현되어있어, 생성자가 있다. 컬렉션 프레임워크 이전부터 존재하던 것이기 때문에 ArrayList가 아닌 Vector를 상속받아 구현되어있다. Queue: 첫번째 원소를 삭제해야하는 큐는 LinkedList가 적합하다. Interface로 구현되어있고 따로 생성자가 없으며 LinkedList()를 통해 생성해야한다. https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/util/Queue.html 의 All Known Implementing Classes에서 여러가지 구현체를 볼 수 있다. 다형성: 실제 수행되는 메소드는 자식 클래스 LinkedList의 메소드들이 수행된다. Stack&amp;lt;Integer&amp;gt; myStack = new Stack&amp;lt;&amp;gt;();Queue&amp;lt;Integer&amp;gt; myQueue = new LinkedList&amp;lt;&amp;gt;(); PriorityQueue: 힙 구조로 이루어진 우선순위 큐 Deque(Double-Ended Queue): 양쪽으로 추가 삭제가 가능하다. Queue를 상속받으며, Interface이다. 구현체로 ArrayDeque, LinkedList가 올 수 있다. Reference)자바의 정석 3판https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/util/Queue.htmlhttps://facingissuesonit.com/2019/10/15/java-collection-framework-hierarchy/" }, { "title": "JIRA 기본 사용법", "url": "/posts/JIRA_%EC%82%AC%EC%9A%A9%EB%B2%95/", "categories": "Study, Tools", "tags": "jira", "date": "2021-12-10 00:00:00 +0900", "snippet": "대체재 Mail 70년대 발명, SMTP 프로토콜 사용 소통을 위해선 또다시 메일을 보내야한다. - 사일로의 주 원인 사일로: 조직 부서간 협력하지 않고 부서간 담을쌓고 내부 이익만을 추구 메신저: 빠른 일 요청 가능하나, 과한 소통으로 본 Task에 집중이 어려워질 수 있다. Jira란? 서비스, 프로젝트가 성공하기 위해선 소통을 잘해야한다. 애자일 지향: 위의 대체제에서의 문제점을 해결하고 일, 이슈를 가시화해 실시간 정보 공유구조 Dashboards: 과제 or 포괄적인 개요 여러가지 볼수있는 Gadget이 있다. 일이 잘 진행되는지, 과거와 비교할 수 있고 앞으로의 방향을 정하는데 도움이 될 수 있다. Pie chart, Activity Stream, Two dimensional ~~ 등 Projects: 프로젝트 목록. read 권한 설정 가능 Issues: 이슈, 필터 검색. 지라에서 사용되는 가장 작은 단위. e.g) 업무적 요청사항, 기능 등 한 이슈 할당시간은 피보나치로 할당해주기. (예상시간에서 올림) 타입을 갖는다. 따라서, 모든 이슈가 동일한 형태는 아니고, 일부는 부모-자식 관계 e.g) Task, Bug, Story 등등 상태를 갖는다 : 업무의 진행상황을 알릴 수 있는, JIRA를 사용하는 사실상 가장 큰 이유. open, resolved, closed 등 여러가지 상태를 갖는다. Boards: 프로젝트에 쌓인 이슈를 보여주는 보드. 기본적으로 프로젝트와 1:1 맵핑. 기본적으로 애자일을 지향하며 Task를 백로그에서 끌어와 팀 내 업무 밸런스를 맞추는 것이 목적 칸반보드: 지속적인 일의 흐름을 보는데 유리 스크럼보드: 스프린트마다 갈아엎어질때가 많다. 다음 버전에 대한 스프린트를 진행할 때 쓴다. Backlog: 생성한 이슈는 open상태가 되고, 여기에 쌓이게 된다. 이슈를 처리할 때 여기서 끌어와서(상태를 변경해서) 하면 된다.우측상단 프로필 - MY JIRA HOME을 바꿔 초기화면을 커스터마이징 가능workflow 팀의 업무 프로세스를 반영한 흐름. Transitions: 워크플로우의 여러 상태 Properties: K-V값으로 커스터마이징 Trigger: 외부 시스템에서 Jira시스템에 Hook을 걸어놓는것 Conditions: transition 권한 조건 Validators: transition 발생 조건 post functions: 트랜지션 발생 후 수행할 event Issues 타입: 항상 같은 타입이라고 할 수 없다. 조직마다 scheme이 다를 수 있다. Epic: 큰 틀. feature 하나. e.g) ~~기능 구현 Story / Task: 에픽 내부 기능. e.g) ~~ 기능의 일부 서브기능 스토리: 비개발적, 태스크: 개발적인 내용 이슈 검색: 이슈가 쌓일수록 보기가 어려워진다. JQL (Jira query Language): Field - Operator - Value + Keyword // 프로젝트명이 TEST이고 할당자가 현재 login 유저인 issue 검색Project = &quot;TEST&quot; AND assignee = currentuser() // 할당자가 나이고, due date 지났는데 처리되지 않은 issue 검색Assignee = currentUser() AND status not in (resolved, closed, Done) AND due &amp;lt;= &quot;0&quot; 이슈 권한에 따라 사용자마다 검색결과가 달라질 수 있다. Reference)카카오 사내 기술학습 - JIRA 사용 기본 가이드https://www.atlassian.com/ko/software/jira" }, { "title": "스프링 인 액션 - 1. 스프링 기초 - 2. 웹 애플리케이션 개발하기", "url": "/posts/%EC%8A%A4%ED%94%84%EB%A7%81%EC%9D%B8%EC%95%A1%EC%85%98_1%EC%9E%A5_2_%EC%9B%B9%EC%95%A0%ED%94%8C%EB%A6%AC%EC%BC%80%EC%9D%B4%EC%85%98_%EA%B0%9C%EB%B0%9C/", "categories": "Study, Spring boot", "tags": "spring, spring boot, 스프링, 스프링부트", "date": "2021-12-10 00:00:00 +0900", "snippet": "스프링으로 정보 보여주기: 작성할 애플리케이션의 도메인을 이해하고, 애플리케이션의 관심사를 Domain으로 나눠 구분한다.Lombok 라이브러리 사용 스프링 라이브러리는 아니지만 Java + Spring에서 유용하게 쓰인다. getter, setter 등 boilerplate를 줄여주고, 다양한 형태의 생성자, 로깅, 빌더를 지원한다.@Data // * 혹은 @Getter / @Setterpublic class FooEntity { private String id;}@Slf4j // *@Controllerpublic class FooController { @GetMapping(&quot;/users&quot;) public String func(User user) { // ... }} 기존에는 @RequestMapping(method = RequestMethod.GET) 처럼 HTTP 메소드를 구별했다고 한다. 스프링 4.3 이후에 생긴 @GetMapping 과 같은 각 메소드에 특화된 어노테이션을 사용하는 것이 권장된다. @RequestMapping은 공통적인 기본 경로를 구별할 때 사용하면 좋다. 위의 경우 (Client)뷰에서 /users로 적절히 유효한 데이터를 전달하면, (Server)컨트롤러에서는 func()가 호출되고 전달되는 데이터들과 바인딩된 속성을 갖는 User 객체를 인자로 받게 된다. 이 때 클라이언트로부터 항상 유효한 데이터를 받으리란 보장이 없다. 따라서, 서버쪽에선 유효성을 검증해야 한다. 유효성 검증 스프링 MVC는 일반적으로 직접 유효성 검증하는 로직을 작성하거나, 자바 빈 유효성 검사 API나 Hibernate 컴포넌트의 유효성 검증 어노테이션을 이용한다. @Datapublic class FooEntity { @NotNull @Size(min=5, message=&quot;Name must be at least 5 characters long&quot;) private String name; @Pattern(regexp=&quot;^(0[1-9]|1[0-2])([\\\\/])([1-9][0-9])&quot;) // MM/YY private String expiration} 간단한 경우 null check, size 검사 등을 할 수 있고, regex를 통해 검증을 강화할 수 있다. 이처럼 어노테이션을 활용하면, 컨트롤러단에서 인자로받는 객체에 @Valid or @Validated 어노테이션을 붙여준다. ```java…import org.springframework.validation.Errors;… @PostMapping public String func(@Valid User user, Errors errors) { if (error.hasErrors()) { return “error”; } // … } 애플리케이션을 실행하는 두 가지 방법 빌드 후 java -jar로 JAR 실행 spring-boot:run 실행뷰 Spring MVC 프레임워크를 사용할 때는 간단한 뷰까지 같이 작성을 해주는 경우가 많다. JSP, Thymeleaf, FreeMarker, Mustache, Groovy 등 다양한 방법이 있다. 저 중 타임리프가 조금 편하다고 하고, 머스타치도 나쁘지는 않았던 것 같다. 뷰 컨트롤러: 스프링 컨트롤러는 @Controller 어노테이션을 이용하는데, 사용자의 입력을 처리하지 않는 간단한 컨트롤러의 경우가 있다. e.g) WebConfig: 보통 WebMvcConfigurer를 implements해 구현한다. Reference) 스프링 인 액션 5판" }, { "title": "자바의정석 - 07장 추상클래스와 인터페이스", "url": "/posts/%EC%9E%90%EB%B0%94%EC%9D%98%EC%A0%95%EC%84%9D_07_%EC%B6%94%EC%83%81%ED%81%B4%EB%9E%98%EC%8A%A4_%EC%9D%B8%ED%84%B0%ED%8E%98%EC%9D%B4%EC%8A%A4/", "categories": "Study, Java", "tags": "java, abstract class, interface, 인터페이스, 추상클래스", "date": "2021-12-07 00:00:00 +0900", "snippet": "추상 클래스와 인터페이스의 공통점 자식클래스는 부모 클래스의 모든 것을 구현해주어야 한다. 하나라도 안된다면 자식 클래스(자식 인터페이스) 역시 추상클래스여야 한다. 그 자체만으로 인스턴스 생성은 불가능하다.추상 클래스란?: 클래스의 구현부 없는 미완성의 형태. 미완성 설계도. 메소드 몸통이 있을 수 있다. 추상클래스는 모든 메소드가 완성되지 않았다는 뜻이고 추상메소드는 구현부가 없다는 뜻이다. 몸통이 없는 추상 메소드라면 꼭 abstract를 명시하는 것이 좋다.추상화: 여러 클래스들의 공통적인 부분을 뽑아서 공통의 부모인 추상클래스로 추상화 &amp;lt;-&amp;gt; 구체화인터페이스란?: 일종의 추상클래스이지만, 추상화의 정도가 높아서 static, default를 제외하고는 메소드 몸통이 없다. 따라서, 밑그림만 그려져있는 기본 설계도라고 볼 수 있다. 모든 멤버변수에는 public static final 가 생략되어있고, 모든 멤버함수에는 public abstract 가 생략되어 있다. (JDK 1.8부터 static, 디폴트 메서드도 있긴하다.) 모든 생략사항은 컴파일 시 컴파일러가 추가해준다. 디폴트 메소드: 추상 메소드의 기본적인 구현을 제공하는 메소드. 새로운 추상 메소드가 추가될 때, 모든 구현체에서 이걸 구현할 필요는 없다.추상 클래스 vs 인터페이스: 이펙티브 자바에서도 가능한 경우라면 인터페이스 사용을 권장하고 있고, java 창시자 제임스 고슬링은 다시 java를 설계한다면 추상 클래스를 없앨 것이라고 했다고 한다. 특별한 이유가 없다면 인터페이스를 사용하는 것이 좋을 것 같다.다중상속 (extends): 일반적으로 자바에서는 다중 상속이 금지되어있다. 그러나 인터페이스의 경우는 다중 상속이 가능하다.interface Fightable extends Movable, Attackable { }인터페이스의 가장 큰 장점 두가지 관계 없는 클래스간 관계를 맺어줄 수 있다. 관계가 없으니 상속으로 묶기 애매한 경우, ~~~able형태의 인터페이스를 구현하는 형태로 묶어준다면 관계가 형성된다. DIP - 독립적인 프로그래밍: 선언과 구현을 분리시킨다. 인터페이스를 통해 클래스간 직접적인 관계를 간접적으로 만들면, 인터페이스에만 의존하기 때문에 계층간 의존이 줄어든다. 클래스를 사용하는 쪽과 클래스를 제공하는 쪽이 있다. 사용하는 쪽에서는 그냥 메소드의 선언부만 알고 사용하면 된다. A - B의 관계에서 A - I(interface) - B의 관계로 개선된다. e.g). JPA를 사용하다가 하이버네이트 구현체를 딴거로 갈아끼워도 Service 코드에는 영향이 미치지 않도록 구현 가능하다. 개념적 차이 일반적으로 인터페이스에서는 어떠한 기능 또는 행위를 하는데 필요한 메서드를 제공한다는 의미를 강조하기 위해 ~able 형태의 네이밍이 많다. 추상클래스에서는 is-a의 상속 개념이 어울리는 클래스에서 사용하는게 적절해보인다.Reference)자바의 정석 3판" }, { "title": "자바의정석 - 07장 다형성", "url": "/posts/%EC%9E%90%EB%B0%94%EC%9D%98%EC%A0%95%EC%84%9D_07_%EB%8B%A4%ED%98%95%EC%84%B1/", "categories": "Study, Java", "tags": "java, 다형성, polymorphism", "date": "2021-12-07 00:00:00 +0900", "snippet": ": 여러가지 형태를 가져 다양한 동작을 할 수 있는 능력이고, 상속과 함께 객체지향의 가장 중요한 특징 중 하나이다.자바에서의 다형성: 자바에서는 한 타입의 참조변수로 여러 타입의 객체를 참조할 수 있도록 했다. List를 예로 생각해보면, List 참조변수로 ArrayList, LinkedList 타입을 받을 수 있다.참조변수와 형변환class UserRepository { // ...}class UserJdbcRepository extends UserRepository { // ...}UserRepository userRepository = new UserJdbcRepository(); // A. 다형성UserJdbcRepository userJdbcRepository = new UserRepository(); // B. Error A에서 부모 참조변수 타입을 갖는 userRepository는 자식 클래스 userJdbcRepository에만 존재하는 멤버를 사용 할 수 없다. 부모 클래스에 있는 멤버에만 접근 가능하고 런타임에는 자식 클래스의 멤버로 맵핑된다. B에서 자식 클래스를 참조변수 타입으로 갖게 했고, 이 경우 실제 인스턴스인 부모 클래스에 없는 멤버에 접근하려 할 수 있기 때문에 컴파일 에러가 발생한다. 멤버변수의 경우 (부모와 자식 클래스에 중복된 경우에) 참조변수의 타입의 변수를 따른다. (위의 A의 경우 userRepository로 정의한 객체의 멤버변수를 따른다.)자바에서의 형변환UserRepository userRepository = new UserJdbcRepository();// 위는 아래와 같다.UserJdbcRepository userJdbcRepository = new UserJdbcRepository();UserRepository userRepository = (UserRepository) userJdbcRepository; 형변환은 참조변수의 타입을 변환하는 것이기 때문에 인스턴스에는 아무런 영향이 없다. 다만, 참조하고 있는 인스턴스에서 사용할 수 있는 멤버의 범위(개수)를 조절하는 것이다.Instanceof 인스턴스의 타입을 알기 위한 연산자 SessionedUser sessionedUser = new SessionedUser();if(sessionedUser instanceof User) { /* */ } // trueif(sessionedUser instanceOf Object) { /* */ } // true Object: 자바에서 모든 클래스의 조상 클래스. toString(), equals()와 같은 기본적인 메소드 제공다형성User users[] = new User[3];users[0] = new AUser();users[1] = new BUser();users[2] = new CUser();users.forEach(User::foo); 위의 배열 users에 대한 loop를 돌면서 무언가를 수행하면 중복된 메소드 대해서는 자식의 메소드를 수행한다. 중복된 멤버변수의 경우 부모가 가진 멤버 변수를 참조한다.Reference)자바의 정석 3판" }, { "title": "스프링 인 액션 - 1. 스프링 기초 - 1. 스프링 시작하기", "url": "/posts/%EC%8A%A4%ED%94%84%EB%A7%81%EC%9D%B8%EC%95%A1%EC%85%98_1%EC%9E%A5_1_%EC%8A%A4%ED%94%84%EB%A7%81%EC%8B%9C%EC%9E%91%ED%95%98%EA%B8%B0/", "categories": "Study, Spring boot", "tags": "spring, spring boot, 스프링, 스프링부트", "date": "2021-12-06 00:00:00 +0900", "snippet": ": 애플리케이션의 모든 기반을 자동으로 구성해주고, 이 것을 통해 개발자는 애플리케이션의 비즈니스 로직에만 집중할 수 있다.용어 컨테이너 (스프링 애플리케이션 컨텍스트) : 빈 객체를 관리한다. 빈 생성, 관리를 하고, 필요한 곳에 (생성자와 같은 방법을 통해) 주입(연결)시켜준다. 컴포넌트: 빈 객체. 다른 애플리케이션 구성요소와 협력해 작업을 처리한다. 각 빈 객체는 의존성 주입 패턴을 기반으로 수행된다.스프링 기존에는 XML 파일을 통해 bean을 관리하고 상호 연결하도록 스프링 애플리케이션 컨텍스트에 알려주었다. &amp;lt;bean id=&quot;userService&quot; class=&quot;com.example.UserService&quot; /&amp;gt; 최신 버전에서는 자바기반의 구성을 통해 빈 객체를 컨텍스트에 제공한다. ```java@Configurationpublic class ServiceConfiguration { @Bean public UserService userService() { return new UserService(); }} 스프링 부트: 스프링을 한번 더 추상화한 프레임워크.큰 차이점 위의 빈 객체 구성, XML 등을 자동 구성하도록 도와준다. starter를 통해 쉽게 시작 환경을 구성 할 수 있다.자동 구성: Auto configure: 자동 연결(autowiring)과 컴포넌트 검색(component scanning)이라는 스프링 기법을 기반으로 한다. @SpringBootApplication 을 통해 위의 과정 가능. 빈(컴포넌트)들이 컨테이너에 등록되고 관리된다. @SpringBootConfiguration, @ComponentScan, @EnableAutoConfiguration 세가지 어노테이션을 합친 것이라고 보면 된다. JAR 실행 실 호출되어 실행되는 main 메서드에 달아놓는다. main 메서드는 SpringApplication의 run() 메서드를 호출한다. ```java// @SpringBootApplication 내부 @Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@SpringBootConfiguration @EnableAutoConfiguration@ComponentScan(excludeFilters = { @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class), @Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) })public @interface SpringBootApplication { // …} @SpringBootConfiguration: 현재 클래스(UserApplication)를 구성 클래스로 지정한다. @Configuration 의 특화된 형태이다. Configuration으로 등록한 것을 찾아 bean으로 등록해준다. @ComponentScan: 컴포넌트(빈) 검색을 활성화한다. @Repositoriy, @Service, @Controller, @Bean 등의 객체를 메모리에 올린다. 스테레오타입 어노테이션: 역할을 구분하기 위한 목적의 @Repository, @Controller 등 어노테이션 @EnableAutoConfiguration : 스프링 부트 자동-구성을 활성화한다. 나머지 어노테이션 내부를 살펴보기 특징 스프링부트 표준 상 WAR(Web Application ARchive)가 아닌 JAR(Java ARchive)로 패키징하는 것을 권장한다. 기존의 자바 웹 어플리케이션은 WAR 파일로 패키징한다. 웹 관련 자원을 포함한다. 기존의 자바 애플리케이션 서버에 애플리케이션을 배포할 때 적합하다. 스프링부트에서는 기본적으로 클라우드를 염두해 JAR로 패키징한다. 클래스, 라이브러리 파일만을 포함한다. Tomcat이 스프링부트 애플리케이션의 일부이다. 장점: 일단 initializer로 초기 설정을 하면 모든 필요한 틀(의존성, 기본 어노테이션 등)이 작성된다. 개발자는 애플리케이션 로직 작성에만 집중하면 된다.핵심 스프링 프레임워크 스프링 부트 자동 구성: 자동적으로 컨테이너에 빈을 등록해준다. 꼭 필요하지 않다면 별도 config를 작성하지 않아도 된다. Actuator: 모니터링 시스템. runtime에 스레드 덤프, 애플리케이션 상태, metric을 살펴 볼 수 있다. 스프링 데이터: 간단한 자바 interface로 데이터 레포지토리 정의 가능(JPA 인터페이스) 스프링 시큐리티: 인증, 허가, API 보안 등. 애플리케이션 보안을 위한 필수요소 스프링 통합과 배치: 애플리케이션 통합과 Batch. 스프링 클라우드: 모놀리식 -&amp;gt; MSAReference) 스프링 인 액션 5판" }, { "title": "쿠버네티스를 사용하는 이유", "url": "/posts/%EC%BF%A0%EB%B2%84%EB%84%A4%ED%8B%B0%EC%8A%A4_%EC%82%AC%EC%9A%A9%EC%9D%B4%EC%9C%A0/", "categories": "Study, Kubernetes", "tags": "kubernetes, 쿠버네티스", "date": "2021-12-05 00:00:00 +0900", "snippet": ": 여러 컨테이너 오케스트레이션 기법 중 쿠버네티스를 사용하는 이유컨테이너 오케스트레이션이 필요한 이유: 많은 컨테이너를 더 편리하게 관리하기 위한 목적 도커 기반 컨테이너 환경이 등장하면서 애플리케이션 배포과정이 쉬워졌다. 그러나, 여전히 많은 컨테이너를 직접 관리해줘야 한다는 불편한 점이 있다. 여러 호스트에 걸쳐 띄워진 컨테이너들(오케스트레이션)에 대한 관리가 편리해진다.대략적인 장점 master를 통해 편리한 관리. 상태 관리: 컨테이너가 늘어나면 쿠버네티스가 자동으로 컨테이너들간 상태를 조정해준다. 배포 관리: 노드의 현재 상태를 체크해 여유있는 노드를 찾고, 해당 노드에 배포해준다. (개발자는 어떤 node에 떴는지 알 필요 없다) 배포 버전 관리: 하나하나 버전 바꿔주는게 아니라 중앙에서 한번에 관리한다. 서비스 등록: 새로운 서버가 하나 뜨면, 저장소에 반영이 되고, Proxy에서 설정이 반영된다. 볼륨 관리왜 쿠버네티스?1. 오픈소스이다. 사실상 표준: 활발히 오픈소스가 운영되고 있다.(google, MS 등등 많은 기업) 인기있는 오픈소스이기 때문에 커뮤니티가 활발하다.2. 확장성이 무한하다. 하나의 플랫폼이다: 많은 것들이 쿠버네티스 위에서 돌게 된다.사실상 표준?e.g) 클라우드 환경에 적합한 오픈소스를 제공하는 Cloud Native(오픈소스 단체)에서의 핵심 역할.Reference)Youtube 44BITS [초보를 위한 쿠버네티스 안내서] https://youtu.be/Ia8IfowgU7s , https://youtu.be/fDcqL6xlOPk" }, { "title": "쿠버네티스 아키텍처", "url": "/posts/%EC%BF%A0%EB%B2%84%EB%84%A4%ED%8B%B0%EC%8A%A4_%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98/", "categories": "Study, Kubernetes", "tags": "kubernetes, 쿠버네티스", "date": "2021-12-04 00:00:00 +0900", "snippet": "쿠버네티스란?: (k8s, kube, …) 컨테이너된 애플리케이션을 자동으로 배포, 스케일링, 관리 컨테이너를 쉽게 관리하기 위해 논리적으로 그룹화(노드 or 파드 or service 등으로 추상화)아키텍처쿠버의 특징: Desired state: Observe 상태 체크 -&amp;gt; Diff 발견 -&amp;gt; Act 조치 매커니즘 사실상 쿠버네티스의 근간을 이루는 시스템이다. 장점: 관리가 용이하다. 단점: 실시간 적용이 어렵다(느리다). -&amp;gt; 파드 띄우면 완전히 뜨는데 시간이 꽤 걸린다.마스터: 체크하고, 실행하는 역할 스케줄러: 어떤 노드에 배포할지 스케줄링 노드에 라벨을 부여 컨트롤러: 끊임없이 상태 체크하기 위한 컨트롤러 파드 or 네트워크 or 노드 등 무엇이든 체크한다. 실제로는 단일 프로세스로, 하나만을 체크하고 대신 각각 여러개를 띄운다. API server 가운데에서 상태를 바꾸거나 조회. 따라서 모든 스케줄러, 컨트롤러, etcd는 API server를 통해야한다. 요청 많다 -&amp;gt; scale out 가능 etcd 모든 상태 저장, 데이터를 저장. 분산 시스템으로 구성해 HA 데이터가 중요하기 때문에 보통 백업한다. 노드: 위의 마스터와 마찬가지로 모든 노드는 API server를 바라본다. 여러 노드가 존재할 수 있다. proxy 요청을 직접 보내지는 않는다. 커널레벨의 iptables 같은 것으로 주고받도록 하고, Proxy는 그 설정만을 들고있도록 한다. kubelet (POD와 1:1 map) 컨테이너를 사용하도록 컨테이너를 직접쓰는게 아니라 Pod으로 감싼다. 각 node마다 떠있어야 한다 pod(파드) 가장 작은 컨테이너 배포 단위 하나 이상의 컨테이너 존재: 메인 하나이거나 메인 컨테이너 + 사이드카 컨테이너로 구성 e.g. 메인 + 로깅서버 내부에서는 IP, 볼륨을 공유 가능 언제든 업데이트 될 수도, 죽을 수도 있다. 컨테이너 오케스트레이션 특성상, 상태를 유지하려는 특성으로 자동으로 다시 뜬다. HPA: Horizontal Pod Autoscaler. Pod 스케일링Node vs Pod?: 노드는 사실상 Host. 물리 PC or 인스턴스라고 보면 된다. 하나의 노드에는 여러 Pod가 존재 할 수 있다.Helm? package manager(e.g npm) Chart - 헬름 패키지 Repository - 패키지 저장소. 차트 공유 Release - 인스턴스 template - 변수 inputReference)Youtube 44BITS [초보를 위한 쿠버네티스 안내서] - https://youtu.be/SNA1sSNlmy0" }, { "title": "DB 접근 통제와 작업 요청", "url": "/posts/DB%EC%A0%91%EA%B7%BC%ED%86%B5%EC%A0%9C_%EC%9E%91%EC%97%85%EC%9A%94%EC%B2%AD/", "categories": "Study, Database", "tags": "database, db, 데이터베이스", "date": "2021-12-02 00:00:00 +0900", "snippet": "DB에 접근하는 일반적인 방법: Client Tool(SQL developer, mysql workbench) 이용 or DB 콘솔로 직접 접근DB 접근 통제 시스템이란?: 해당 DB에 접근 권한을 보유하고 있는지, 권한이 어느정도까지인지 제어하는 것. Client tool과 DB 사이의 통제 agent가 게이트웨이 역할을 수행한다. 따라서, 유저는 DB에 직접 붙는 것이 아니라 에이전트에 붙는다. 권한이 있다면 이 서버가 중개자가 되고, 권한이 없다면 요청을 막는다. 이러한 설계로 인해, 이 시스템을 이용할 때 목적지 호스트, 포트는 접근통제 서버가 된다. 접근 통제 Agent: 내부적으로 연결을 허용하는 client를 정해놓는다.(client 프로그램. e.g. mysql workbench). 또한, 유저에 대한 인증을 수행해 접근이 가능한 유저인지를 판단한다. Agent 뒷단의 master, slave DB 역할은 failover 과정에서 언제든 바뀔 수 있다. 접근 통제 Agent에서 직접 매번 요청에 적절하게 LB해주는게 아니라면(e.g HA-Proxy), 클라이언트는 요청 전 DB 리스트에서 DB 권한을 확인할 필요가 있다. 변경사항을 인지하고, port forwarding 정보를 수정해준다. Reference)카카오 사내 기술학습" }, { "title": "취약점과 대응방안", "url": "/posts/%EC%B7%A8%EC%95%BD%EC%A0%90_%EB%8C%80%EC%9D%91%EB%B0%A9%EC%95%88/", "categories": "Study, Network", "tags": "network", "date": "2021-12-01 00:00:00 +0900", "snippet": "취약점이란?: 1. 소프트웨어의 결함 2. 공격자의 접근 3. 악용 가능성 세가지 모두 제거하려는 노력을 해야한다. 어떠한 경우라도 완벽하게 제거했다고 말하기 어렵기 때문 여러 취약점들이 계속해서 생기고 있다. 보안 관련 진단을 주기적으로 계속 해야한다.다양한 사례Local Web Proxy를 통한 패킷 조작 본인의 PC 패킷은 얼마든지 가로채서 변조가 가능하다. 공격자는 이러한 패킷을 가로채서 쿼리를 넣는 등 변조할 수 있다. (e.g 자바스크립트 코드를 개발자도구에서 변조)URL Scheme을 통한 리다이렉트: 공격자가 목적지 URI 파라미터에 공격자의 악성사이트를 넣어 해당 주소로 리다이렉트 하도록 하는 방식 모바일 클라이언트에서 발견되는 취약점. 이후 원하는 정보(토큰 등)를 가져와 악용 가능대응 방안: URL 등 정보들에 유효한 정보가 알맞게 들어있는지 strict하게 검증Regex를 통해 검증하면 좀 더 강력할 것 같다.SSRF(Server-side Request Forgery): 공격자는 웹 서버의 WAS를 호출하는 어떤 것을 호출해 내부 서버들의 실제 IP를 스캔하거나 데이터 유출, (악용)쓰기 API를 호출하는 등의 공격이 가능하다. 마찬가지로 파라미터를 이용한 공격 기본적으로 웹서버를 통해 리버스 프록시를 구현하고, 이를 통해 보안성을 높인다.대응 방안: 파라미터에 대한 검증 or redirect 필요할때만 redirect 가능하다는 헤더 추가, redirect 목적지 주소 검증CSRF(Cross-site): 공격자의 악의적인 리소스를 사용자가 읽어, CSRF 스크립트를 실행하도록 한다.XXE(xml external entity) injection: 사용자로부터 xml 파일을 입력받거나 하는 곳에 XML 공격코드를 주입시킨다. 보통 External entity 사용을 금지하지 않아서 발생.대응 방안: XML 파서 외부참조 비활성화Command injection: 파라미터같은 곳에 커맨드 파이프라인을 넣는 방식대응 방안: 서버측에서 커멘드에 대해 검증. REGEX로 파이프라인 존재 여부 확인불필요한 정보 노출: docs html 노출(엔드포인트 명세 노출), 에러처리 미흡 등Reference)카카오 사내 기술학습" }, { "title": "RESTful과 Rest 유니폼 인터페이스(Uniform Interface)", "url": "/posts/RESTful_%EC%9C%A0%EB%8B%88%ED%8F%BC_%EC%9D%B8%ED%84%B0%ED%8E%98%EC%9D%B4%EC%8A%A4/", "categories": "Study, REST API", "tags": "rest, rest api", "date": "2021-11-27 00:00:00 +0900", "snippet": "HTTP API HTTP를 사용해서 서로 정해둔 스펙으로 통신 넓은 의미의 Rest APIREST API(Restful): http api와 같으나 추가적으로 Restful한 네가지 특징을 갖고 일관된 인터페이스를 만들어야 한다.1. 자원 식별: 각각의 리소스는 URI를 통해 식별 가능해야한다.​ e.g) GET /rooms/1 리소스의 표현 방법 종류: document, collection, store, controllerURI vs URL URL은 URI의 한 부분. Resource에 어떻게 접근하는지를 나타내는 Path URI는 Client, Server간 리소스의 Representation을 교환하기 위한 방법. 시간이 흘러도 변하지 않는 정보를 포함한 Identifier2. 메시지(표현, 행위)를 통한 리소스 조작: 자원을 어떻게처리할 지 표현을 전송한다. GET, POST, PUT, DELETE, PATCH 메서드 뿐 아니라, 자원의 표현 Resource에 대한 상태를 설명하는 Representation을 주고 받음. Representation 형태는 content-type. text/html, application/json 등 e.g) html을 선호하는 한국 사용자를 위한 representation Content-Type: text/html; charset=UTF-8Content-Language: ko &amp;lt;html&amp;gt;&amp;lt;body&amp;gt;안녕하세요&amp;lt;/body&amp;gt;&amp;lt;/html&amp;gt; 3. 자기 서술형 메시지: 수신자가 이해하기 위한 모든 정보를 가지고 있어야 한다. 별다른 문서를 제공받지 않고, REST API 메시지만 보고도 쉽게 이해할 수 있도록 자기서술적이다. method, status code, Header 등 HTTP 표준을 적극 활용 GET /HTTP /1.1 HTTP/1.1 200 OK\\[{ “op” : “remove”, “path” : “a/b/c&quot;}\\] 이러한 메시지보다 아래의 메시지가 더 self-descriptive GET /HTTP /1.1 Host: www.test.co.kr HTTP/1.1 200 OKContent-Type: application/json-patch+json\\[{ “op” : “remove”, “path” : “a/b/c&quot;}\\] 4. hateoas : 클라이언트가 리소스에 접근하기를 원한다면, server가 응답을 줄 때 hyperlink를 추가해서 보내준다. 다음에 클라이언트가 어떤 API를 호출해야하는지는 해당 링크를 통해 받을 수 있다. 이 원칙을 통해 클라이언트와 서버는 완전하게 분리됨. 오토마타에서의 상태전이와 비슷하게 이해 가능하다. URI 등이 바뀌어도 클라이언트에서는 자동으로 연결됨 클라이언트에게 자원을 보내면서 다음에 연결할 URL을 링크로 같이 보내기 때문에 e.g) 주문에 대한 정보를 보낼 때 주문 고객에게 사용 가능한 작업을 식별하는 링크를 주문 presentation에 포함 요청에 대한 응답을 보낼 때 그 스크린에서 할 수 있는 것들을 요청으로 보내면 됨 ref) https://docs.microsoft.com/ko-kr/azure/architecture/best-practices/api-design#use-hateoas-to-enable-navigation-to-related-resources 이 원칙이 중요한 것은 이렇게 함으로서 클라이언트와 서버간의 완전한 분리가 이루어지게 됩니다. 만약 서버의 자원을 나타내는 URI 가 변경되었을 경우 클라이언트는 서버의 변화에 종속적으로 그 정보를 클라이언트 정보에 추가하게 됩니다. (SPA 상에서 href 데이터를 바꾸어 줘야함) 하지만 HATEOAS를 제대로 적용했을 시 아래와 같이 _links.profile 에 대한 href정보만 조회해주면 되므로 서버에서 URI정보가 바뀌어도 클라이언트 측에서 소스 변경없이 그대로 사용할 수 있게 됩니다. 출처: https://engkimbs.tistory.com/855 [새로비] e.g ) &quot;_links&quot; : { &quot;self&quot; : { &quot;href&quot; : &quot;http://localhost:8080/api/events/46&quot; }, &quot;profile&quot; : { &quot;href&quot; : &quot;/docs/index.html#resources-events-get&quot; }}HATEOAS가 어려운 이유 html으로 전달하는 방법 말고 JSON의 경우에는 본문에 link라는 것을 하나 정의해서 거기에 링크를 박으면 됨 그런데 클라이언트입장에서 이를 동적으로 파싱해야하기도 하고 링크 정보가 과다해질 수 있다.(상태전이가 아주 많고 복잡한 경우) 최소 어떠한 link relation이 있는지를 파악하고 있어야 UI에 바인딩이 가능 또한, URI 변경 말고, link relation이 변경되면, 우리가 변경에 대한걸 반영해야 하는 것은 여전하기도 함 reference)https://doitnow-man.tistory.com/96https://blog.npcode.com/2017/04/03/rest%ec%9d%98-representation%ec%9d%b4%eb%9e%80-%eb%ac%b4%ec%97%87%ec%9d%b8%ea%b0%80/https://www.inflearn.com/questions/126743http://amazingguni.github.io/blog/2016/03/REST%EC%97%90-%EB%8C%80%ED%95%9C-%EC%9D%B4%ED%95%B4-1https://sabarada.tistory.com/9https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&amp;amp;blogId=saltynut&amp;amp;logNo=220758336130" }, { "title": "Container 인스턴스 Locale 설정", "url": "/posts/Container_locale_%EC%84%A4%EC%A0%95(%ED%95%9C%EA%B8%80%EA%B9%A8%EC%A7%90)/", "categories": "Study, Docker", "tags": "docker, 도커, 컨테이너 설정, locale", "date": "2021-11-23 00:00:00 +0900", "snippet": ": 한글이 마름모 + 물음표로 보인다면 locale 설정이 맞지 않는 것이다. 컨테이너 내부에서 한글 문자를 보면 아래와같이 마름모 + 물음표 + 특수문자 형태로 보이게 된다. locale을 통해 확인해보면 현재 컨테이너의 로케일 설정에서 LC_ALL= 이 값이 비어있고 나머지는 POSIX 라는 로케일로 설정되어있다.POSIX: POSIX 규격을 따르는(우분투) 시스템에서의 디폴트 로케일 위 그림에서 locale -a 을 통해 사용가능한 모든 로케일의 이름을 출력하면, C, POSIX(C와 같음), C.UTF-8 세가지가 있음이 확인된다. ko_KR.UTF-8 (한국에서 사용하는 한글 UTF-8이라는 뜻)같은걸 사용하고자 한다면 별도 설치가 필요하다. 위의 C, C.UTF-8중 두번째껄 사용하기 위해 컨테이너 실행 옵션에 추가 옵션을 주면 된다. docker exec -itu 0 -e LC_ALL=C.UTF-8 ${container} /bin/bash 이후 실행환경(Dockerfile이나 컴포즈 설정)에도 env를 반영해 자동적으로 환경변수를 먹이면 된다. Reference)https://www.44bits.io/ko/post/setup_linux_locale_on_ubuntu_and_debian_container" }, { "title": "Redis의 자료구조와 Full scan", "url": "/posts/Redis_%EC%9E%90%EB%A3%8C%EA%B5%AC%EC%A1%B0%EC%99%80_%ED%92%80%EC%8A%A4%EC%BA%94/", "categories": "Study, Redis", "tags": "redis, 레디스", "date": "2021-11-20 00:00:00 +0900", "snippet": ": Redis에는 불가피하게 full scan을 해야하는 API를 제공한다. getKeys(hscan())와 같은 것이 그런 것에 속한다. 싱글스레드 기반의 redis를 block시키는 것은 큰 문제를 발생시킬 수 있어, 해결 방안 중 하나로 많은 곳에서 cursor 매커니즘을 이야기한다.cursor 매커니즘 Redis는 open addressing 방식의 해시테이블(버킷)로 구성되어있다. Cursor의 한 턴은 한 버킷의 단위이다. 따라서, 각 cursor는 한 bucket의 linked list를 한번 순회하면 그 다음 bucket의 주소를 가리키고, 멈춘다. // 아래와같이 hashScan(별도 구현)을 통해 얻어온 key값들을 저장하고, cursor를 새롭게 갱신한다. let cursor = &#39;0&#39;;const keys: string[] = [];try { do { const [nextCursor, ...result] = await hashScan(redisClient, hash, cursor); cursor = nextCursor; } while (cursor !== &#39;0&#39;);} catch (error) { // ..} 위와 같은 방법을 통해 full scan에서의 문제를 해결한다. 이걸 사용한다 하더라도, 내부구조가 해시테이블이 아니고 그냥 리스트라면 같은 문제가 고스란히 발생 지나간 자리는 다시 스캔하지 않는다. 반환된 Key로 뭔가를 하려한다면 주의해야 한다. Redis의 자료구조 해시테이블을 사용한다. 1 버킷: 1 리스트의 형태이다. 초기 사이즈는 버킷 4개이고, 각 버킷 인덱스는 비트값이다. (초기에는 00, 01, 10, 11) 해싱 결과 &amp;amp; sizemask 비트연산을 수행해, 어떤 bucket으로 맵핑할지를 결정한다. 일정 수준 이상으로 충돌이 많이발생하면, Rehashing을 수행한다.Rehashing: 일정 수준 이상의 충돌이 발생할 때 버킷 크기를 두배로 늘리고 다시 해싱하는 것 O(n) 번의 리해싱. cursor 매커니즘 사용: 한 cursor당 하나의 버킷 rehashing 리해싱 중일 때는 해싱 테이블 두개 존재하게 된다. 생성, 변경, 삭제 데이터는 새로운 테이블로 처리 조회는 두 테이블을 다 순회 Reference)https://tech.kakao.com/2016/03/11/redis-scan/" }, { "title": "DB Indexing", "url": "/posts/DB_%EC%9D%B8%EB%8D%B1%EC%8B%B1/", "categories": "Study, Database", "tags": "database, db, 데이터베이스, 인덱싱, indexing", "date": "2021-11-18 00:00:00 +0900", "snippet": "인덱싱이란? DB 조회시 더 빠르게 할 수 있는 방법. 책 맨 첫페이지에 있는 목차 느낌 column(속성), 해당 레코드가 저장된 주소를 Key - value 쌍으로 인덱스를 만들어 두는 것c.f) MariaDB 디폴트로 PK, FK 컬럼에 대해 인덱스 테이블을 만들어놓는다. 기본값으로 B-Tree 사용한다고 명시되어있다. 정확하게는 B-Tree에서 성능을 개선한 B+Tree를 사용한다. 확인 CLI: show index from ${table}인덱스의 장단점 장점 테이블 조회 속도 향상 단점 인덱스 관리를 위해 별도의 (약 10%) 관리공간 추가적 필요 추가 작업 필요 잘못 사용하면 오히려 역효과 발생할 수 있음 Index를 사용할 때의 성능, 주의할 점: 항상 성능을 향상시키지는 않음성능 저하(사용하면 안 좋은 곳) INSERT, DELETE, UPDATE가 많은 곳(DML(데이터 조작 언어) 자주 일어나는 컬럼) INSERT - 인덱스에 대한 데이터 하나 추가해야 함 DELETE - 인덱스를 삭제하지 않고 사용하지 않음 처리 만약 데이터가 10만건, 인덱스가 100만건 있다고 가정하면 오히려 역효과 UPDATE - INSERT와 DELETE의 문제점 동시에 수반 더 중요한 것 : 컬럼을 이루는 데이터의 형식에 따라 인덱스에 악영향(데이터 중복이 큰 컬럼) e.g. 이름, 나이, 성별 필드를 갖는 테이블의 경우 : 이름에 대해서만 인덱싱을 생성하면 효율적이다. 나이로 인덱싱 되어있으면 일단 B-Tree에서 원하는 노드를 찾아간 후 원하는 컬럼을 찾기위해 추가조회를 하면서 성능이 좋지 않아진다. 사용하면 좋은 곳 규모가 작지 않은 테이블 join(외래 키) 로 사용되는 컬럼 where, orderby 자주 사용되는 컬럼 데이터 중복 적은 컬럼(카디널리티가 높은 것)Index 자료구조B+Tree 인덱스 알고리즘 일반적으로 사용되는 인덱스 알고리즘. (Maria DB, Mongo의 default) 컬럼의 값을 변경하지 않고 (앞 부분만 잘라서 관리 : 전방 일치) 원래의 값을 이용해 인덱싱 Select 질의에 일반적으로 부등호 연산이 있기 때문에 Hash보다는 B+ Tree를 사용 B-Tree와 다르게, Non-leaf에는 leaf로 가기 위한 경로만 있다. 따라서, 불가피하게 실제 값까지 가기 위해선 leaf까지 항상 도달해야한다 -&amp;gt; log N leaf node에는 인덱싱한 값 존재(e.g PK)Hash 인덱스 알고리즘 컬럼의 값으로 해시 값을 계산해서 인덱싱 - 속도가 빠름 O(1) 값을 변경해서 인덱싱하기 때문에, 특정 문자로 전방 일치를 찾아 검색하고자 하는 경우 사용 불가 부등호 연산에 문제가 발생(hash table은 동일(=) 연산에 특화되어 있음) 부등호가 필요하지 않은 케이스에 이 알고리즘을 선택하면 더 효율이 좋을 수 있다. Clustered index 비슷한 것들을 묶어서 저장하는 형태. 주로 비슷한 값들을 동시에 조회하는 경우가 많기 때문 PK 값이 비슷한 레코드끼리 묶어서 저장하는 것 PK값에 의해 저장 위치가 결정. 따라서, PK 변경 시 저장 위치도 변경됨 신중한 선택이 필요 테이블 당 하나 생성 가능 &amp;lt;-&amp;gt; non clustered는 한 테이블에 여럿 생성 가능Composite Index (결합 인덱스) 두개의 컬럼을 결합해 자주 사용되는 곳에서. 그런데, 첫번째 인덱스, 두번째 인덱스 순으로 결합했는데 두번째로 검색을 한다면 효과없음 쿼리문을 어떻게 작성할지도 중요Reference)https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Database/%5BDB%5D%20Index.mdhttps://github.com/WeareSoft/tech-interview/blob/master/contents/db.md#index%EB%9E%80https://github.com/JaeYeopHan/Interview_Question_for_Beginner/tree/master/Databasehttps://mangkyu.tistory.com/96" }, { "title": "Spring MVC vs Webflux", "url": "/posts/MVC_Webflux/", "categories": "Study, Spring boot", "tags": "spring, spring boot, 스프링, 스프링부트", "date": "2021-11-13 00:00:00 +0900", "snippet": "Spring MVC 동기식 처리방식. 멀티 스레드 환경 Spring boot에서의 일반적인 모습 기본적으로 client로 부터 요청이 들어오면 queue를 통한다.(WAS의 대기열?) Thread pool이 수용할 만큼만 처리하고 나머지는 queue에서 대기한다. Resource를 줄이기 위해 Thread는 성능에 맞게 최대치를 정해놓고 효율적으로 사용한다 그럼에도 불구하고, thread pool size(Default 200)를 계속 초과하게 된다면 thread pool hell이 발생한다. → 평소의 배가 되는 delay 발생Spring Webflux특징 client req 발생시 event loop을 통해 작업 처리. (서버의 코어 갯수 == thread 갯수). 따라서 적은 수의 thread로 동시성을 다룬다. concurrent user가 1000명 이상일 때 webflux를 사용하면 좋다. 이벤트 루프기반 Non blocking을 지원한다. block이 생길 경우 성능이 저하되어 사용 의미가 없어진다. thread를 줄였는데 blocking이 걸리는 API에 요청이 몰린다면 결국 I/O작업이 끝날 때까지 기다려야 하기 때문. reactive Programming이 가능해진다. -&amp;gt; event driven문제 DB connection을 non-blocking으로 지원하는 라이브러리는 아직 잘 사용되지 않고 있다. R2DBC, jasync sql 등. MongoDB, Redis 등 NoSQL은 지원중. 러닝커브 높다. 또한, Event 기반이기에 작업이 엉겨붙어(이리갔다 저리갔다) 처리되기 때문에 Tracking이 다소 복잡할 수 있다.Reference)https://velog.io/@dyllis/Spring-MVC-vs-WebFlux" }, { "title": "DBCP(DB 커넥션 풀)", "url": "/posts/DB_%EC%BB%A4%EB%84%A5%EC%85%98%ED%92%80/", "categories": "Study, Database", "tags": "database, db, 데이터베이스, 커넥션 풀", "date": "2021-11-13 00:00:00 +0900", "snippet": ": Thread pool과 같은 맥락. 디비 커넥션을 pool에 미리 만들어두고 재사용하기 위한 방법 커넥션을 관리하는 캐시 or 기법 매 요청마다 쓰레드를 생성 삭제하면 비용이므로 WAS(tomcat)에 thread pool을 두고 재사용하는 방법과 같음 마찬가지로 DB connection이 있을때마다 커넥션 객체를 생성 삭제하면 비용이 될 수있음 일반적으로 Thread 수 &amp;gt; DB connection 수 가 좋다고 함. 모든 요청에 항상 DB를 호출할 필요는 없기 때문 이 두 곳에서 유지하는 커넥션 / 쓰레드 수는 메모리와 직관됨. 많을수록 메모리를 사용하고, 적을 수록 클라이언트 대기가 증가하게 됨 WAS에서 설정할 값이고, 실 서버 테스트 후 수를 정하는게 바람직해보임 커넥션이 부족한 경우(모두 사용중일 때): 클라이언트가 대기상태가 되고, 커넥션이 풀 반환되면 순차 제공 OOM(out of memory) 발생. 이 경우 보통 Thread 개수나 DB connection 조정과정 웹 컨테이너가 실행되면서 적절한 수의 DB 커넥션 객체들을 생성해 pool에 저장해놓음 DB에 통신(DB 요청) 시 풀에서 커넥션을 가져 DB 접근에 사용 후, 다시 pool에 반환DB와의 통신은 무슨 프로토콜?? 기본적으로 신뢰성 바탕의 TCP/IP 통신 위에서 감싸진 형태로 DB마다 존재 MariaDB(mysql과 같음) - mysql client/server protocol MongoDB - mongoDB wire protocol Redis - RESP(Redis Serialization Protocol) Reference)https://www.holaxprogramming.com/2013/01/10/devops-how-to-manage-dbcp/https://delf-lee.github.io/post/connection-pool/" }, { "title": "Was vs Web Server(nginx, apache)", "url": "/posts/Webserver_vs_WAS/", "categories": "Study, Network", "tags": "network, web server, was, nginx, apache", "date": "2021-11-11 00:00:00 +0900", "snippet": "Was(Web application server) 사용자 요청에 맞게 동적인 컨텐츠를 전달 Web server + Web container DB 서버가 같이 수행 비즈니스 로직 처리 Node.js 서버, Spring boot 서버가 여기에 해당. 정확하게는 node의 express, 서블릿을 지원해주는 Tomcat Web server(e.g. nginx, apache) 정적인 컨텐츠를 반환한다.(html, css 등) 리버스 프록시 방식으로 동작한다. 클라이언트는 WAS의 위치, 존재 여부를 모른다. 한 Web server는 여러 WAS로 전달될 수 있다. 한 WAS가 scaled-out 되어있을 때 LB도 수행한다. 이건 Proxy서버 또한 마찬가지: HAProxy에서 Redis 마스터, 슬레이브에 적절히 요청을 보내는 것을 생각하면 된다. http 프로토콜 기반으로 클라이언트 요청을 서비스 클라이언트 요청에 대해 가장 앞에서 요청 처리Was는 Web server가 하는 일을 다 할 수 있다. 효율적인 분산처리를 위해 Web server도 사용해야 함 보통 Web server에 Was가 플러그인같이 붙은 형태NginX vs Apache 둘다 일단 .conf 와 같은 설정파일에 명시해 worker process 수를 정할 수 있다.(보통 서버의 코어 수) 많은 요청에 대해 병렬적인 처리를 위해 기본적으로 멀티프로세스이다.NginX 싱글스레드 + 멀티프로세스 방식, 이벤트, 비동기 기반. Node.js 서버와 사용하면 좋은 퍼포먼스를 낼 수 있다. Apache보다 적은 스레드를 사용해 처리할 수 있다. Master 프로세스는 worker 프로세스를 관리하는 역할만 수행한다. Worker process는 새로운 연결을 초기화하고, Run loop에 추가해주는 등등 싱글 스레드를 잘 사용하기 위한 작업들을 수행한다. 다중 I/O처리에 적합하다. HTTP 요청 관점에서 한 스레드가 계속 돌면서 여러 요청들을 돌아가며 처리해주는것. 이 방식을 통해 스레드는 쉬지 않고 일하고, 좋은 Concurrency를 얻는다.(초당 수천개까지) 점유율 2위. Apache에 비해 레퍼런스가 적다.(그래도 충분히 많다)Apache 멀티 프로세스 + 멀티 스레드 방식 fork를 통해 스레드를 늘릴수록 CPU, 메모리 사용량이 증가한다. 멀티스레드의 스프링 부트처럼 한 Connection에 한 스레드가 사용된다. 스레드가 동기적으로 Block되는 방식으로 동작하기 때문에, 스레드 낭비가 있을 수 있다.(스레드 각각이 유휴시간을 활용 못한다.) 가장 높은 점유율을 차지한다. 따라서, 레퍼런스가 많다. 당연하게도 확장 모듈 또한 NginX에 비해 많다고 한다.Reference)https://gmlwjd9405.github.io/2018/10/27/webserver-vs-was.htmlhttps://jeong-pro.tistory.com/84https://niklasjang.tistory.com/56" }, { "title": "IaaS, PaaS, SaaS", "url": "/posts/IaaS_PaaS_SaaS/", "categories": "Study, Cloud", "tags": "cloud, iaas, paas, saas", "date": "2021-11-08 00:00:00 +0900", "snippet": ": 인프라, 플랫폼, 소프트 웨어의 형태로 클라우드 컴퓨팅을 제공하는 것클라우드: 기존 온프레미스 환경에서 기업 각각이 IT 인프라를 관리하고 책임졌다면, 클라우드 환경에서는 더 중요한 사안(어떠한 서비스를 제공할 지) 만 신경 쓰고, 인프라에 관한 것을 클라우드에 맡김각각이 지원해주는 정도와 비용이 위와 같이 다르기 때문에 적절한 클라우드를 비교하며 채택해 사용해야한다.IaaS: Infrastructure as a Service. 서비스로서의 인프라 온프레미스 인프라와 대응되는, 온프레미스에서 클라우드화 된 클라우드 스토리지, 네트워킹, 서버 등 인스턴스를 종량제로 이용할 수 있도록 제공 자체 하드웨어 구매 비용을 절감할 수 있음 데이터가 클라우드에 저장 데이터 센터를 보유하고 있지 않은 기업에 적합 적절히 인프라를 구성할줄 알아야한다. 스케일링: 확장 또는 축소 할 수 있는 유연성 제공 주요 단점은 보안 문제, 여러 클라이언트와 인프라 리소스를 공유해야하는 멀티 테넌트 시스템 인지도 있는 좋은 서비스를 이용해야한다. AWS EC2, GCP compute engine 등PaaS: Platform as a Service. 서비스로서의 플랫폼 IaaS에서 인프라 관리가 더 발전한 형태의 클라우드(약간 정의가 까다로울 수 있음) 사용자가 애플리케이션을 개발, 제공할 수 있는 가상화 환경을 제공 사용자(개발자)는 코드 작성, 빌드, 관리에 집중할 수 있음 인프라: 소프트웨어 업데이트나 하드웨어 관리는 제공업체에서 제공 따라서 여러 사람이 같은 환경에서 개발, 테스팅 등 협업하는데 용이 민첩하게 개발해야하는 개발업체에 적합 Heroku, AWS 람다, 구글 앱 엔진SaaS: Software as a Service. 서비스로서의 소프트웨어 인터넷으로 클라우드 기반 소프트웨어 및 애플리케이션을 제공 사용자는 소프트웨어를 구독하고 웹 또는 공급업체 API를 통해 소프트웨어 이용 개별 시스템에 소프트웨어를 설치할 필요 없고 그냥 API 이용 Gmail, ERP, 사무용 앱, Dropbox 이와 같은 소프트웨어에 그냥 로그인해서 사용할 수 있다. Reference)https://www.ibm.com/kr-ko/cloud/learn/iaas-paas-saashttps://www.redhat.com/ko/topics/cloud-computing/iaas-vs-paas-vs-saas" }, { "title": "외부 정렬(External sort)", "url": "/posts/%EC%99%B8%EB%B6%80_%EC%A0%95%EB%A0%AC/", "categories": "Study, Algorithm", "tags": "algorithm, sort", "date": "2021-11-08 00:00:00 +0900", "snippet": ": 정렬해야하는 목적 데이터의 양이 큰 경우 사용한다.“메인 메모리의 양이 100MB인데, 정렬해야 할 데이터가 10GB이면 어떻게 해야하는가?”“한 줄에 한 문자열이 쓰여있는 텍스트 파일인데 이게 20GB이다. 어떻게 할 것인가?” 위와 같은 경우에 사용될 수 있는 것이 외부 정렬이다. 내부 정렬의 경우 일반적으로 성능 좋다고 알려진 퀵 or 합병 정렬을 사용하면 된다.방법 메인메모리에서 읽을 수 있는 단위(n MB)만큼 Disk로부터 읽고, 일반적인 방법(퀵 정렬)로 정렬한 후, 다시 디스크에 쓴다. 이 작업이 끝나면, 디스크에 존재하는 m개의 청크(블록. chunk) 각각은 정렬되어있는 청크이다. m개의 청크중 두개를 n / (m + 1) 만큼 디스크에서 읽어와, 병합을 진행하면서, 정렬 결과를 출력버퍼에 넣어 계속 디스크에 write한다. 2번의 과정을 반복하다보면, m개의 청크는 회를 거듭하면서 m / 2, m / 4로 줄게 되고, 결국 하나의 정렬된 청크가 디스크에 남게 된다.성능 PASS: Disk에 데이터를 write, read하는 과정을 PASS라고 한다. 패스를 줄이는 요건인 메모리의 크기가 중요하다. 메모리 크기가 두배가 되면 청크 수와 청크 당 읽기 수가 절반으로 줄어든다. -&amp;gt; 결국 O(log(N/M)) (N: Input data, M: Main memory)Reference)코딩 인터뷰 완전분석https://en.wikipedia.org/wiki/External_sorting" }, { "title": "커널모드 vs 유저모드", "url": "/posts/%EC%BB%A4%EB%84%90%EB%AA%A8%EB%93%9C_%EC%9C%A0%EC%A0%80%EB%AA%A8%EB%93%9C/", "categories": "Study, OS", "tags": "os, 운영체제", "date": "2021-11-03 00:00:00 +0900", "snippet": ": 중요 자원 관리를 위해 자원에 대한 접근 권한을 다르게 갖도록 모드를 두개로 나눈 것유저모드 제한적인 접근 권한을 갖는다.(하드웨어 접근 불가) 애플리케이션 코드 실행(새로운 프로세스 실행) 시스템에 영향을 주는 악의적인 명령을 수행하지 못하도록 막는다. 유저모드 특권 level을 갖는다.커널모드 컴퓨터 내 모든 자원에 접근 가능: 메모리, CPU 제어, 외부 process 호출 등 운영체제 코드, device driver 컴퓨터 부팅 시 시작된다. 커널모드 특권 level을 갖는다.모드간 전환 유저 -&amp;gt; 커널 인터럽트 or 시스템 호출 발생 시. 주로 프로세스가 유저모드로 수행하다가 특별한 요청(시스템에 영향을 줄 수 있는)을 할 때 커널 -&amp;gt; 유저 요청받은 Task를 처리하고 system call의 리턴값으로 전해준다. Mode bit -&amp;gt; 듀얼모드: 0일때 커널모드, 1일때 유저모드로 구분짓는다.Reference)https://notesformsc.org/operating-system-structure/https://blckdmask.tistory.com/69" }, { "title": "네트워크의 성능", "url": "/posts/%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC_%EC%84%B1%EB%8A%A5/", "categories": "Study, Network", "tags": "network", "date": "2021-11-02 00:00:00 +0900", "snippet": ": 네트워크의 객관적 성능 측정은 시스템 설계의 지표로 활용될 수 있다.대역폭 단위 시간에 전송할 수 있는 데이터의 최대치 (최대 능력). 보통 초당 비트 or 초당 기가바이트로 이야기처리량 단위 시간에 실제로 전송된 데이터 양 데이터 압축 등의 방법으로 향상 가능지연 시간(latency) 데이터 전송에 걸리는 시간(발송자 발송 시점부터 수신자 수신 시점) 이걸 단축시키기 위해 할 수 있는 방법은 일반적으로 없다고 한다.Example 공장 컨베이어 벨트에서 물품이 이동되는 상황 컨베이어 벨트의 폭을 늘리는 것: (최상의 조건에서의 퍼포먼스인) 대역폭을 키워 결과적으로 (실제 상황에서의) 처리량을 높이는 것 벨트 길이를 줄이는 것: 지연 시간을 줄인다. 단위 시간을 기준으로, 대역폭과 처리량은 변함 없다. 벨트 속도를 높이는 것: 셋 다 해당Reference)코딩 인터뷰 완전분석" }, { "title": "커널(Kernel)", "url": "/posts/%EC%BB%A4%EB%84%90(Kernel)/", "categories": "Study, OS", "tags": "os, 운영체제", "date": "2021-10-30 00:00:00 +0900", "snippet": "커널이란?: 컴퓨터의 운영 체제의 핵심이 되는 컴퓨터 프로그램의 하나. 운영체제 중 항상 필요한 부분이 메모리에 상주하게 되는데, 이 것이 커널이다. 보호(보안): 결함이나 악의적인 행동으로부터 하드웨어를 보호해준다. 프로세스 협동(자원관리): 프로세스간 협력을 위해 IPC(Inter process communication)를 제공한다. 이진 세마포어 locking: 비효율적일 수 있고 안전하지 않을 수 있다.. Message Passing: 유연하게 사용된다. RPC call, 공유 메모리 등등이 이것에 속한다. I/O device 관리: IPC와는 다르게 External Process Communication 이라고 불린다. 물리 메모리와 비슷하다. 하드웨어와 프로세스 사이에서 중재자 역할을 수행한다. 키보드, 모니터, 프린터 등 장치 드라이버. 커널은 유저모드에서 요청을 받고 커널모드로 전환 후 이러한 장치 드라이버를 통해 받은 것을 유저에게 전달해준다. 운영체제란?: 여러 시스템의 자원을 효율적으로 관리하고 사용될 수 있도록 환경을 제공하는 여러 프로그램의 모임.OS 내에서 커널의 위치 하드웨어: 시스템의 토대가 되는 물리적 머신, 메모리(RAM)와 프로세서 또는 중앙 처리 장치(CPU) 그리고 입출력(I/O) 장치(e.g. 스토리지, 네트워크 및 그래픽)로 구성된다. CPU는 계산을 수행하고 메모리를 읽고 쓴다. Linux 커널: OS의 핵심. 메모리에 상주하며 CPU에 명령을 내리는 소프트웨어. 사용자 프로세스: 실행 중인 프로그램으로, 커널이 관리한다. 사용자 프로세스가 모여 사용자 공간을 구성한다. 일반적으로 프로세스라고 하면 사용자 프로세스를 의미하기도 한다. 커널은 이러한 프로세스 및 서버가 서로 통신(IPC)하도록 한다.Reference)https://www.redhat.com/ko/topics/linux/what-is-the-linux-kernelhttps://ko.wikipedia.org/wiki/%EC%BB%A4%EB%84%90_(%EC%BB%B4%ED%93%A8%ED%8C%85)https://en.wikipedia.org/wiki/Kernel_(operating_system)" }, { "title": "실제 사용되는 sort() 알고리즘", "url": "/posts/%EC%8B%A4%EC%A0%9C_%EC%82%AC%EC%9A%A9%EB%90%98%EB%8A%94_sort_%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98/", "categories": "Study, Algorithm", "tags": "algorithm, sort", "date": "2021-10-28 00:00:00 +0900", "snippet": ": 일반적으로 시간 복잡도를 기준으로 sort 알고리즘의 성능을 판단하지만, 실제로는 지역성이나 실 데이터의 분포 등 고려할 것들이 많다. 언어마다 default로 사용하는 sort들이 정해져있다.C++: Intro sort: c++의 std::sort 로 사용되는 Intro sort는 퀵 정렬, 삽입 정렬, 힙 정렬로 이루어져 있다.특징 기본적으로 퀵 정렬로 시작을 한다. 그런데, 정렬할 element가 Threshold(일반적으로 16) 미만일 때는, 삽입 정렬로 수행된다. 재귀 depth가 정렬되는 element 수(n)과 비교해 log N보다 많아지면 힙 정렬로 수행된다. 퀵, 삽입 정렬은 지역성의 이점을 얻는 알고리즘(배열의 경우)으로 유명하다. 특히, 삽입 정렬은 참조 지역성을 아주 잘 만족한다고 한다. 삽입 정렬의 경우 Best case(거의 다 정렬되어있는 상태일 경우)에 O(n) 의 performance를 기대 할 수 있다.복잡도 시간복잡도: Best case O(n), Average O(n log n) , Worst O(n log n) 공간복잡도: 제자리 정렬 알고리즘이다. 따로 공간이 필요 없다.Java: Tim sort(): java에서 디폴트로 사용하는 이 정렬은 삽입 정렬과 합병 정렬을 사용한다.특징 2^x개씩 잘라 각각을 Insertion sort로 정렬하는 방식으로, 기존 Merge sort에서 덩어리별 x개의 병합과정을 생략할 수 있다. 안정 정렬 두개를 결합했기 때문에 안정적이고, 제자리 정렬이 아니지만 기존 합병정렬보다 적은 추가 메모리를 사용한다. 합병정렬의 경우 캐시의 Page가 계속 변경된다(지역성을 잃는다). java 말고도 Python, Android, chrome(v8), swift 에서 이 sort를 사용한다고 한다.복잡도 시간복잡도: Best case O(n), Average O(n log n), Worst O (n log n) 공간복잡도: 최악의 경우 O(n)Reference)https://d2.naver.com/helloworld/0315536https://docs.oracle.com/javase/9/docs/api/java/util/Arrays.html#sort-java.lang.Object:A-https://en.wikipedia.org/wiki/Introsort" }, { "title": "Transaction과 격리수준", "url": "/posts/Transaction_isolation/", "categories": "Study, Database", "tags": "database, db, 데이터베이스, acid, transaction, 트랜잭션", "date": "2021-10-26 00:00:00 +0900", "snippet": ": 데이터베이스에 접근해 로직을 처리하는 하나의 논리적 단위Transaction의 네가지 성질 (ACID) 원자성(Atomic): 트랜잭션은 오직 커밋 or 롤백된다. 일부만 성공하는 것은 없다. 일관성(Consistent): 일관성 있는 DB.(data integrity 만족). String이던 데이터가 갑자기 Date타입으로 변경되는 일 없음 격리성(Isolated): 동시 실행되는 트랜젝션이 서로 영향이 없도록 격리 지속성(Durability): 트랜잭션을 성공적으로 마치면 결과가 항상 지속된다.(영원하다)ACID를 엄격히 지키면 동시성이 떨어진다. 동시성을 얻고 안정성을 해결하기 위한 방법: transaction에 isolation 단계 설정Inno DB lock의 종류InnoDB이란? MySql을 위한 데이터베이스 엔진Lock의 종류 Shared lock - 읽기 잠금. Read 가능, Write 불가. N개의 트랜잭션이 동시에 걸 수 있음. 이게 걸려있으면 다른 트랜잭션은 Exclusive lock을 걸지 못한다. Exclusive lock - 쓰기 잠금. R,W 둘다 가능. 다만 한 개의 트랜잭션만이 트랜잭션을 걸 수 있음 Update lock - 처음엔 Shared lock처럼 동작. Update할 준비가 되면(본인 외의 다른 shared lock들이 할당 해제되면) Exclusive lock으로 변하면서 해당 레코드에 update하게 된다.record lock (row lock): index record에 락을 걸어버림. 다른 트랜잭션이 해당 row에 대한 변경을 하는 것을 방지gap lock: Where 절 등에 존재하는 조건을 만족하는 새로운 record 삽입을 방지 경우에 따라서 테이블 전체가 될 수도 있다.다수의 트랜잭션 경쟁시 발생하는 문제 Dirty read: 다른 트랜젝션에 의해 수정되어 값이 달라졌지만, 아직 커밋은 되지 않은 데이터를 읽는 것 e.g) 트랜잭션 A가 어떤 값을 1에서 2로 변경하고 커밋이 안됐을 때 B가 해당 값을 읽으면 2가 조회 된다. 이 때 A가 롤백되면 B는 잘못된 값을 읽은게 됨 다른 문제들에 비해 발생 확률이 높다. Non-repeatable read: 커밋된 데이터를 읽긴 하지만, 선행 트랜잭션이 읽은 데이터를 후행 트랜잭션이 수정, 삭제. 이후 같은 쿼리를 날리면 값이 달라져 있는 것. 따라서, 한 트랜잭션에서 여러 스냅샷이 사용되는 경우 e.g) A가 값 1을 읽고 또 해당 쿼리를 실행하기 전에 B가 값을 2로 바꾸고 커밋하면 A가 같은 쿼리를 요청했을 때 쿼리 결과가 달라짐. Dirty read에 비해 발생 확률 적다. Phantom Read: 트랜잭션에서 쿼리를 두번 날리면 첫번째에 없던 데이터가 두번째에 생성되는 것 e.g) 2번과 비슷한 상황. B가 테이블에 값을 추가하면 A의 후행 쿼리에서는 없던 값이 생김 격리 수준: 레벨이 올라갈 수록 동시성이 떨어진다. 문제가 발생할 확률도 떨어져 안정성은 증가한다. Consistent Read: 일반적으로 쿼리의 log를 저장하고, 어떠한 시점에 쿼리를 치면 이 log를 통해 스냅샷을 불러와 읽는다고 한다.격리 수준 레벨 - 발생하는 이상현상으로 이해하기 level 0 - read uncommited 찾고자 하는 데이터가 커밋되지 않아있어도 그냥 데이터를 읽어온다. Dirty read, non-repeatable read, phantom read 발생 level 1 - read commited shared lock이 사용되지 않은 것. 변경사항이 커밋되어 확정된 데이터만 읽는다. 사실 DB에는 커밋되지 않은 데이터도 적용된 상태이고, 트랜잭션이 한 레코드를 Read 할 때마다 DB 스냅샷을 새로 만든다. 따라서, 변경사항이 보이게 되는 것 non-repeatable read, phantom read 발생 대부분의 DBMS가 이걸 디폴트로 한다고 한다. level 2 - repeatable read shared lock이 사용되는 것. 한 트랜잭션 안에서는 처음 읽을 때 시간을 기록하고, 나중에 데이터를 다시 읽더라도 해당 시점의 데이터(스냅샷)를 읽어온다. - 이 때 로그를 사용 phantom read 발생 level 3 - serializable Select 쿼리가 전부 Select ... for share 쿼리로 변환된다. - gap lock을 걸어버린다. 테이블에 걸다보니 데드락에 쉽게 걸릴 수 있다. phantom read도 방지. 완전한 단계의 lock Reference)https://dev.mysql.com/doc/refman/8.0/en/innodb-transaction-isolation-levels.htmlhttps://suhwan.dev/2019/06/09/transaction-isolation-level-and-lock/" }, { "title": "온프레미스와 클라우드(Off-premise)", "url": "/posts/%EC%98%A8%ED%94%84%EB%A0%88%EB%AF%B8%EC%8A%A4_%ED%81%B4%EB%9D%BC%EC%9A%B0%EB%93%9C/", "categories": "Study, Cloud", "tags": "cloud, on-premise, off-premise", "date": "2021-10-26 00:00:00 +0900", "snippet": "온프레미스(On-premise. 구축형): 클라우드 같은 원격 환경이 아닌, 자체 전산실 서버에 올리고 운영하는 방식. 클라우드가 나오기 전까지 기업 인프라 구축의 일반적인 방식이었음 Private cloud라고도 부른다. 클라우드의 등장에도 불구, 여전히 회사 내부 온프레미스 환경에 구축해두고 사용하는 경우가 있다. 간단히 개발해서 팀원 혹은 다른 팀원에게 공유하고 테스트환경 제공하는 경우. 장점 단기적인 시점으로 저렴할 수 있다. 클라우드를 구독할 필요 없고 사내 IT 인력으로 솔루션을 구축하는 것이기 때문. 물리적으로 전산실을 확보하고 있기도 하며, 데이터, 네트워크 등을 모니터링 할 수 있다. 대부분 사내에서만 사용하는 서버이고, 다운로드가 잦은 경우 온프레미스가 더 좋을 수 있음 간단한 것을 배포해야 할 때 클라우드 저장소에 배포하는 방법보다 간편하다. 그냥 내부망에서 접근하면 되기 때문단점 보안: 사내 환경이기에 보안에 좋다고 생각할 수 있지만, 내부적으로 보안 시스템을 직접 책임져야한다. 현금을 집에 그냥 놓는 것에 비유 -&amp;gt; 보안업체에게 맡기는 것이 더 보안에 좋다고 말할수있다. 스케일링: 더 많은 리소스를 필요로할 때 스케일링이 어렵다. 반면에 클라우드는 동적으로 증축 가능 비용: 하드웨어, 설치, 공간 확보, 데이터 백업, 지속적인 IT 서비스 지원(유지 보수) 등 많은 시간과 비용이 든다. 일단 최대 가용량으로 설치를 해놓는다. 컴플라이언스: 업계나 국제 규정 준수에 대한 책임도 회사에 있음 서버나 저장소 문제 발생 시 100% 회사책임클라우드(Off-premise): IaaS, PaaS, SaaS 등의 클라우드 서비스 초기 비용이 크게 들어가지 않는다. 물리적 비용도 들지 않고, 그냥 월간 구독요금만 지불 이용하는 만큼 지불이기 때문에 온프레미스(최대치 구축)보다 효율적이다. 스케일링에 용이 : 필요에 따라 증축 가능 보안 서비스를 지원받음 네트워크 보호, 위협 모니터링, 데이터 암호화, 지속적 유효성 검사 등 어디서나 접근 가능 IT 생산성 증진(개발에만 집중) 자체 클라우드 환경의 dev, test환경 or 고객사 클라우드에 띄운 prod환경 등Reference)https://www.microsoft.com/ko-kr/microsoft-365/business-insights-ideas/resources/cloud-storage-vs-on-premises-servers" }, { "title": "DB 정규화가 필요한 이유와 함수적 종속", "url": "/posts/%EC%A0%95%EA%B7%9C%ED%99%94%EA%B0%80_%ED%95%84%EC%9A%94%ED%95%9C%EC%9D%B4%EC%9C%A0/", "categories": "Study, Database", "tags": "database, db, 데이터베이스, 정규화, 반정규화", "date": "2021-10-14 00:00:00 +0900", "snippet": ": 불필요한 데이터 중복으로 인한 공간낭비 + 사이드 이펙트 (a.k.a. 삽입 이상, 갱신 이상, 삭제 이상) 발생을 해결하기 위해 정규화 해야한다.예시 테이블 course: professor = 1 : 1 가정 STUDENT_ID COURSE_ID PROFESSOR_NAME GRADE STUDENT_NAME 1 OS123 김ㅇㅇ B 김ㅇㅇ 1 ALG123 권ㅇㅇ F 김ㅇㅇ 2 ALG123 권ㅇㅇ A 이ㅇㅇ 3 NET123 최ㅇㅇ B+ 최ㅇㅇ 4 OS123 김ㅇㅇ A+ 손ㅇㅇ 반정규화: 정규화로 인해 오히려 join 비용이 증가하는 경우가 있을 수 있다. 이 때 join한 컬럼을 기준으로 반정규화. DB를 설계할 때 SQL의 성능, 모델의 단순성 등을 고려해서 정규화를 해야한다.이상 현상 삽입 이상: 새 데이터를 삽입하기 위해 NULL 불가한(기본키 중 하나인 경우?) 컬럼에 불필요한 데이터도 삽입해야하는 문제 수업을 수강하지 않은 학생을 테이블에 넣기 위해 course_id 컬럼에 미기입 이라는 불필요한 정보를 써넣어야 하는 경우 갱신 이상: 중복된 튜플 중 일부 컬럼(속성)을 갱신할 때 데이터 부정합이 발생하는 문제 수업의 교수가 바뀌어 변경해야 할 때 모든 튜플의 해당 컬럼을 변경해줘야 하는 경우 삭제 이상: 튜플을 삭제함으로써 꼭 필요한 데이터(필요한 컬럼의 정보)까지 연쇄적으로 삭제되는 문제 학생이 수강을 취소해 강의를 삭제해야 할 때 학생 이름, 학번까지 없어짐 함수적 종속성: 어떠한 릴레이션에서 속성들의 부분집합이 X, Y에서 X -&amp;gt; Y 관계일 때 Y가 X에 종속. 이 때 X가 Y를 함수적으로 결정하고, 각각 결정자, 종속자 라고 한다. 위에 예시에서 종속성은 아래와 같이 표현 가능 STUDENT_ID -&amp;gt; STUDENT_NAME - 부분 함수 종속 COURSE_ID -&amp;gt; PROFESSOR_NAME - 부분 함수 종속 { STUDENT_ID, COURSE_ID } -&amp;gt; GRADE - 완전 함수 종속완전 함수 종속, 부분 함수 종속?부분 함수적 종속 속성 Z가 속성집합 { X, Y } 전체가 아닌 일부분에도 함수적으로 종속됨완전 함수적 종속 속성 Z가 속성집합 { X, Y } 전체에 함수적으로 종속됨Reference)https://yaboong.github.io/database/2018/03/09/database-anomaly-and-functional-dependency/https://wkdtjsgur100.github.io/database-normalization/https://nirsa.tistory.com/107" }, { "title": "Database 스키마", "url": "/posts/%EC%8A%A4%ED%82%A4%EB%A7%88/", "categories": "Study, Database", "tags": "database, db, schema", "date": "2021-10-13 00:00:00 +0900", "snippet": ": 개체 Entity, 개체의 속성 Attribute, 개체간 Relation에 대한 정의와 제약조건 기술한 것개념 스키마 조직체 전체를 보는 입장에서 DB에 대한 논리적 구조를 기술한 스키마 통상적으로 말하는 ‘스키마’가 이것내부 스키마 DB가 저장장치에 실제로 어떻게 저장될지에 대한 명세 레코드 형식, 인덱싱 여부, 레코드 순서 등 개발자 관점 스키마외부 스키마 사용자 각 개인의 입장에서 보는 논리적 구조의 스키마. 따라서 하나의 데이터베이스에 여러 외부 스키마 존재할 수 있음. 어떤 형식, 구조로 사용자에게 보여질 것인가에 대한 명세Reference)https://jwprogramming.tistory.com/47https://github.com/WooVictory/Ready-For-Tech-Interview/blob/master/Database/%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B2%A0%EC%9D%B4%EC%8A%A4%20%EA%B8%B0%EB%B3%B8%20%EC%9A%A9%EC%96%B4.md" }, { "title": "Node.js 디자인 패턴 2장 - 4. Observer Pattern(옵저버 패턴)", "url": "/posts/Node.js_%EB%94%94%EC%9E%90%EC%9D%B8%ED%8C%A8%ED%84%B4_2%EC%9E%A5_4_Observer_Pattern/", "categories": "Study, Node.js", "tags": "node.js", "date": "2021-10-05 00:00:00 +0900", "snippet": " 전통적인 Callback 스타일은 Listener 하나에게 전달하는데, 옵저버 패턴은 여러 관찰자(Listener)에게 전달 상태변화가 일어날 때 관찰자에게 알릴 수 있는 객체(Subject)를 정의하는 것EventEmitter: 코어에 내장되어있고 해당 패턴을 이용할 수 있게 해주는 클래스 on(event, listener): 리스너 등록, once(event, listener): 첫 이벤트 후 제거되는 리스너 등록, emit(event, [arg1], [...]), removeListener(event, listener) 제공 마찬가지로 동기, 비동기를 혼용해서 사용하지 않고, 그냥 비동기로 사용오류 전파 콜백에서는 비동기적으로 발생할 경우 이벤트 루프에서 손실되는걸 방지하기 위해 바로 throw EventEmitter에서는 .on(&#39;error&#39;, err) 처럼 직접 명시해 처리 마찬가지로 캐치되지 않으면 프로그램 강제종료. 마찬가지로 항상 에러 이벤트 리스너를 등록하는게 좋다.EventEmitter 클래스 확장 일반적으로 제공하는 것 외에 EventEmitter 클래스를 확장해 더 다양하게 사용 우리가 잘 아는 HTTP 모듈인 Server 객체도 EventEmitter를 확장해, express.use(&#39;/api&#39;, someRouter);와 같이 Request 이벤트 핸들러(정확히는 ApplicationRequestHandler)로 해당 URI를 등록해놓는다. Open WebRTC 코드에서도 QuicController, RtcController로 EventEmitter를 확장해 사용EventEmitter vs Callback둘 중 어느걸 사용할 것인가? 가독성, 의미 등을 고려 할 것 콜백: 비동기의 방식으로 반환되어야 하는 경우 이벤트: 일어난 일이 무슨 일인가를 전달할 필요가 있을 때 이벤트가 더 적절한 경우 동일한 이벤트가 여러번 발생할 수도, 전혀 발생하지 않을 수도 있는 경우(콜백은 단 한번) 여러 수신자가 수신해야 하는 경우 c.f) 둘다 사용하는 예시 - 실제로는 많이 없다.const glob = require(&#39;glob&#39;);glob(&#39;data/*.txt&#39;, (error, files) =&amp;gt; console.log(`All files found: ${JSON.stringify(files)}`)) .on(&#39;match&#39;, match =&amp;gt; console.log(`Match found: ${match}`)); 콜백과 동시에 match 이벤트를 등록(여러번 호출되어도 동작하도록)한다.Reference)Node.js 디자인패턴" }, { "title": "Node.js 디자인 패턴 2장 - 2. 예측할 수 없는 함수", "url": "/posts/Node.js_%EB%94%94%EC%9E%90%EC%9D%B8%ED%8C%A8%ED%84%B4_2%EC%9E%A5_2_%EC%98%88%EC%B8%A1%ED%95%A0%EC%88%98_%EC%97%86%EB%8A%94_%ED%95%A8%EC%88%98/", "categories": "Study, Node.js", "tags": "node.js", "date": "2021-10-02 00:00:00 +0900", "snippet": "예측할 수 없는 함수const fs = require(&#39;fs&#39;);const cache = {};function inconsistentRead(filename, callback) { if(cache[filename]) { // 동기적으로 호출 callback(cache[filename]); } else { // 비동기적 호출 fs.readFile(filename, &#39;utf8&#39;, (err, data) =&amp;gt; { cache[filename] = data; callback(data); }) }} 위의 inconsistentRead()는 캐싱된 파일이 있냐 없냐에 따라 동기적 / 비동기적으로 동작한다.function createFileReader(filename) { const listeners = []; inconsistentRead(filename, value =&amp;gt; { listeners.forEach(listener =&amp;gt; listener(value)); }); return { onDataReady: listener =&amp;gt; listeners.push(listener) };}// -----------------const reader1 = createFileReader(&#39;data.txt&#39;);reader1.onDataReady(data =&amp;gt; { console.log(data); const reader2 = createFileReader(&#39;data.txt&#39;); reader2.onDataReady(data =&amp;gt; { console.log(data); })}) 위의 시나리오에서 reader2의 listener는 동작하지 않는다. reader1의 경우 inconsistentRead가 비동기로 동작해 비동기식 연속 전달 방식 으로 동작해 queue를 한번 거쳐서 실행 call stack으로 전달되지만, reader2의 경우 동기적으로 호출되기 때문에 동기 연속 전달 방식(CPS) 으로 동작하기 때문(바로 수행) 따라서, 결과를 예측하기 어렵고 실제 어플리케이션의 상황이라면 더더욱 어려울 수 있다.동기 API 사용 완전히 동기식으로 만들기 : 동기 I/O 사용으로 블로킹 되는 것은 많은 경우 권장되지 않지만, 가장 쉽고 효율적인 해답이 될 수 있다.지연 실행 완전히 비동기로 만들기 : 동기처리 부분에 process.nextTick()사용 -&amp;gt; 콜백을 대기중인 I/O 이벤트 큐 대기열의 맨 앞으로 밀어넣고, 즉시 반환해 이벤트 루프의 다음 사이클까지 함수의 실행을 지연시킴 가장 앞으로 밀어넣기 때문에 nextTick() 는 starvation을 발생시킬 수 있다. -&amp;gt; setImmediate()로 해결 Reference)Node.js 디자인패턴" }, { "title": "스케줄링 알고리즘", "url": "/posts/%EC%8A%A4%EC%BC%80%EC%A4%84%EB%A7%81_%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98/", "categories": "Study, OS", "tags": "os, 운영체제", "date": "2021-09-26 00:00:00 +0900", "snippet": " 스케줄링 대상은 Ready Queue에 있는 프로세스들 대부분의 OS에서는 우선순위 알고리즘이나 Round Robin 혼합해서 사용한다고 함비선점형 스케줄링: 어떤 프로세스가 CPU를 할당 받으면 그 프로세스가 종료되거나(State: terminated) 입출력 요구가 발생하여 자발적으로 중지(State: waiting(blocked))될 때까지 계속 실행 순서대로 처리되어 공정성 있음 응답 시간을 예상 가능. 선점 방식보다 스케줄러 호출 빈도가 낮고 context switch로 인한 오버헤드가 적음 사용자 개입 없이 순서대로 처리해야 할 곳에 적절 CPU 사용시간이 긴 하나의 프로세스가 있을 때 여러 프로세스가 기다리게 되고, 처리율이 떨어질 수 있음.FCFS(First Come First Served) CPU 사용시간 긴 프로세스가 전체 처리율을 낮출 수 있음SJF(Shortest Job First) CPU 시간 짧은 프로세스 선 할당 starvation: 프로세스가 긴 프로세스는 영원히 CPU 할당 못 받음선점형 스케줄링: 어떤 프로세스가 CPU를 할당받아 실행 중에 있어도 다른 프로세스가 실행 중인 프로세스를 중지하고 CPU를 강제로 점유할 수 있다. 모든 프로세스에게 CPU 사용 시간을 동일하게 부여할 수 있음 빠른 응답시간을 요하는 대화식 시분할 시스템에 적합 긴급한 프로세스 제어 가능 OS가 CPU를 선점하고 있다가 프로세스의 요청이 있을 때 할당RR(Round Robin) - 실제 사용 각 프로세스를 10ms~ 100ms의 시간 단위로 분할해 돌아가면서 수행하는 알고리즘. 시간이 지나면 선점당하고 ready queue의 가장 뒤로 간다. 이 알고리즘은 FCFS를 시분할 선점 형태로 변형한 기법 이라고 볼 수 있다. 대화형 운영체제에 적합한데 그 이유는, 실제로 대화형 운영체제에서는 I/O 작업이 CPU 시간보다 길기 때문이다. IO작업이 빈번하므로 CPU를 빠르게 교체하며 유휴시간을 효율적으로 사용할 수 있다. 현대 운영체제는 대부분 대화형 운영체제이기 때문에 이 알고리즘을 채택 CPU 사용시간이 랜덤한 프로세스들에 효율적 프로세스 교체 시 context save대화형 운영체제(시분할 운영체제) 사용자의 입력(키보드, 마우스 등 입력장치)에 대해 컴퓨터가 결과를 출력(모니터)해준다. 이러한 방식으로 컴퓨터 시스템과 대화하듯 작업을 처리. 대화형이기 때문에 커널에 의한 I/O 작업이 CPU 시간보다 길다. 리눅스, 윈도우, MS-DOS 등 대부분의 현대 운영체제Priority Scheduling 우선순위 높은 프로세스에게 우선 할당(우선순위 정수로 표현) 비선점형으로 구성할 수도 있음.다단계 큐 스케줄링 Ready Queue를 여러개의 큐로 분리 큐 사이에 우선순위를 부여 각 큐는 각각 다른 스케줄링 알고리즘 가질 수 있음 다단계 피드백 큐 스케줄링: 프로세스들이 큐를 갈아 탈 수도 있음SRTF(Shortest Remaining Time First) 새로운 프로세스 도착할 때마다 새로운 스케줄링 이루어짐 - 따라서 CPU 사용시간을 측정 불가 SJF를 선점형으로 바꾼 것 여전히 starvationReference)https://ko.wikipedia.org/wiki/%EC%8A%A4%EC%BC%80%EC%A4%84%EB%A7%81_(%EC%BB%B4%ED%93%A8%ED%8C%85)https://github.com/JaeYeopHan/Interview_Question_for_Beginner/tree/master/OS#cpu-%EC%8A%A4%EC%BC%80%EC%A4%84%EB%9F%AC" }, { "title": "코드 리뷰하기", "url": "/posts/%EC%BD%94%EB%93%9C_%EB%A6%AC%EB%B7%B0%ED%95%98%EA%B8%B0/", "categories": "Study, Develop", "tags": "develop", "date": "2021-09-25 00:00:00 +0900", "snippet": "코드 리뷰하기리뷰를 받는 입장. Assignee마음가짐 열린 마음: 리뷰어의 지적에 무조건 방어적인 태도로 받지 않기 열린 마음이되, 비판적인 사고를 유지하기 리뷰어의 리뷰 타당성에 대해 냉정하게 고민하기 리뷰하기 쉽게 만들기 리뷰 단위를 작게. -&amp;gt; PR or diff를 작은 단위로 쪼개서 리뷰해야 하는 점에 더욱 Focus (당연히) 코드를 간결하게 테스트 플랜을 쓰기 Unit test 혹은 적어도 코드가 동작한 결과물(스크린샷 이라던지) 결국 코드의 신빙성을 높일 수 있다. 리뷰를 하는 입장. Reviewer 받는 사람의 입장에서 Soft하게 느껴질 수 있도록 “제 생각에는… “을 입에 달고 리뷰하기 받는 사람이 빠르게 받아들일수록 팀 전체의 생산성이 증대된다. 정확하고 자세하고 actionable(뭘 해야하는지 명확하게) 코드 변경을 요청하기 전에 변경에 드는 노력과 노력대비 Return이 어느정도 될지를 생각하기 코드 push가 늦어질만한(생산성이 줄어도 될만한) 가치가 있는 피드백인지? 개발 외적으로 관계를 빌딩하면 리뷰에서 약간의 트러블이 발생할 여지가 있어도 좋게 받아들여질 수 있다.Refernce) 유튜브 Teccboi Wonie - 코드 리뷰를 잘 하는 법 https://www.youtube.com/watch?v=VaaRvs8YU1M" }, { "title": "Lazy Loading과 N + 1", "url": "/posts/LazyLoading_N+1/", "categories": "Study, JPA", "tags": "jpa, spring boot jpa", "date": "2021-09-23 00:00:00 +0900", "snippet": ": JOIN 쿼리를 통해 두 엔티티를 조회할 때, 엔티티 로딩 시점이 달라, DB에 쿼리가 한번 더 나가게 된다. JPA에서는 글로벌 페치 전략을 지연 로딩에서 즉시 로딩으로 변경해 해결할 수 있다. JPQL (queryDSL)을 사용한다면 글로벌 페치 전략을 참고하지 않고 그냥 쿼리를 생성하기 때문에 여전히 문제이다.JPQL에서의 해결방법1. Fetch join: 조인 대상(연관된 엔티티)까지 함께 조회해온다. 이때 글로벌 페치 전략은 무의미해진다. 단점: 메소드가 화면에 맞춰 무분별하게 증가한다. 예를 들어 화면 A에선 order만 필요로 하고, B에선 order, member를 필요로 할 때 결국 fetch를 하거나 하지 않는 다른 메소드를 사용하게 될 것이고, 뷰와 레포지토리가 논리적 의존관계를 갖게 된다. Facade 패턴을 이용하면 계층간 논리적 의존관계를 제거할 수 있다고는 하나, 계층 하나가 더 끼어버린다는 점에서 트레이드 오프를 고려해야 할 것 같다. 전부 즉시 로딩을 하도록 하면 또 예상치 못한 SQL 실행이 될 수 있다. 일단은 지연 로딩을 하고, 성능 최적화가 필요한 곳에 즉시 로딩을 하는 방법이 좋다. ManyToOne, OneToOne: 기본 페치 전략이 즉시 로딩 OneToMany, ManyToMany: 기본 페치 전략은 지연 로딩 2. EntityGraph: 아래와 같은 방법으로 attribute 하나만 Eager하게 가져온다.@EntityGraph(attributePaths = &quot;name&quot;)카테시안 곱: Fetch는 inner join, EntityGraph는 Outer join인데, 두 방법 모두 카테시안 곱이 발생한다. 따라서 중복된 데이터가 많아지게 된다. 해결방안 Set 자료구조 사용(중복 허용하지 않도록) select distinct ~~~ 쿼리 사용 Reference)자바 ORM 표준 JPA 프로그래밍" }, { "title": "B-Tree", "url": "/posts/B-Tree/", "categories": "Study, Data Structure", "tags": "data structure, 자료구조, b-tree", "date": "2021-09-23 00:00:00 +0900", "snippet": ": Self-balancing tree 중 하나. 데이터베이스나 파일 시스템에서 사용되는 것으로 유명.한 블럭에 많은 데이터를 저장한다는 것이 큰 장점. 한 블럭이 1024 Byte라고 한다면 2Byte를 읽으나 1024Byte를 읽으나 입출력 1회 발생하는 비용은 같기 때문규칙 정렬된 상태이다. 자식 노드 수가 적어도 2개 이상이다. 자식 노드의 수를 최대 M개 가질 수 있을 때 M차 B-tree라고 말한다. 자식 노드가 M개 일 때 부모 노드의 key 값은 M-1개이다. Root를 제외한 모든 노드는 적어도 M/2개의 데이터를 갖는다.삽입과 삭제: 삽입 삭제 시 위의 규칙들을 전부 만족하는지를 체크한다. 삽입: 만족이 되지 않는 경우 자식 노드를 추가한다. 특히, 균형을 맞춰가며 재구성한다. 삭제: 만족이 되지 않는 경우 비어있는(M/2 이하의 데이터를 갖는) 노드는 sibling 노드와 합쳐지고 다시 조건이 만족되는지를 검사한다.B+Tree B-Tree의 변형 구조이다. leaf로 가는 경로 안내만 수행하는 non-leaf node가 존재한다. leaf 노드끼리는 연결리스트로 연결되어있다. DB indexing의 자료구조로 사용된다고 유명. 장점: DB indexing에서 hash table을 사용하지 않는 이유로 범위 탐색(쿼리에서의 where ~~ 절)을 이야기 하는데, B+Tree에서는 실 데이터인 Leaf node들간 연결리스트로 연결되어있어서 범위 탐색에 유리 단점: 항상 leaf까지 내려가야 찾고자 하는 데이터에 도달한다. (log N)Reference)https://en.wikipedia.org/wiki/B-treehttps://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Data%20Structure/B%20Tree%20%26%20B%2B%20Tree.md" }, { "title": "Node.js 디자인 패턴 2장 - 1. Callback Pattern(콜백 패턴)", "url": "/posts/Node.js_%EB%94%94%EC%9E%90%EC%9D%B8%ED%8C%A8%ED%84%B4_2%EC%9E%A5_1_Callback_Pattern/", "categories": "Study, Node.js", "tags": "node.js", "date": "2021-09-16 00:00:00 +0900", "snippet": "연속 전달방식: 연산의 결과를 콜백으로 전달하는 방식동기식 연속 전달 방식(Continuation-Passing Style): 일반적으로 아는 전달방식. 직접 스타일function add(a, b) { return a + b;}비동기 연속 전달 방식function add(a, b, callback) { setTimeout(() =&amp;gt; callback(a + b), 100);} setTimeout은 addAsync로 제어를 돌려주어 제어가 호출자에게 반환된다. 호출 시점의 컨텍스트를 유지하는 것은 Closure의 특성 덕분비 연속 전달 방식의 콜백(연속 전달 방식이 아닌 콜백)array1.map(element =&amp;gt; element - 1);// 따로 연산을 통해 callback으로 전달하는 것이 아니라, 그냥 배열의 인자를 전달 콜백이라고 항상 CPS나 비동기식이 아니다.Node.js 콜백 규칙 콜백은 맨 마지막에, 오류는 맨 앞에 fs.readFile(&#39;foo.txt&#39;, (err, data, callback) =&amp;gt; { if(err) handleError(err); else { callback(data); }}) 가독성 측면에서 좋음. err가 있으면 첫번째 인자가 Error라고 판단 오류 전파 일반적으로 비동기식 CPS에서 오류를 callback으로 전달하여 수행 오류를 전달할 때는 return callback(err) 처럼 사용해 early return 캐치되지 않는 예외 uncaughtException은 어플리케이션의 일관성을 보장할 수 없게 만든다. 비동기 콜백 내부에서 예외를 발생시키면, 그 예외는 이벤트 루프로 이동한다. ... try { const parsed = JSON.parse((err, data) =&amp;gt; { ... });} catch { // Error catch return callback(err);} ... 위의 예에서 만약 try... catch 구문이 없고 JSON.parse 에서 에러가 발생한다면, 예외가 그대로 이벤트 루프로 이동하고 다음 콜백으로 전파되지 않는다.(위의 그림 참고) 제대로 된 예외를 받고자 한다면, 예외가 발생한 스택과 실행 스택이 같아야한다. 즉, 위와같이 에러가 발생할만한 비동기 코드 내부에서 try catch 로 감싸야 한다. 위의 예시를 기준으로, try ... catch 스택과 parse((err, data) =&amp;gt; { })의 스택은 별개의 스택 그런데, uncaughtException이 만약 발생한다면, 어쨌든 어플리케이션을 종료하도록 처리하는 것이 좋다. Async Await와 관련된 처리되지 않는 에러 테스트 코드 작성 중 아래와 같은 테스트가 실패한 이유?expect(await funcThrowException()).to.be.rejectedWith(..);// 이렇게 보면 편하다.expect( // .. await funcThrowException // .. ).to.be.rejectedWith(..); await 키워드를 만나는 시점에 백그라운드로, 이후에 queue로 들어가지만 다시 call stack에 들어간 시점에 funcThrowExecption에서 던진 에러를 어디에서도 받지 못한다. 바깥의 블락(expect ... to.be.rejectedWith)에서 try ... catch로 감싸주면 에러를 잡을 수 있게 된다.Reference)Node.js 디자인패턴" }, { "title": "객체지향 설계 원칙 - SOLID 원칙", "url": "/posts/SOLID%EC%9B%90%EC%B9%99/", "categories": "Study, OOP", "tags": "oop, 객체지향", "date": "2021-09-12 00:00:00 +0900", "snippet": "1. SRP(단일 책임 원칙) S 모든 클래스는 하나의 책임만 갖고, 하나의 책임만을 갖기 때문에 그 책임을 완전히 캡슐화 캡슐화: 외부로부터 자세한 구현을 숨김 응집성 원칙에 근거 어떠한 클래스나 모듈은 변경되려는 단 하나의 이유만을 가져야 한다. e. g.) 보고서를 편집하고, 출력하는 모듈 -&amp;gt; 1. 보고서때문에, 2. 출력때문에 변경될 수 있음 분리된 두 책임이기 때문에, 클래스나 모듈로 나뉘어야 함. 변경이 있을 때, 영향이 적게 미치면 SRP대로 잘 나눈 것? 2. OCP(개방-폐쇄 원칙) 기존 코드를 변경하지 않으면서(closed), 기능을 추가할 수 있도록(open) 설계 하기 객체지향에서 가능한 동작을 단위별로 추상화를 통해 묶을 수 있음. 추상화: 데이터 명세와 구현을 분리. 인터페이스 분리 등 고정되기는 해도, 제한되지는 않게 가능한 동작끼리 묶어 추상화.3. LSP(리스코프 치환 원칙) 상위 타입의 객체를 하위 타입의 객체로 치환해도 프로그램은 정상적으로 동작해야 한다. 자식 클래스는 부모 클래스의 책임을 무시하거나 재정의하지 않고 확장만 해야함. 위반 예시 : 직사각형class로부터 정사각형 class를 파생하는 경우 정사각형 객체가 직사각형을 다루는 context에서 사용되는 경우 정사각형 크기는 독립적으로 변경 불가능. 정사각형의 “각 변이 같다”는 조건을 유지하면, 직사각형에서 “각 변은 독립적이다”라는 조건을 무력화(위반)한다. 위반을 하더라도, 위의 조건과 같은 조건이 사용이 되지 않는다면 문제가 되지 않을 수도 있긴 하다.4. ISP(인터페이스 분리 원칙) 클라이언트는 자신이 사용하지 않는 인터페이스는 구현하지(의존하지) 말아야 한다. 인터페이스들을 최대한 작은 단위(역할 인터페이스)로 분리시켜 클라이언트는 필요한 메서드만 이용할 수 있도록 e.g.) 자동차 클래스 -&amp;gt; 운전, 정비 클래스로 바꾸면, 추후 클라이언트 -&amp;gt; 운전자, 정비사 클래스로 나눌 수 있고, 하나의 변경이 다른 하나의 변경에 영향을 미치지 않는다.5. DIP(의존 역전 원칙) 고수준 모듈은 저수준 모듈의 구현에 의존해서는 안된다. 추상화에 의존, 구체화에 의존 x e.g.) JPA를 사용해 hibernete 본체에 의존하지 않는 것Reference)https://ko.wikipedia.org/wiki/SOLID_(%EA%B0%9D%EC%B2%B4%EC%A7%80%ED%96%A5%EC%84%A4%EA%B3%84)https://siyoon210.tistory.com/155https://ko.wikipedia.org/wiki/%EB%8B%A8%EC%9D%BC_%EC%B1%85%EC%9E%84_%EC%9B%90%EC%B9%99https://doublem.org/SOLID_SRP_OCP/https://hckcksrl.medium.com/solid-%EC%9B%90%EC%B9%99-182f04d0d2b" }, { "title": "Sequelize에서 DB Migration하기", "url": "/posts/Sequelize_DB_Migration/", "categories": "Study, Node.js", "tags": "node.js, sequelize", "date": "2021-09-12 00:00:00 +0900", "snippet": "Query Interface Sequlize: ORM Query interface DB와의 communication을 위함.(low level) 대부분의 Sequlize method들은 query interface의 도움을 받아 구현된다. Sequelize migration 마이그레이션: 이미 운영중인 서비스의 DB를 변경해야 할 때. 개발, 운영, 테스트 환경 등 각각 뿐 아니라 개발자마다도 버전을 다르게 가져갈 수 있고, 기존의 system의 데이터를 보존하면서 새로운 system에 맞게 변경사항 적용Module.exports = { up:function(queryInterface, Sequelize){ //Add altering commands here return promise. } down:function(queryInterface, Sequelize){ //Add reverting commands here. }}up &amp;amp; down up: DB 변경사항 적용 $ sequelize db:migrate : up에 정의된 코드 실행 down: ‘up’ 실행되기 전의 상태로 DB 복원. $ sequelize db:migrate:undo : down에 정의된 코드 실행 Trouble ShootingDocker환경에서 마이그레이션 잘 적용되지 않는 문제 -&amp;gt; Mount 디렉토리 확인 문제 상황: Model을 수정하고 마이그레이션 파일 생성해서 테스트까지 완료했는데, 다른 PC에서 500 code와 함께 컬럼이 존재하지 않는다고 에러 해결: docker 설정부의 MariaDB를 마운트하는 디렉토리 내부에 해당 PC(문제있던)에서 이미 이전의 모델들이 존재했기 때문. 컬럼값이 달라서(이미 어느정도까지 마이그레이션이 진행된 데이터들에 새롭게 하려고해서) 마이그레이션 제대로 되지 않던 것. 아래의 마운트 경로/data/mariadb 디렉토리를 지워버리고 다시 새롭게 만들기 volumes: - ./data/mariadb:/var/lib/mysql:Z Reference)https://sequelize.org/master/manual/query-interface.html" }, { "title": "가상 메모리", "url": "/posts/%EA%B0%80%EC%83%81_%EB%A9%94%EB%AA%A8%EB%A6%AC/", "categories": "Study, OS", "tags": "os, 운영체제", "date": "2021-09-10 00:00:00 +0900", "snippet": " 프로세스에 필요한 메모리 전체가 물리 메모리에 적재되지 않고도 실행할 수 있도록, 물리 메모리를 가상의 엄청나게 큰 메모리(가상 메모리) 로 추상화해서 사용하는 기법 원래는 물리 메모리에 필요한 모든 것을 적재했었음 -&amp;gt; 실행할 프로그램에 필요한 메모리가 실제 물리 메모리보다 크다면 실행이 불가하다는 문제 필요한 페이지만 메모리에, 나머지는 디스크(보조기억장치)에 저장하고, 논리 페이지를 물리 메모리의 프레임에 사상해주는 것은 MMU의 역할 논리 메모리와 물리 메모리 개념을 분리 가상 주소 공간을 제공함으로써 개발자는 물리 메모리를 신경쓰지 않고 가상 메모리만을 신경 쓰면 됨 또다른 장점: 프로세스 간 페이지 공유 각 물리 메모리 페이지들은 모든 프로세스에 공유되고 있음.가상 주소 공간 한 프로세스가 메모리에 실제로 저장되는 논리적인 모습을 구현한다. 가상 주소는 MMU(Memory Management Unit)에 의해 물리 주소로 사상(Mapping)된다. e.g) 한 프로그램이 실행되며 논리 메모리로 100KB 가 요구되었다고 할 때, 실행까지에 필요한 메모리 공간(Heap영역, Stack 영역, 코드, 데이터)의 합이 40KB 라면, 실제 물리 메모리에는 40KB 만 올라가 있고, 나머지 60KB 만큼은 필요시에 물리메모리에 요구함.요구 페이징(demand paging) 프로그램 전체를 디스크에서 메모리에 적재하지 않고 초기에 필요한 것만 적재 한번도 접근되지 않은 페이지는 물리 메모리에 적재되지 않음. 프로세스 내 개별 페이지들은 페이저에 의해 관리됨. 만약 프로세스 중 물리메모리에 올라와있지 않은 페이지가 요구되면, page fault(페이지 부재) 실제로는 참조 지역성 덕분에 페이지 부재가 잦지는 않다고 함. 참조 지역성: 시간 지역성(최근에 참조된 건 곧 다시 참조될 확률 높음), 공간 지역성(참조된 주소와 인접한 주소가 다시 참조될 확률 높음)단편화: 프로세스가 차지하는 작은 틈이 발생해 메모리 공간이 낭비되는 것내부 단편화, 외부 단편화 내부 단편화: 메모리 할당 시 프로세스가 필요로 하는 양보다 더 크게 할당되어 공간 낭비 외부 단편화: 메모리 할당 해제가 발생하면서, 서로 다른 프로세스의 공간 사이에 메모리가 비게 되는데, 다른 프로세스를 올릴 때 이 빈 공간에 나눠서 할당할 수 없어 발생하는 공간 낭비. 내부 단편화보다 치명적페이징, 세그멘테이션 페이징 물리 메모리는 균등한 사이즈의 프레임으로 나뉘게 되고, 프로세스는 프레임과 같은 균등한 사이즈의 페이지로 나뉜다. 따라서, 페이지는 작은 고정사이즈의 프로세스 조각. 마지막 프레임에는 페이지가 꽉차지 않게 될 수 있고, 이 때 적은 양의 내부 단편화 외부 단편화 없다. 페이징 테이블 필요 세그멘테이션 프로세스가 서로다른 크기의 세그먼트로 나뉜다. 외부 단편화 존재 세그먼트 테이블 필요 Reference)https://github.com/JaeYeopHan/Interview_Question_for_Beginner/tree/master/OShttps://velog.io/@gimtommang11/%EA%B0%80%EC%83%81%EB%A9%94%EB%AA%A8%EB%A6%AChttps://frontalnh.github.io/2018/04/04/%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C-%EA%B0%80%EC%83%81-%EB%A9%94%EB%AA%A8%EB%A6%AC%EB%9E%80-%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80/" }, { "title": "Sync, Async, blocking, non-blocking", "url": "/posts/%EB%8F%99%EA%B8%B0_%EB%B9%84%EB%8F%99%EA%B8%B0_block_non-block/", "categories": "Study, Node.js", "tags": "node.js", "date": "2021-09-09 00:00:00 +0900", "snippet": " 동기: 두개 이상의 작업이 시작 종료시간이 같거나 시작과 동시에 종료 (선후 관계가 확실) 비동기: 다른 작업과 시작, 종료 시점이 관계가 없다. blocking: 다른 작업 진행되는 동안 기다린다. (코드상 Return 하지않음) non blocking: 다른 작업 진행 동안 기다리지 않는다. (코드상 일단 Return)   Blocking Non-blocking Sync Read/Write Read/Write. + Polling Async I/O Multiplexing Asynchronous I/O Sync + blocking 기본적인 mvc 패턴, application에서 I/O 요청한 후 완료되기 전까지 application block된다. 메서드에서 다른 메서드를 호출해, 결과값 기다리는 것Sync + non-blocking 논 블로킹 IO에 접근하는 가장 기본적인 패턴 application에서 I/O 요청한 후 return하여 다른 작업 수행하다가 완료되었는지 틈틈히 확인해준다. 이것이 polling 방식 (busy-waiting) long polling : 응답주는 쪽에서 기다렸다가 지연 응답을 주는 것 작업 효율이 좋지 않다.Async + blocking 비효율적이다. Async + non-block 모델에서도 잘못된 코드로 인해 이와 같이 동작할 수 있다. e.g) Nodejs + Mysql. (mysql 드라이버는 blocking 방식이므로 이와 같은 문제 발생) 환경에서 쿼리 결과를 기다린다면 이러한 경우에 해당한다. 다중 I/O 서버에서 각 커넥션의 입장에서는 Async + Blocking이라고 볼 수 있다. Async + non-blocking I/O 요청 후 return해 다른 작업을 수행. 이벤트 루프 동작 방식: 완료시 이벤트가 발생하거나 미리 등록한 callback을 통해 이후 작업 진행. HTTP 커넥션 입출력하는 웹 서버에서의 다중 I/O 서버를 생각해보면 된다. 이 때 모든 커넥션들은 각각 본인의 작업만 끝나면 client에게 응답메시지로 전송되고 커넥션은 종료된다. 물론, I/O를 처리해야하는 스레드는 같은 하나의 스레드이므로, 해당 스레드가 작업중일 때 다른 작업의 커넥션들은 run loop에서 Block되지만, 웹서버 입장에서는 스레드가 Async non blocking으로 잘 수행한다고 볼 수 있다.Reference)https://deveric.tistory.com/99https://yorr.tistory.com/20" }, { "title": "Node.js 디자인 패턴 1장 - 3. Reactor 패턴을 통한 Non-blocking 처리", "url": "/posts/Node.js_%EB%94%94%EC%9E%90%EC%9D%B8%ED%8C%A8%ED%84%B4_1%EC%9E%A5_3_Reactor_Pattern/", "categories": "Study, Node.js", "tags": "node.js", "date": "2021-09-05 00:00:00 +0900", "snippet": ": 리소스(기다리고 있던 DB의 목적 리소스)에서 새 이벤트를 사용할 수 있을때까지 디멀티플렉서가 차단되다가, 처리된 다음 이벤트 큐로 전해지고, 이벤트 루프에 의해 핸들러가 호출되어 반응하는 것이벤트 디멀티플렉싱: Non-blocking 리소스를 처리하기 위한 기본적인 메커니즘 Disk I/O작업은 기본적으로 블로킹 I/O인데, 이걸 매번 block시키면 해당 스레드의 유휴시간이 길어지기 때문에 효율적으로 바꿔야 한다. 하나의 연결은 한 thread로 처리되는데, block이 많으면 위와같이 유휴시간이 길어진다. 동시성을 위해서 각 연결 당 스레드 풀에서 스레드 가져와 할당해줄텐데, 이처럼 스레드 낭비(유휴시간)이 많다면 메모리를 소비하고 context switch를 유발하고, 낭비이다. 따라서, 각 연결당 짧은 연결을 가지면서 context swtich를 유발하지 않는 것이 좋다. Non-blocking으로 만드는 방법 Polling 방식: 매번 리소스를 받았는지 계속 확인하는 것은 Busy waiting이고, CPU를 계속 사용해야 해서 비효율적이다. 동기 이벤트 디멀티플렉서: 감시중인 리소스들로부터 들어오는 I/O 이벤트를 이벤트 큐에 넣고, 처리할 새 이벤트 있을때까지 다시 차단Reactor 패턴: 각 I/O 작업과 관련된 핸들러를 갖는 것. Javascript의 Callback은 리액터 패턴의 핸들러를 구현한 것. 이벤트가 생성되어 디멀티플렉서에 의해 이벤트 큐로 전해지고, 이벤트 루프에 의해 처리되는 즉시 각 핸들러는 호출된다. 핸들러는 (5a)실행을 완료해 이벤트 루프에 제어를 반환할 수도, 혹은 새로운 비동기 요청(5b)이 발생해, 제어가 이벤트 루프로 돌아가기 전에디멀티플렉서에 새로운 이벤트를 등록(1)할 수도 있다. 디멀티플렉서에 의해 처리 될 일이 없고, 이벤트 큐가 비어있게 되면 Node.js 어플리케이션은 끝난다.libuv: 운영체제마다 이벤트 디멀티플렉서를 위한 자체 인터페이스가 있으나, 불일치가 있을 수 있다. libuv라는 C 라이브러리를 통해 기본 시스템 호출을 추상화해, 문제를 해결 또한, 해당 libuv는 Reactor 패턴을 구현하고 있어 이벤트 루프 생성, 이벤트 큐 관리 등에 대한 API를 제공한다.Reference)Node.js 디자인패턴" }, { "title": "스케줄링과 스케줄러", "url": "/posts/%EC%8A%A4%EC%BC%80%EC%A4%84%EB%A7%81_%EC%8A%A4%EC%BC%80%EC%A4%84%EB%9F%AC/", "categories": "Study, OS", "tags": "os, 운영체제", "date": "2021-09-03 00:00:00 +0900", "snippet": ": 프로세스에게 CPU 등의 자원을 적절히 배정하는 것Queue: 프로세스 스케줄링에 사용되는 큐 Job Queue: 현재 시스템 내의 모든 프로세스 집합 Ready Queue: 현재 메모리 내에 있고, CPU 할당을 기다리고 있는 프로세스 집합 Device Queue: Device I/O 작업을 대기하고 있는 프로세스 집합장기 스케줄러: 어떤 프로세스를 Ready Queue(메모리)로 보낼지 결정. swap-in 메모리와 디스크 사이 스케줄링 일단 많은 프로세스가 한번에 올라오면, 대용량 메모리(디스크)에 임시로 저장되고, 이걸 적절히 메모리로 올려야 함. 메모리는 한정되어있기 때문에 적절한 스케줄링 필요 실행중인 프로세스 수 제어하는 역할(degree of Multi-programming) new -&amp;gt; ready 상태단기 스케줄러: 어떤 프로세스를 실행할지(Running) 결정. 따라서, 프로세스에 CPU 를 할당(scheduler dispatch) CPU 와 메모리 사이 스케줄링 Ready Queue에 존재하는 프로세스 중 어떤 프로세스를 running 시킬지 ready -&amp;gt; running -&amp;gt; waiting -&amp;gt; ready중기 스케줄러: 어떤 프로세스를 메모리에서 디스크로 쫓아낼지 결정 메모리 공간 확보를 위해 디스크로 swap-out 프로세스에게서 memory를 deallocate 실행중인 프로세스 수 제어하는 역할(degree of Multi-programming) ready -&amp;gt; suspended (job queue로?) 대부분의 OS에서는 우선순위 알고리즘이나 Round Robin 혼합해서 사용한다고 함Reference)https://github.com/JaeYeopHan/Interview_Question_for_Beginner/tree/master/OS#cpu-%EC%8A%A4%EC%BC%80%EC%A4%84%EB%9F%AC" }, { "title": "Node.js 디자인 패턴 1장 - 2. ES2015(ES6 이후)에서 달라진 점", "url": "/posts/Node.js_%EB%94%94%EC%9E%90%EC%9D%B8%ED%8C%A8%ED%84%B4_1%EC%9E%A5_2_ES2015_JS/", "categories": "Study, Node.js", "tags": "node.js", "date": "2021-09-03 00:00:00 +0900", "snippet": "var, let, constvar 변수 재선언, 재할당 가능 Function scope if문에서 선언하면 block이기 때문에 전역변수 함수 내부라면 블록 밖이라도 참조 가능 함수 내부에서 var로 선언한 것은 함수 내부까지만 hoisting var hoisting 방지를 위해 ‘use strict’(ES2015) let ES2015에서(이전에는 ES6라고 함) var을 보완하기 위해 나옴 block scope 이게 있기 전에는 if문 내부 변수는 밖에서 액세스 가능했다. 재선언 불가, 재할당 가능const ES2015에서(이전에는 ES6라고 함) var을 보완하기 위해 나옴 기본적으로 const를 지향 block scope 재선언 불가, 재할당 불가 상수의 경우 const로 선언 완전 불변 객체를 만들고싶으면 const만으로 충분하지 않다. Object.freeze() or deep-freeze 모듈을 사용해야 한다. -&amp;gt; 객체 속성조차 변경 불가 대문자 상수: const COLOR_RED = &quot;F00&quot;;arrow function 간결하다. -&amp;gt; 직관적 A.map( function cb(element) { return element.length; }); A.map((element) =&amp;gt; element.length); this의 범위가 어휘 범위(lexical scope)로 바인딩 // with arrow functionfunction Person(){ this.age = 0; setInterval(() =&amp;gt; { this.age++; // this는 person 객체(window)를 참조 }, 1000);} var p = new Person(); // without arrow functionsetInterval( function cb() { this.age++; // 이 경우 this는 undefined. 따라서 this.age도 undefined}, 1000); 클래스 구문// 기존의 방식function Person(name, age) { this.name = name; this.age = age;}Person.prototype.getFullName = function() { return this.name + &#39;&#39; + this.surname;}Person.older = function(person1, person2) { return (person1.age &amp;gt;= person2.age) ? person1 : person2;}// ES2015부터의 방식class Person { constructor (name, age) { this.name = name; this.age = age; } getName() { return this.name; } static older (person1, person2) { return (person1.age &amp;gt;= person2.age) ? person1 : person2; }} ES2015에서 생겼지만, 여전히 내부적으로는 전통적인 prototype이 사용 됨 런타임에 의해 내부적으로 객체가 관리되는 방식이 달라진 것이 아님 차이점: 기존과는 다르게, super, extends 키워드를 통해 Person 프로토타입을 확장할 수 있다는 점객체 리터럴 새로운 형태의 getter, setterconst person = { name: &#39;AA&#39;, get name() { return this.name; } set name(name) { this.name = name; } validate: (): void =&amp;gt; { //something }}console.log(person.name)person.validate()module.exports = { square(x) { return x * x; }}이 외 Map, Set, 콜렉션 WeekMap, WeekSet 콜렉션: 객체만을 키로 가질 수 있다. -&amp;gt; 해당 Week collection 내 유일 참조가 남을 경우 GC에 의해 삭제 Template 표기법 - 백틱을 통해 변수 삽입Reference)Node.js 디자인 패턴" }, { "title": "Data class", "url": "/posts/Data_Class/", "categories": "Study, Kotlin", "tags": "kotlin", "date": "2021-09-03 00:00:00 +0900", "snippet": ": 보통 DTO 등 데이터를 보관하기 위한 목적으로 사용할 때 Kotlin에서는 Data class로 선언해 사용한다. JPA 사용 시 Kotlin에서는 entity를 data class로 선언하지 않는다. Entity는 그냥 class로, 어노테이션을 사용해서. 주로 DTO나 VO를 목적으로 data class를 사용하는 것으로 보인다.특징 코틀린은 기본적으로 상속을 막아놓고 open keyword를 추가해 상속 가능한 class로 변경할 수 있다. 그런데, data class에서는 open keyword 조차 불가능하다. 애초에 상속을 받는 것을 목적으로 만든 클래스가 아니기 때문 위와 마찬가지로 abstract, inner 키워드도 불가능하다. primary constructor가 있어야한다. -&amp;gt; data clarr Foo( //here) 컴파일러가 primary constructor에 선언된 모든 프로퍼티들에 대해 여러 메소드들을 제공한다.자동 생성 메소드: 이 메서드들은 data class 생성 시점에 자동으로 만들어진다. hashCode(): 객체의 주소값을 해싱해서 생성한 객체마다 갖는 고유의 값. 따라서, 같은 객체인지 판별할 때 쓰인다. equals(): 객체가 담고있는 내용이 같은지를 검사한다. hashCode 구분. toString() componentN(): JavaScript의 구조 분해 할당처럼 쓰이는 것 같다. // 구조 분해 할당val (name, age) = person // componentN() 이용. 선언한 순서대로 숫자가 들어가야 한다.val name = person.component1()val age = person.component2() copy(): 어떠한 객체의 내용을 그대로 복사해 사용할 수 있게 해준다. 사이드 이펙트를 없애고 새로 만들어버림 (함수형의 패러다임에 어울리는 메소드인 것 같다.) fun copy(name: String = this.name, age: Int = this.age) = User(name, age) val jack = User(name = &quot;Jack&quot;, age = 1)val olderJack = jack.copy(age = 2) Reference)https://kotlinlang.org/docs/data-classes.html" }, { "title": "Node.js 디자인 패턴 1장 - 1. Node.js란?", "url": "/posts/Node.js_%EB%94%94%EC%9E%90%EC%9D%B8%ED%8C%A8%ED%84%B4_1%EC%9E%A5_1_Node.js_%EB%9E%80/", "categories": "Study, Node.js", "tags": "node.js", "date": "2021-09-02 00:00:00 +0900", "snippet": " Javascript가 서버에서 동작될 수 있도록 하는 그러한 환경(플랫폼) 구글이 크롬 브라우저 용으로 개발한 V8 JavaScript 엔진으로 빌드된 JS 런타임기특징 Nods.js 라이브러리 내의 api는 모두 비동기 단일 스레드. 이벤트 메커니즘을 통해 서버가 멈추지 않으며 실시간 데이터 애플리케이션, SPA, I/O 잦은 앱개발에 효율적 여기서 I/O작업이란? 파일 시스템 접근, DB 접근, 네트워크 요청과 같은 작업. 컴퓨터의 기본적인 동작 중 가장 느리다. 느린 이유? 요청을 보낸순간부터 완료될때까지 지연되기 때문 이것을 해결하기 위한 것 Non blocking + Sync : 폴링방식으로 busy waiting하기 Non blocking + Async : 이벤트 루프 하나의 작업 자체가 오래걸리면 전체 성능 저하. (싱글스레드 이기 때문)Node.js의 철학: JS나 Unix 체제의 공통적인 철학(경량)에 뿌리를 둔다.​ 다른 소프트웨어 개발 철학들 모음: https://en.wikipedia.org/wiki/List_of_software_development_philosophies경량 코어: Node.js 그 자체만으로는 정말 최소의 기능만하도록 최소한으로 유지경량 모듈: 필요한 패키지만을 npm을 통해 관리가능 패키지간 의존성 없이 관리, 재사용성을 높게 유지 아주 작은 단위의 코드 조각(패키지)조차도 재사용 -&amp;gt; DRY원칙작은 외부 인터페이스: 최소한의 기능만을 export로 노출 가능간결함과 실용주의: 단순한 설계 추구 JS의 철학. 객체지향의 복잡성을 버리고 합리적인 수준의 복잡성으로, 높은 생산성을 지향 KISS 원칙Node의 주요 도구(패키지) 확장을 잠가 확장성을 줄이더라도, 단순한 구현과 유지 용이, 가용성을 높이는 것이 목적Http 모듈 HTTP 통신으로 데이터를 주고 받을 수 있는 프로토콜 createServer를 통해 server 객체 생성(웹서버 객체) Express 외장 모듈(npm으로 다운) package.json : 모듈 버전, 의존 패키지 관리(npm 이용) Routing: app.js로 routing 역할 수행 URI 및 특정 HTTP 요청메소드인 특정 엔드포인트에 대한 요청에 application이 응답하는 방법을 결정 앱 구동Sequelize DB와 연동할 때 객체와 테이블을 매핑해주는 ORM 이걸 이용하면 객체의 메서드를 통해 쿼리를 조작함. sql 문법을 모르더라도. create(), findOne(), findAll(), update(), destroy() 등 Reference)Node.js 디자인패턴https://velog.io/@new_wisdom/Node.js-SOPT-%EB%A9%B4%EC%A0%91-%EC%A4%80%EB%B9%84" }, { "title": "웹 스토리지(세션 스토리지, 로컬 스토리지)", "url": "/posts/%EC%9B%B9_%EC%8A%A4%ED%86%A0%EB%A6%AC%EC%A7%80(%EB%A1%9C%EC%BB%AC_%EC%8A%A4%ED%86%A0%EB%A6%AC%EC%A7%80_%EC%84%B8%EC%85%98_%EC%8A%A4%ED%86%A0%EB%A6%AC%EC%A7%80)/", "categories": "Study, Network", "tags": "network", "date": "2021-09-01 00:00:00 +0900", "snippet": ": 쿠키의 단점을 보완하고, 서버가 아닌 클라이언트에 데이터를 저장할 수 있도록 HTML5에서 나온 기술. 따라서, HTML5를 지원하지 않는 브라우저에선 사용 불가능. Key-value 형태이고, 쿠키와 다르게 5MB까지 저장(브라우저마다 용량 차이 있음) 쿠키와 달리, 서버에 매번 전송되지 않아 서버 처리를 줄인다. 쿠키와 달리, 필요할 때만 꺼내 쓰는 것.(자동전송의 위험성이 없음) 유효기간 존재하지 않는다. 세션, 로컬 스토리지 존재 둘 다 window 객체 안에 있음. 둘의 차이는 저장 위치와 데이터 영구성의 차이 로컬 스토리지(반영구적) window.localStorage 객체 브라우저를 종료해도 계속 브라우저에 남아있고, 명시적으로 지우지 않는 한 영구적으로 저장. 도메인별로 생성되어 도메인(origin)이 같은 탭, 창 전체에서 이 storage를 공유 다른 도메인의 로컬 스토리지에는 접근 불가하다. 서로 다른 탭이라도, 같은 도메인이면 동일한 로컬 스토리지 사용 지속적으로 필요한 정보에 사용하기 좋음 e.g) 자동 로그인 등 로컬 스토리지 저장 경로인 ~/.config/google-chrome/Default/Local Storage/leveldb 가보면 leveldb로 저장되어있는 것을 볼 수 있다. filefox의 경우 sqlite로 저장되어있다고 한다.세션 스토리지 window.sessionStorage 객체 쿠키와 달리, 탭/윈도우 단위로 세션 스토리지 생성 즉, window 객체와 동일한 life cycle을 가져 윈도우나 브라우저 탭을 닫을 경우 제거 동일한 탭/윈도우라도, 다른 도메인이라면 또다른 세션 스토리지가 생성된다. 따라서, 세션 스토리지는 독립적(서로 영향이 없음) 윈도우 복제로 생성된 경우 세션 스토리지가 복제되어 생성 잠시동안 필요한 정보를 저장하기에 좋음 e.g) 입력했던 폼 저장, 비로그인 장바구니 Reference)https://www.zerocho.com/category/HTML&amp;amp;DOM/post/5918515b1ed39f00182d3048https://tristan91.tistory.com/521https://it-eldorado.tistory.com/90https://velog.io/@kler/TIL4-%EB%A1%9C%EC%BB%AC%EC%8A%A4%ED%86%A0%EB%A6%AC%EC%A7%80-%EC%84%B8%EC%85%98%EC%8A%A4%ED%86%A0%EB%A6%AC%EC%A7%80-%EC%BF%A0%ED%82%A4-%EC%A0%95%EB%A6%AC" }, { "title": "페이지 부재와 교체", "url": "/posts/Page_fault/", "categories": "Study, OS", "tags": "os, 운영체제", "date": "2021-08-25 00:00:00 +0900", "snippet": "페이지 부재 과정: MMU가 OS에게 제어권을 넘겨 Disk(보조기억장치)에서 가져오는 과정 실행되는 Process에서 필요한 프레임(페이지)를 가져오기 위해 Page Table을 봤는데, i(invalid)로 되어있으면, OS에게 페이지를 찾아올 것을 요청 OS가 디스크에서 필요한 페이지의 위치 찾음 페이지를 가져온다. 물리메모리에 빈 프레임이 있으면 저장. 그런데, 프레임이 존재하지 않으면 페이지 교체 발생 페이지 교체 알고리즘을 통해 내려갈(swap out) victim 페이지를 고른다. 해당 페이지를 디스크에 기록하고, 관련 페이지 테이블을 수정한다. 이 때 victim 프레임 swap out, 페이지 swap in 하는 두번의 디스크 접근이라 오버헤드일 수 있어, 줄여야함. 모든 페이지마다 변경 bit를 주고, 확인해서 변경된건 어차피 disk에 적용해야하기 때문에 선택 다른 페이지 교체 알고리즘 페이지 테이블에 valid 값 설정해주고 명령어 재시작(시작 위치 프로그램 카운터 참고)페이지 테이블페이지 교체 알고리즘 FIFO : 가장 오래된것 내리기 이해하기 쉬우나, 오래된 페이지가 항상 필요하지 않다는 것을 보장할 수 없으며 효율이 좋지 않음 Belady의 모순: 물리메모리에 페이지를 저장할 수 있는 프레임 갯수를 늘리면 page fault가 줄을 것이라 생각했지만, 오히려 page fault가 많아지는 것 오래되어서 디스크로 내렸는데 사실은 그 페이지가 앞으로 많이 사용될 페이지인 경우. 따라서 항상 그런것은 아니다. OPT(최적 페이지 교체): 앞으로 가장 오랫동안 사용되지 않을 페이지 내리기 가장 효율이 좋으나, 실제에서는 불가능함. 보통 연구 목적으로 사용한다고 함. Belady의 모순을 해결 LRU: 가장 오랫동안 참조(사용)되지 않은 페이지 내리기 FIFO보단 좋고, OPT보단 좋지 않다고 함. 앞으로 사용될 것을 예측할 순 없겠지만, 실제로는 지역성이라는 개념이 있어, 실제로는 이게 적합하다고 함 Belady 모순 없음 LFU: 가장 적게 사용된 페이지 내리기 특정 페이지가 초반에만 집중적으로 사용되었으면, 이제 더 이상 사용되지 않더라도 계속 메모리에 머물게 되는 문제. 잘 쓰이지 않음 Reference)https://github.com/JaeYeopHan/Interview_Question_for_Beginner/tree/master/OShttps://velog.io/@gimtommang11/%EA%B0%80%EC%83%81%EB%A9%94%EB%AA%A8%EB%A6%AChttps://frontalnh.github.io/2018/04/04/%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C-%EA%B0%80%EC%83%81-%EB%A9%94%EB%AA%A8%EB%A6%AC%EB%9E%80-%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80/" }, { "title": "Git 델타와 스냅샷", "url": "/posts/Git_%EB%8D%B8%ED%83%80_%EC%8A%A4%EB%83%85%EC%83%B7/", "categories": "Study, Git", "tags": "git, commit, delta, snap shot", "date": "2021-08-25 00:00:00 +0900", "snippet": "Git: 델타와 스냅샷: git에서 커밋을 저장하는 방식 과거에는 오픈소스 프로젝트를 diff와 patch를 통해 개발했다. 코드를 수정하고 diff 프로그램으로 델타를 생성해 전달하고 patch 프로그램으로 메인 코드에 적용했다고 한다. 현재는 git을 사용하면 스냅샷과 델타를 통해 변화된 사항을 관리한다. 한 브랜치의 히스토리에서 보이는 커밋은 델타 혹은 스냅샷 델타란?: 커밋과 커밋 사이에서 변경된 사항을 델타라고 한다. git push를 했을 때 몇개의 델타가 있는지를 보여준다. 모든 commit을 스냅샷으로 저장하면, 변동사항이 없는 부분까지 중복으로 관리하는 것이 되기 때문에 이러한 방식으로 관리 git diff를 쳐서 봤던 것이 델타 commit 1 -&amp;gt; commit 2 -&amp;gt; commit 3 이라고 할 때 git diff commit3 commit1 와 같은 요청을 하면, commit 2 델타(diff)와 commit 1 델타를 적용해서 반환해주는 것 그렇다면 어느 시점에 델타로 변할까?델타가 되는 시점 일단 커밋 하나가 있다면 이는 스냅샷으로 저장된다. 추후에 데몬스레드에서 돌고있는 GC에 의해 적정 시점에 기존의 사항들이 델타로 변경되는 것 뿐만 아니라, gzip으로 압축해 저장하기 때문에 실제로는 아주 효율적이라고 함 git gc : 데몬스레드에 의해서가 아니라 직접 gc를 돌리고 싶다면 이 CLI를 사용 직접 저장공간을 압축한 것 GC가 돌면서, 마지막 버전의 커밋만 스냅샷으로 두고, 나머지는 델타가 된다. 대부분의 경우 우리가 날리는 질의는 마지막 버전에 대한것이기 때문에 그런데, 어떠한 경우에도 마지막 버전만 스냅샷, 나머지는 델타인 것은 아니다. 모든 변경사항을 델타로만 저장하기에는, 변경된 부분이 너무많을 때 오히려 스냅샷으로 저장하는게 이득인 경우 TODO : 직접 확인해보기 git verify-pack -v .git/objects/pack/pack-~~~ 제대로 보는 법 알아보기 Reference)http://dogfeet.github.io/articles/2012/git-delta.html" }, { "title": "Squash로 commit 통합하기", "url": "/posts/Squash%EC%99%80_commit_%ED%86%B5%ED%95%A9/", "categories": "Study, Git", "tags": "git, commit", "date": "2021-08-23 00:00:00 +0900", "snippet": " Rebase를 해야하는데, rebase적용해야할 source 브랜치 커밋이 긴 경우, 그리고 충돌이 많을 것 같을때 하나하나 컨플릭 해결하는 것은 너무 많은 일을 해야한다. Rebase 말고 그냥 merge 기존 commit을 Squash해, 하나의 커밋으로 통합하고 rebase 위 두 가지 방법이 좋아보이는데, 2번의 방법을 사용. 기존 팀프로젝트에서 github에서 리뷰 후 merge할때 squash는 사용해봤지만, CLI로 해보려니 방법을 몰라 헤맸다..과정 커밋이 합쳐지기 전인 이전 버전을 추후에 사용할 수 있으니, temp/~~~ 와 같이 새로운 branch를 만들어서 하는 것이 좋을 것 같다. 일단 커밋 로그를 찍어보면 (git log --oneline) 이렇게 보이긴 하는데,내가 작업한 commit 중 아래의 보이는 32개의 commit을 합치려 한다. 세어보면 32개 git rebase -i HEAD~32 (-i == --interactive) 하면 아래와 같이 나온다. pick(사용할 커밋) : 사용할 커밋을 pick으로 표시 squash(사용하지만 통합) : 사용하지만 통합할 커밋을 squash로 표시 나의 경우 하나만 빼고 다 통합이니까 가장 위에꺼(가장 오래된 것) 하나를 reword로 적절히 네이밍해주고, 나머지는 전부 squash 완료 " }, { "title": "비밀번호 대신 PAT(Personal Access Token) 받아 사용하기", "url": "/posts/Access_Token_%EC%82%AC%EC%9A%A9/", "categories": "Study, Git", "tags": "git", "date": "2021-08-15 00:00:00 +0900", "snippet": " 깃헙 레포지토리에 push했더니 위와같은 에러가 있었는데, 알고 보니 21년 8/13 이후로 깃헙이 더이상 비밀번호 인증방식을 사용하지 않는 것 같다. 1. 액세스 토큰 받기1) 깃헙 로그인 후 Settings - developer settings Personal access tokens 토큰 생성하기 Note에 description 적어주고, expiration 기간 설정, scope는 귀찮으니 다 체크 해주면 된다. 예시용 토큰 키값 나중에 필요할수있으니 갖고있기!?!?!?????2. (Mac) 키 체인 접근Reference)https://stackoverflow.com/questions/68775869/support-for-password-authentication-was-removed-please-use-a-personal-access-to" }, { "title": "코딩 인터뷰 완전분석 - 트리(Tree)와 그래프(Graph)", "url": "/posts/%EC%BD%94%EB%94%A9_%EC%9D%B8%ED%84%B0%EB%B7%B0_%EC%99%84%EC%A0%84%EB%B6%84%EC%84%9D-%ED%8A%B8%EB%A6%AC_%EA%B7%B8%EB%9E%98%ED%94%84/", "categories": "Study, Data Structure", "tags": "data structure, 자료구조, tree, graph, 트리, 그래프", "date": "2021-08-14 00:00:00 +0900", "snippet": ": 그래프의 한 종류로, Root 노드를 기준으로 노드간 Edge로 연결된 트리모양의 자료구조트리 조건 하나의 루트노드를 갖는다. 0개 이상의 자식 node를 갖는다. 자식 node는 또 재귀적으로 0개 이상의 자식 node를 갖는다. cycle이 존재하지 않는다. 서로 다른 두 node간 경로는 오직 한 가지 존재한다. 그래프의 한 종류이다. 트리는 사이클이 없는 하나의 연결 그래프이다. 특정 노드에서 다른 모든 노드로 접근 가능면접에서의 트리: 일반적으로 세부사항이 모호하거나 가정 자체가 틀린 경우가 많다. 필요에 따라 요구사항을 명확하게 물어보기 트리 vs 이진 트리: 이진, 삼진, … 을 명확하게 구분 이진 트리 vs 이진 탐색 트리: 이진트리를 제시 받았을 때 정렬되어있는가 아닌가의 차이를 명확하게 구분 균형 vs 비균형: 비균형의 경우 일반적으로 알려진 복잡도의 효율을 기대하기 어렵다. 탐색 - log N과 선형(N)의 차이 균형을 맞추기 위한 레드-블랙 트리와 AVL 트리가 있다. 이진 힙: 최소 힙과 최대 힙핵심 연산 삽입 언제나 밑바닥에 삽입 최소(최대) 힙을 만족하는지 확인 후 Root노드와 새 노드 위치 변경하는 방식 제거 - 최소 원소 뽑아내기(최소 힙의 경우) Root를 제거한 후 가장 leaf의 노드를 Root에 채워넣기 최소(최대) 힙을 만족하는지 확인 후 Root 노드를 자식 노드 중 하나와 교환(더 조건에 부합하는 노드) 트라이: 접두사 트리.(prefix tree) 각 노드에 문자를 저장한다. 아래쪽부터 순회하면 단어 하나가 나오게 된다. null node(* node)를 만나면 단어의 끝이라고 판단. 위의 그림에서 각 단어(to, tea, ten 등)의 자식 노드에는 * 노드가 존재할 것 접두사를 빠르게 찾아보기 위한 흔한 방식 e.g) “github”이라는 단어를 찾으려고 하는데 “gi”까지 검색했을 때 “gi” 라는 접두사를 갖는 단어가 무엇이 있는지를 찾으려고 할 때 그래프: 단순히 Node와, 그 Node를 edge로 모아놓은 것 방향성이 있을 수도, 없을 수도 있다. 순환 그래프, 비순환 그래프 존재인접 리스트: 그래프를 표현하는 일반적인 방법 모든 정점을 리스트에 저장한다. 무방향 그래프라면 간선은 두번 저장된다.(a-&amp;gt;b, b-&amp;gt;a) 트리에선 한 트리 내의 특정 노드에서 다른 모든 노드로 접근이 가능했지만, (방향이 있는)그래프에선 불가능한 경우가 있다. 배열이나 연결리스트를 이용해 인접 리스트 표현 가능인접 행렬 NxN 불리언 행렬로, matrix[i][j] 가 true이면 i에서 j로 간선이 있다는 뜻 무방향이라면 대칭 행렬일 것이고, 방향이라면 대칭이지 않을 수 있다.탐색 방법 - BFS, DFS 사용되는 자료구조가 다를 수 있음(큐, 스택) 이전에 방문했는지를 반드시 체크해야한다.(무한루프방지) 전위, 후위, 중위 순회의 경우 DFS에 속한다고 보면 된다.예상 문제트리에서 각 레벨에 존재하는 노드를 연결리스트로 연결해주는 알고리즘 설계 레벨 갯수가 D라면 D개의 연결 리스트가 존재해야한다. 현재 순회중인 노드의 깊이만 알 수 있으면 그 깊이인 n번째의 연결리스트에 추가하면 된다.균형 확인 - 이진트리가 균형이 잡혀있는지를 확인하자 Root부터 시작해 왼쪽, 오른쪽 노드의 길이 차가 1 이하인지 재귀적으로 확인한다.Reference)코딩 인터뷰 완전분석" }, { "title": "코딩 인터뷰 완전분석 - 연결 리스트(Linked list)", "url": "/posts/%EC%BD%94%EB%94%A9_%EC%9D%B8%ED%84%B0%EB%B7%B0_%EC%99%84%EC%A0%84%EB%B6%84%EC%84%9D-%EC%97%B0%EA%B2%B0_%EB%A6%AC%EC%8A%A4%ED%8A%B8/", "categories": "Study, Data Structure", "tags": "data structure, 자료구조, linked list, list", "date": "2021-08-13 00:00:00 +0900", "snippet": "특징 삽입, 삭제가 O(1)시간에 가능하다는 장점 조회에는 O(n)의 선형시간 (최악의 경우) 단방향, 양방향 연결 리스트 가능 해시 테이블의 chaining 기법은 해싱한 한 Key에 대해 value 리스트(여러 value)를 갖는데, 연결리스트를 이용하는 것Runner 기법: current 노드를 가리키는 포인터와, current부터 tail 노드까지 순회하는 포인터로 구성. 기본적으로 알고리즘 작성 시 O(N^2)여러가지 연결리스트 문제중간 노드 삭제: n1은 next를 찾아가고, n2는 next의 next(두번 점프)를 찾아가도록 구성하면 n2가 tail에 다다른 시점에 n1은 리스트의 가운데 노드를 가리키게 되는 것을 이용 slow runner, fast runner두 연결리스트의 합// (7 -&amp;gt; 1 -&amp;gt; 6) + (5 -&amp;gt; 9 -&amp;gt; 6)// 2 -&amp;gt; 1 -&amp;gt; 9 // 즉, 912// 재귀를 이용하는 방법Node addList(Node* n1, Node* n2, int carry) { if(n1 == NULL &amp;amp;&amp;amp; n2 == NULL &amp;amp;&amp;amp; carry == 0) { return NULL; } Node* node = new Node(); node.data += carry; node.data += n1 == NULL ? 0 : n1.data; node.data += n2 == NULL ? 0 : n2.data; carry = node.data / 10; node.data %= 10; node.next = addList( n1 == NULL ? NULL : n1.next, n2 == NULL ? NULL : n2.next, carry == 0 ? 0 : 1 ); return node;}// 순서를 반대로 한 경우struct prevResult { Node* node = NULL; int carry = 0;};prevResult getPrevResult(Node* n1, Node* n2) { bnm if(n1 == NULL &amp;amp;&amp;amp; n2 == NULL) { return new prevResult(); } prevResult* prevNode = getPrevResult( n1.next == NULL ? NULL : n1.next, n2.next == NULL ? NULL : n2.next ); Node* cur = new Node(); cur.data += prevNode.carry; cur.data += n1 != NULL ? n1.data : 0; cur.data += n2 != NULL ? n2.data : 0; int carry = cur.data /= 10; cur.data %= 10; cur.next = prevNode.node; prevResult curResult = new prevNode(); curResult.node = cur; curResult.carry = carry; return curResult;}Node getResult(Node* head1, Node* head2) { prevResult* headResult = getPrevResult(head1, head2); return headResult;}연결리스트가 팰린드롬인지 확인하기// #1 stack 사용 - reverse 방향을 스택에 쌓기stack&amp;lt;char&amp;gt; reversed;void stackReversed(Node* cur) { if(cur.next == NULL) { return; } reversed.push(cur.data); stackReversed(cur.next); return;}bool isPalindrome(Node* head) { stackReversed(head); int size = reversed.size(); Node* left = head; while(size / 2 == reversed.size()) { char rightData = reversed.top(); reversed.pop(); if(left.data != rightData) { return false; } } return true;}// #2 역방향 연결리스트 만들기Node* getReversed(Node&amp;amp; cur) { if(cur.next == NULL) { return cur; } Node node = new Node(); node.next = getReversed(cur); return node;}bool isPalindrome(Node* head) { Node* tail = getReversed(head); // 길이를 알면 절반만 순회하도록 개선 가능 while(tail != NULL &amp;amp;&amp;amp; head != NULL) { if(tail.data != head.data) { return false; } } return true;}두 연결리스트의 교집합: 두 연결리스트가 합쳐지는 어떤 접점노드가 있다는 뜻 방법 1. 모든 노드(주소값)를 해시에 넣어 중복값이 있는 것을 확인하기 방법 2. 두 리스트를 단순히 조회해서 tail이 같은 노드인지를 확인연결리스트에 루프 존재유무 판별하기 방법 1. 주소값을 해시에 넣어 이미 조회한 노드인지를 확인 방법 2(책 해법). slow runner와 fast runner를 돌려 충돌하는지를 확인 건너뛰지 않을까 생각했지만, 직접 시나리오를 생각해보면 그런 경우는 존재하지 않는다. Reference)코딩 인터뷰 완전분석" }, { "title": "코딩 인터뷰 완전분석 - 해시 테이블", "url": "/posts/%EC%BD%94%EB%94%A9_%EC%9D%B8%ED%84%B0%EB%B7%B0_%EC%99%84%EC%A0%84%EB%B6%84%EC%84%9D-%ED%95%B4%EC%8B%9C%ED%85%8C%EC%9D%B4%EB%B8%94/", "categories": "Study, Data Structure", "tags": "data structure, 자료구조, hash", "date": "2021-08-07 00:00:00 +0900", "snippet": ": 효율적으로 탐색을 하기 위한 알고리즘. Key - Value 쌍의 자료구조 일반적으로 Chaining을 통해 구현한 해시테이블을 말한다. 충돌이 발생한다면 최악의 경우 O(N)(연결리스트를 가정)이 된다.(N은 버킷 내의 키값 개수) 일반적으로 충돌이 발생하지 않도록 구현해 O(1) 과정: 키의 해시코드를 계산 후 hash(key) % array_length 과 같이 배열 인덱스(버킷 주소)를 구한다. 배열의 인덱스에는 일반적으로 연결리스트 혹은 이진 탐색 트리 가 존재한다. 그 인덱스에 해당하는 자료구조를 탐색하면 된다. Java의 경우 해시테이블은 1~7까지는 연결리스트, 8부터 이진 트리로 변경한다. 또 다시 6으로 줄어드는 순간 연결 리스트로 변경하는데, 2의 차이를 둔 것은 자료구조 변경에 대한 오버헤드를 고려해 최대한 변화를 적게 두기 위함. ` 실제 키 / 버킷의 개수` 비가 1을 넘으면 조회의 성능이 안좋아지고(한 버킷으로 맵핑되는 키가 많아진다), 0에 가까울수록 낭비가 심하다.(맵핑을 받지 않는 버킷이 많아진다) 0.7정도가 적당하다고 한다.ChainingOpen addressing 선형 탐사(linear probing)과 제곱 탐사(Quadratic probing)가 존재. 선형 탐사의 경우, 충돌 시 정해진 폭(예를들어 1)으로 인덱스를 탐사. 특정 해시값 주변이 모두 채워져있는 경우(primary clusturing)에 취약 제곱 탐사의 경우, 충돌 시 해당 수의 제곱 으로 인덱스 탐사(idx 4 -&amp;gt; 16으로 탐사) 서로 다른 키들이 동일한 해시값을 갖는 경우(secondary clusturing) 에 취약 이중 해싱: 둘의 경우를 커버하기 위해 사용 해시함수를 두개 이용. 하나는 해시값을 얻을 때, 두번째는 충돌 시 이동 폭을 얻을 때 사용 Reference)https://ratsgo.github.io/data%20structure&amp;amp;algorithm/2017/10/25/hash/코딩 인터뷰 완전분석" }, { "title": "Red Black Tree", "url": "/posts/%EB%A0%88%EB%93%9C%EB%B8%94%EB%9E%99%ED%8A%B8%EB%A6%AC/", "categories": "Study, Data Structure", "tags": "data structure, 자료구조, red black tree, tree", "date": "2021-08-05 00:00:00 +0900", "snippet": ": 이진 탐색 트리(BST)는 조회, 삽입, 삭제시 O(logN)== O(h) == O(depth) 의 시간이 걸린다. 그런데, 운이 좋지 않아 편향된 모양을 갖게 되면 될수록 시간복잡도는 O(N)에 가까워진다. 따라서 균형잡힌 이진탐색트리를 유지하는게 좋은데, 그 중 하나로 대표적인게 RBT이다.특징 자가 균형잡힌 이진트리 실 사용에서 효율적 실제로 실무에 많이 사용된다고 함. 항상 O(logN) Leaf 노드는 NIL값을 저장. 최소경로와 최대경로 비율이 최대 2로 유지 Java에서 ArrayList의 경우 내부적으로 RBT로 구현되어있다고 함.규칙 각 노드는 Red 혹은 Black Root와 Leaf 노드(NIL) 는 Black. 모든 Leaf 는 NIL을 자식으로 갖는다. Red노드의 두 자식노드는 Black이다. Root에서 임의의 Leaf(NIL)까지 가는 경로에서 만나는 Black 노드의 수는 같다. 그냥 노드의 수는 다를 수 있음. 이 것을 Black Height 라고 한다. Black height: 노드 x 로부터 노드 x 를 포함하지 않은 Leaf 까지의 simple path 상에 있는 Black 노드들의 개수 삽입 삽입된 노드를 Red로 지정. Black height 변경을 최소화하기 위해 삽입 결과 규칙을 위배해버리면(double red) uncle노드의 색깔에 따라 어떻게 변경할지 정책을 정함 uncle black - Restructuring uncle red - Recoloring Restructuring (이걸 rotation이라고 함) 나와 부모와 부모의 부모 노드를 정렬해, 가운데 노드를 Root로 만들어버림 다른 서브트리에 영향을 미치지 않음. 따라서, 한번의 restructuring이면 끝남. 따라서 O(1). 그러나, 삽입 자체의 시간복잡도가 있기 때문에 전체 시간복잡도는 O(logN) Recoloring 부모와 uncle을 Black으로, 부모의 부모를 Red로 바꿔버림. 한번에 끝나지 않을 수도 있음. 이유: 위의 경우에서 부모의 부모가 전체의 root가 아니었뎐 경우에 변경 후 또 double red가 나올 가능성이 있다. 최악의 경우 root까지 Propagation되고, 이 때 O(log N)이 걸리게 될 듯 Reference)https://zeddios.tistory.com/237https://velog.io/@agugu95/%EC%9D%B4%EC%A7%84-%ED%8A%B8%EB%A6%AC%EC%9D%98-%EA%B7%A%ED%98%95-RED-BALCKAVLhttps://itstory.tk/entry/%EB%A0%88%EB%93%9C%EB%B8%94%EB%9E%99-%ED%8A%B8%EB%A6%ACRed-black-treehttps://github.com/JaeYeopHan/Interview_Question_for_Beginner/tree/master/DataStructure" }, { "title": "이진 탐색 트리(BST)", "url": "/posts/%EC%9D%B4%EC%A7%84%ED%83%90%EC%83%89%ED%8A%B8%EB%A6%AC/", "categories": "Study, Data Structure", "tags": "data structure, 자료구조, binary search tree, tree, 이진탐색트리", "date": "2021-08-04 00:00:00 +0900", "snippet": ": 이진 트리의 일종이고, 효율적인 탐색을 위한 자료구조규칙 각 노드의 키는 유일하다. 부모가 왼 자식보다 크고, 오른 자식보다 작다. 각 서브노드도 이진탐색트리이다.탐색: root부터 시작해, 원하는 key가 작으면 왼쪽 서브트리, 크면 오른쪽 서브트리로 이동 시간복잡도: O(log n) . 정확히는 O(h) 최악의 경우(편향된 트리, 즉, 각 노드가 일렬로 되어있는 경우 O(N)이 된다.) // linked listbool search(Node* node, int target) { if(node == NULL) return false; if(node-&amp;gt;data == target) return true; return node-&amp;gt;data &amp;lt; target ? search(node-&amp;gt;right, target) : search(node-&amp;gt;left, target);}// arraybool search(int index, int target) { if(!indexInRange(index) || tree[index] == 0) return false; if(tree[index] == target) return true; return tree[index] &amp;lt; target ? search(index * 2 + 1, target) : search(index * 2, target);}삽입: 탐색 후 마지막으로 NULL인 자리에다가 삽입 탐색을 바탕으로 하고, 삽입만을 하는 연산 자체는 O(1). 따라서, 전체 복잡도는 탐색이랑 같음 O(log n)// linked listvoid insert(Node* node, int target) { if(node-&amp;gt;data &amp;lt; target) { if(node-&amp;gt;right == NULL) { //found node-&amp;gt;right = new Node(target); node-&amp;gt;right-&amp;gt;left = node; return; } insert(node-&amp;gt;right, target); } else { if(node-&amp;gt;left == NULL) { //found node-&amp;gt;left = new Node(target); node-&amp;gt;left-&amp;gt;right = node; return; } insert(node-&amp;gt;left, target); }}// Array. 연결 작업이 없기 때문에 linked list에 비해 간결void insert(int index, int target) { if(isInRange(index) &amp;amp;&amp;amp; tree[index] == 0) { tree[index] = target; return; } tree[index] &amp;lt; target ? insert(index * 2 + 1, target) : insert(index * 2, target);}삭제: 삭제할 노드의 서브트리 갯수에 따라 로직이 상이. 0개 일 때: 그냥 지워버림 1개 일 때: 지우고 리프를 지운 노드 위치로 승격 2개 일 때: 왼쪽 서브트리 중 가장 큰 것 or 오른쪽 서브트리 중 가장 작은 것을 지운 노드 위치로// linked list// 오른쪽 서브트리에서의 최솟값을 찾는 함수Node* searchMinNode(Node* node) { return node-&amp;gt;left == NULL ? node : searchMinNode(node-&amp;gt;left);}void delete(Node* root, int target) { Node* cur = root; while(1) { // 지울 node 찾기 root = cur; // 부모노드 set if(cur-&amp;gt;data == target) break; cur = cur-&amp;gt;data &amp;lt; target ? cur-&amp;gt;right : cur-&amp;gt;left; } // leaf 0개 일 때 if(cur-&amp;gt;left == NULL &amp;amp;&amp;amp; cur-&amp;gt;right == NULL) { if(root-&amp;gt;right-&amp;gt;data == cur-&amp;gt;data) root-&amp;gt;right = NULL; else root-&amp;gt;left = NULL; } // leaf 1개 일 때 if(cur-&amp;gt;left == NULL || cur-&amp;gt;right == NULL) { Node* newNode = NULL; if(cur-&amp;gt;left != NULL) newNode = cur-&amp;gt;left; else newNode = cur-&amp;gt;right; if(newNode-&amp;gt;data == root-&amp;gt;right-&amp;gt;data) root-&amp;gt;right = newNode; else root-&amp;gt;left = newNode; } // leaf 2개 일 때 else if(cur-&amp;gt;left != NULL &amp;amp;&amp;amp; cur-&amp;gt;right != NULL){ Node* minNode = searchMinNode(cur-&amp;gt;right); minNode = delete(cur, minNode-&amp;gt;data); // 옮길 노드의 연결을 유지하기 위한 재귀 cur-&amp;gt;data = minNode-&amp;gt;data; } }Reference)https://dailykoding.tistory.com/26https://ansohxxn.github.io/algorithm/bst/https://github.com/JaeYeopHan/Interview_Question_for_Beginner/tree/master/DataStructure" }, { "title": "이진트리(Binary Tree)", "url": "/posts/%EC%9D%B4%EC%A7%84%ED%8A%B8%EB%A6%AC/", "categories": "Study, Data Structure", "tags": "data structure, 자료구조, tree, binary tree, 이진트리", "date": "2021-08-03 00:00:00 +0900", "snippet": ": Root를 중심으로 두 개의 서브 트리로 나뉘는 트리. 이 때 나눠진 두 서브트리도 이진트리여야 한다. leaf node에 도달했을 때 해당 leaf node를 root로 하는 (마지막의) 서브트리도 이진트리여야 하기 때문에 Node 하나인 것도 이진 트리. -&amp;gt; 같은 논리로 공집합도 이진 트리. 트리 순회 DFS - 기본적으로 재귀적 탐색(스택으로 구현) 전위 순회 : R, 좌, 우 e. g) 아래와 같이 재귀적으로 구현. (중위, 후위는 순서만 다름) // linked listvoid PreOrder(Node* node) { if (node == NULL) return; cout &amp;lt;&amp;lt; node-&amp;gt;data; PreOrder(node-&amp;gt;left); PreOrder(node-&amp;gt;right);} // arrayint tree[100] = {};void PreOrder(Int index) { if (index &amp;lt;= 0 || treeSize &amp;lt; index || tree[index] == 0) return; cout &amp;lt;&amp;lt; tree[index]; PreOrder(index * 2); PreOrder(index * 2 + 1);} 중위 순회 : 좌, R, 우 후위 순회 : 좌, 우, R BFS - 낮은 레벨부터(root부터) (큐로 구현) 종류 포화 이진 트리 모든 노드가 꽉 찬 이진 트리. 높이(level)을 h라고 할 때 노드 갯수는 2^(h+1) - 1 이다. 여기서 높이 == 간선 높이 완전 이진 트리 모든 자식이 위에서 아래로, 왼쪽에서 오른쪽으로 순서대로 채워진 트리 정 이진 트리 모든 자식 노드는 2개 or 0개 이진 트리를 이용한 BST(이진 탐색 트리), 균형 이진 탐색 트리, 힙(최대, 최소 힙) 등트리 표현(내부 구현방식) 순차 표현 - 배열로 구현하고 Index로 접근 Root 노드: 1 / 내가 n 일 때, 왼쪽 자식은 2 * n, 오른쪽 자식은 2 * n + 1 완전이진트리가 아니라면 사용하지 않는 메모리 낭비하게 됨. linked list 표현 - 각 노드는 아래의 구조를 갖게 됨 struct Node{ int data; Node* left; Node* right;}; Reference)https://sean-ma.tistory.com/25?category=781378https://galid1.tistory.com/176" }, { "title": "HTTP 완벽가이드 5장 - 웹 서버가 하는 일", "url": "/posts/HTTP_%EC%99%84%EB%B2%BD%EA%B0%80%EC%9D%B4%EB%93%9C_5%EC%9E%A5_%EC%9B%B9%EC%84%9C%EB%B2%84%EA%B0%80_%ED%95%98%EB%8A%94%EC%9D%BC/", "categories": "Study, HTTP", "tags": "http, web server", "date": "2021-08-01 00:00:00 +0900", "snippet": " 웹 서버는 목적에 따라 다양하지만, 기본적으로 리소스에 대한 HTTP 요청을 받아 콘텐츠를 클라이언트에게 돌려주는 일을한다. 간단한 일을 처리하는 작은 임베디드 서버(프린터, 가전기기, IoT 등)을 생각해보자 커넥션을 맺고, 요청을 받고, 처리(해석)하고, 리소스에 접근하고, 응답을 만들고 보낸다.1. 커넥션 수락: 커넥션을 지속하고 있지 않는 이상 새로운 커넥션을 만든다. 유닉스 환경에서 TCP 커넥션은 소켓으로 표현되며, 소켓을 통해 IP를 추출해낸다(getpeername) 대부분은 역방향 DNS로 알아낸 IP 주소를 클라이언트의 호스트 명으로 변환. 몇몇은 ident 프로토콜을 지원(어떤 사용자 이름이 HTTP 커넥션을 초기화했는지 알 수 있도록)2. 요청 메시지 수신: 요청메시지를 CRLF로 구분해 요청줄, 헤더, 메시지로 파싱한다. - 몇몇 웹 서버는 그것을 key-value 자료구조에 저장 웹 서버는 항상 새 요청을 주시하고 있다고 보면 된다. 웹 서버에 따라 요청을 처리하는 방식이 달라진다.요청 메시지 처리에 따른 방식request 처리방식 설명에 이만한 그림은 없는 것 같다. 단일 스레드 I/O 아키텍처: 한번에 하나씩 요청 처리. 트랜젝션 완료 시 다음 커넥션 처리(간단한 서버에서만 사용) 멀티 스레드 I/O 아키텍처: 커넥션을 받는 스레드를 늘릴 수 있다. 동적으로도 가능하고, 미리 할당해놓을 수 있다. 수만 건을 처리하는데 스레드를 다 만들어놓으면 오히려 시스템 리소스를 과소비하게 된다. 따라서 제한을 건다. Apache에서 사용하는 방식이 이 방식인 것 같다. 다중 I/O 아키텍처: 한 커넥션에 대해서 처리하다보면 Blocked 되는 테스크에 대해 유휴시간이 발생할텐데, 이 유휴시간동안 다른 Task를 처리한다. 한 커넥션에 대한 처리가 완료되면, 커넥션은 다음번의 state 변경을 기다리기 위해 커넥션 목록으로 들어가고, 스레드는 수행할 수 있는 커넥션을 빼와서 수행한다. NginX에서 사용하는 방식. 비동기적 처리 다중, 멀티스레드 I/O 아키텍처: 동작만 잘 되도록 구성한다면 가장 이상적인 방법 일 것으로 보인다.3. 요청 처리: 웹서버에서 처리할 수 있는 적절한 처리를 수행한다. 단, WAS 개입이나 다른 동적 컨텐츠에 대해서는 당연히 리소스 접근이 필요.4. 리소스 접근: 정적 리소스(HTML, CSS, JPEG)에 대한 것은 웹 서버 에서 처리, 리소스는 주로 동적 컨텐츠가 필요할 떄docroot:요청 URI를 파일 시스템 내의 파일 이름으로 사용하는 방식 e.g) /aaa/bbb.gif 요청이 들어오고 문서 루트가 /usr/local 라면 /usr/local/aaa/bbb.gif 파일을 반환 가상 호스팅 docroot: 한 웹 서버가 여러 웹 사이트를 호스팅하고 URI나 Host 헤더로부터 얻은 IP주소나 호스트 명을 통해 문서 루트를 식별하고 적절한 콘텐츠를 전달해 주는 것 사용자 홈 디렉터리 docroots : 사용자가 자신의 로컬에서 자신의 웹 사이트를 만들도록 하는 것디렉터리 목록 요청: 색인 파일(index.html) 반환동적 콘텐츠 리소스 맵핑: 동적 리소스에 맵핑. 애플리케이션 서버는 백엔드 애플리케이션과 연결되는 것 e.g) 아파치는 URI의 경로명이 바이너리의 위치로 맵핑되도록 기능을 제공한다. ScriptAlias /cgi-bin/ /usr/local/etc/httpd/cgi-programs/ 5. 응답 만들기 웹 서버는 응답 메시지를 만든다. (상태 코드, 헤더, 본문) 응답 본문(엔티티): Content-Type(MIME), Content-Length, 본문내용 MIME type 결정 매치 타이핑: 웹 서버가 직접 파일 내용을 검사 (표준 확장자 없는 경우) 유형 명시: 항상 어떤 type을 갖도록 웹 서버에 명시 유형 협상: 여러 종류에 속하도록 설정. 사용자와 협상을 통해 가장 좋은 형식으로 정함 리다이렉션 : Location 응답 헤더에 새로운 위치 URI를 포함시킴 영구히 리소스가 옮겨진 경우(301 Moved Permanently) 임시로 리소스 옮겨진 경우 URL 증강: 뚱뚱한 URL 세션 유지 용도로 URL 뒤에 유저의 상태 정보를 붙여서 리다이렉션 -&amp;gt; 사용자는 해당 상태(세션)를 포함해 재요청 6. 응답 보내기: 커넥션 너머로 데이터를 보낼 때에 받을때와 비슷한 이슈에 직면. 커넥션 상태를 추적해야 하며, 지속 커넥션이라면 Content-Length를 고려하는 등Reference)HTTP 완벽 가이드" }, { "title": "파라미터의 역할", "url": "/posts/%ED%8C%8C%EB%9D%BC%EB%AF%B8%ED%84%B0%EC%9D%98_%EC%97%AD%ED%95%A0/", "categories": "Study, Develop", "tags": "develop", "date": "2021-07-31 00:00:00 +0900", "snippet": "문제상황private foo(data: { id: string }) { const { id } = data; if(typeof id === &#39;string&#39;) { // ... } else { debug(&#39;invalid data type&#39;); }} 타입스크립트 언어를 사용하는 프로젝트, 위와같은 상황에서 foo()의 매개변수로 전해지는 id는 항상 string 형이어야 하고, 그렇지 않으면 타입이 맞지 않아 컴파일타임에 에러가 발생한다. 따라서, 이 프로젝트에서 개발하는 입장으로 본다면, 조건문 if(typeof id === &#39;string&#39;)의 결과는 어떠한 경우에도 절대 falsy하지 않다고 판단했다. IDE에서도 “Redundant typeof check: ‘owtUserID’ always has type ‘string’ “ 라는 메시지와 함께 해당 줄이 불필요하다는 메시지를 보낸다. 오류 파라미터에서 type을 지정해주는 것은 형식을 명시함으로써 개발자가 적절한 개발을 할 수 있게하는 목적이지, 외부에서 항상 해당 type에 맞는 데이터를 전해줄 것을 보장하지 못한다. 심지어 해당 프로젝트 내부에서도 const data: any = { id: 123 }; 이러한 data를 argument로 전달한다면, 컴파일에러 없이 그냥 통과하게 된다. 해당 부분에서 data라는 데이터는 socket 연결 후 어떠한 소켓 이벤트에 의해 전해지는 데이터이다. 일반적으로 API 호출이라면 ajv와 같은 패키지를 통해 JSON 데이터의 형식 검증을 할 수 있다고 한다. const schema: JSONSchemaType&amp;lt;Seed&amp;gt; = { type: &#39;object&#39;, properties: { // ... }} 소켓 이벤트로 전해진 하나짜리 데이터(그냥 string)를 이런 방법 보다 그냥 if(typeof id === &#39;string&#39;) 처럼 검증해준 것 뿐. 결론: 함수 파라미터의 역할을 다시 생각해보자. 형식, 타입을 지정함으로써 개발자가 적절한 데이터를 전달받고, 그걸 통해 의도했던 대로 로직을 작성하기 위한 목적이지, 외부에서 전해지는 데이터까지 막는 역할은 하지 못한다." }, { "title": "SQL Injection", "url": "/posts/SQL_injection%EA%B3%BC_prepared_statement/", "categories": "Study, Database", "tags": "database, db, sql, sql injection, 보안", "date": "2021-07-25 00:00:00 +0900", "snippet": "공격 방법 인증 우회 아이디를 입력하고 비밀번호 창에 “1234 or 1=1” 과 같은 비밀번호를 전달해주면, 이게 쿼리로 변환되면서 WHERE 절에서 항상 true 결과를 불러오는 쿼리가 되고, admin 페이지로 접근하게 됨. 에러 유발 기본적으로 웹앱은 쿼리 오류 발생시 DB오류를 브라우저에 노출함 UNION SELECT을 통해 에러를 일으킴 이 쿼리에서 union하는 두 테이블은 컬럼 수가 일치해야함 따라서, 에러가 안날때까지 수행해보고, 컬럼의 갯수를 파악할 수 있음 방어 방법 SQL 구문에 주석을 삽입해 Where 구문 무력화 String query = &quot;Select * From Users&quot; + &quot; Where id = &#39;&quot;+ id +&quot;&#39; and Password = &#39;&quot; + Password + &quot;&#39;&quot; SQL 서버 오류 시, 에러 메시지 감추기 일반 사용자는 view를 통해서만 원본 데이터에 접근 할 수 있도록 막아두는 것 Prepared statement 사용 일반적인 Statement “1. 쿼리 문장 분석, 2. 컴파일, 3. 실행” 이 순서를 쿼리 수행마다 매번 반복 동적 쿼리 Prepared Statement 처음 한번만 위의 세 단계 거치고, 캐시에 담아놓는다. 이후 캐시를 통해 재사용 정적 쿼리 Reference)https://github.com/WooVictory/Ready-For-Tech-Interview/blob/master/Database/SQL%20-%20Injection.mdhttps://m.mkexdev.net/427https://medium.com/pocs/sql-injection%EC%9D%B4%EB%9E%80-3b57f2415ef4https://devbox.tistory.com/entry/Comporison" }, { "title": "HTTP 완벽가이드 4장 - 2. HTTP 커넥션", "url": "/posts/HTTP_%EC%99%84%EB%B2%BD%EA%B0%80%EC%9D%B4%EB%93%9C_4%EC%9E%A5_2_HTTP_%EC%BB%A4%EB%84%A5%EC%85%98/", "categories": "Study, HTTP", "tags": "http, http connection", "date": "2021-07-23 00:00:00 +0900", "snippet": "Connection 헤더란? 헤더 보호하기 : 한 Connection 작업에서만 사용되어야 하는 토큰 값들을 쉼표로 구분해 갖고 있는다. 다른 커넥션(다른 홉)에 전달되는 것 방지 HTTP/1.1 200 OKCache-control: max-age=3600Connection: meter, close, bill-my-credit-card 위의 메시지에서 Connection: 부분에 명시한 것 Hop-by-Hop: 두 홉(노드) 사이에서만 전달되고 그 이후엔 없어져야 한다.(클라 - 프락시 or 프락시 - 서버 등) 병렬 커넥션: HTTP 클라이언트가 여러 개의 TCP 커넥션을 맺어 HTTP 트랜잭션을 병렬로 처리할 수 있게 한다. 클라이언트 입장에서의 객체당 한 서버와 커넥션을 맺어 각 커넥션의 지연시간을 겹치게 해 처리 속도를 빠르게 하는 것항상 빠르지는 않다. 대역폭이 좁으면 각 객체를 전송하는게 느리기 때문에 성능상 장점이 없다. 실제로 연결하는 병렬 커넥션 수에는 제한이 있다. (커넥션을 늘릴 수록 성능 문제) 한 사용자 당 100개의 커넥션을 허용하고 100명의 사용자가 사용하면 서버는 10000개의 커넥션을 맺어야 하는데, 이 것은 큰 부하가 될 수 있다. 따라서, 최신 브라우저는 대부분 6~8개 라고 함 연결을 맺고 끊음을 반복하다보니 TCP의 느린 시작을 피할 수 없다.지속 커넥션: HTTP 트랜잭션이 처리된 이후에도 커넥션을 끊지 않고 재사용하는 것 사이트 지역성(site locality): 서버에 HTTP 요청을 하기 시작한 애플리케이션은 웹 페이지 내의 이미지 등을 가져오기 위해 그 서버에 또 요청을 할 것 커넥션을 맺기위한 준비작업을 줄일 수 있고, TCP 느린 시작으로 인한 지연을 피할 수 있다. 튜닝된 커넥션 : 느린시작에서 수차례 성공해서 다수의 패킷을 전송할 권한을 얻은 상태 HTTP/1.0의 Keep-Alive, HTTP/1.1의 지속 커넥션 지속적으로 커넥션을 유지하는 상황이더라도, 양 측에선 언제건 끊을 수 있긴 하다.HTTP/1.0의 Keep-alive 커넥션 TCP 핸드셰이크와 느린시작으로 인한 지연을 줄인다. Keep-alive가 HTTP/1.1에서 사용하지 않도록 되어 빠졌지만, 많은 브라우저에서 여전히 Keep-alive를 사용하기 때문에 개발자는 keep-alive가 가능하도록 개발해야 한다. Connection:Keep-Alive 헤더 요청에 Connection:Keep-Alive 헤더 : “이 방식으로 통신하고 싶다” 의미 응답에 Connection:Keep-Alive 헤더 : “이 방식을 지원할 것”(없다면 연결 끊을 것임을 의미) HTTP/1.0을 따르는 기기로부터 받는 모든 Connection 헤더 필드(Connection: Keep-Alive와 같은)는 무시되어야 한다. 멍청한 프락시: 오래된 프락시로 전달해서 Hang 걸릴 수 있기 때문 이 방식을 사용하려면 정확한 Content-Length 값이 있어야 한다. 기존 메시지 끝과 새로운 메시지 시작점을 정확히 알수 어렵기 떄문 Keep-alive와 멍청한 프락시(Dumb Proxy) 오래된 프락시들은 Connection:Keep-Alive 헤더를 해석하지 못하고 그대로 전달한다. Connection 헤더는 기본적으로 홉별(Hop-by-Hop) 헤더이기 때문에 한개의 전송 링크에만 적용되며 다음 서버로 전송되면 안된다. a에서의 Connection:Keep-Alive 는 b까지 전파되지 않아야 하는데, 멍청한 프락시 문제로 서버에선 proxy가 커넥션을 유지하자고 요청하는 것으로 잘못 판단하게 된다. 프락시는 서버가 커넥션을 끊기를 기다리지만 서버는 프락시가 Keep-alive를 요청한 것으로 알기때문에 끊지 않는다. 클라이언트가 유지하고 있는 커넥션으로 요청을 보내면 같은 커넥션 상 다른 요청이 오는 경우를 예상하지 못하기 때문에 무시해버린다. 해결방안 1 : Proxy는Connection: Keep-Alive 헤더를 전달하면 안되고, 당연히 Keep-Alive: ~~ 와 같은 Keep-Alive 헤더도 전달하면 안된다. 같은 이유로, Proxy는 다른 홉별(Hop by Hop) 헤더를 전달 혹은 캐싱하면 안된다. 해결방안 2: 프락시에 커넥션 관련 메시지를 보낼 때는Proxy-Connection 이라는 확장 헤더를 사용 오래된 프락시는 이 것을 똑같이 무조건 전달해도, 서버에선 뭔지 모르니 괜찮다. 영리한 프락시는 이 것을 Connection 헤더로 바꾸고 요청한 의도대로 동작할 것 그러나, 멍청한 프락시가 중간에 하나라도 끼어있다면 다시 문제가 발생한다. 프락시의 경우 보이지 않는 경우가 많기 때문에 지속 커넥션을 명확히 구현하는 것이 중요하다. HTTP/1.1의 지속 커넥션 디폴트로 활성화 되어있고, 커넥션을 끊으려면 Connection: close 헤더를 명시하는 방식으로 사용 마찬가지로 정확한 Content-Length 필요 HTTP/1.1 프락시는 클라이언트, 서버 양측 별도의 지속 커넥션을 맺고 관리해야한다. HTTP/1.1 애플리케이션은 중간에 끊어지는 커넥션을 복구할 수 있어야 한다. 이 때 클라이언트는 언제든 재요청 할 준비를 해야 한다. 클라이언트는 과부하 방지를 위해 넉넉잡아 두개의 지속 커넥션만 유지해야한다.파이프라인 커넥션: 지속 커넥션을 통해 요청을 파이프라이닝해 keep-alive 효과를 더 높인다. 요청은 Queue에 쌓여 파이프라인 방식으로 전달된다. 지속 커넥션일 때만 파이프라인을 이을 수 있다. 순서가 유지되어야 한다.(그런데, 이미 TCP 통신이면 ACK로 순서가 보장이 될 것 같은데 왜 그런지는 모르겠다) 끊김에 대한 준비: 커넥션이 끊어지는 상황에서 클라이언트는 언제든 재요청할 준비가 되어있어야 하는데, 클라이언트는 파이프라인 중 어느게 성공하고 어느게 실패한지 알 방법이 없기 때문에 비멱등 요청은 파이프라인으로 보내면 안된다.커넥션 끊기와 관련된 것들: 커넥션 끊는 것에 명확한 기준은 없다. 마음대로 커넥션 끊기: 메시지를 다 보낸다음 끊는다. e.g) 지속 커넥션에서 일정 timeout 이후에 끊어버리기.(그러나 더이상 필요 없다고 확신은 못함) Content-Length: 정확한 값을 가져야 비교를 통해 끝났는지를 판단할 수 있다. - 없다면 데이터 길이를 서버에게 물어봐야 한다. 끊기 허용, 재시도, 멱등성: HTTP 애플리케이션은 커넥션이 끊겼을 때 적절히 대응할 준비가 되어 있어야 한다. 파이프라인 커넥션의 경우 더 어려워진다. 위에서 이야기했듯, 비멱등 요청의 경우 다시 보내기를 피해야한다. 해결 예시) 캐시된 Post 요청 페이지를 다시 로드할 때, 요청을 다시 보내기를 원하는지 alert를 띄워준다 등 우아한 커넥션 끊기 TCP커넥션에선 두 채널(입력 큐와 출력 큐) 이 존재한다. 한쪽의 입력 큐는 반대쪽의 출력 큐가 된다. 전체끊기, 절반끊기 : 두 채널 중 하나만 끊는 것은 shutdown() 을 통한 절반 끊기, 둘다 끊는 것은 close() 를 통한 전체 끊기 보통은 출력 채널을 끊어버리는게 이상적이다. -&amp;gt; 상대방은 받을 것을 다 받고나서 내가 커넥션을 끊었다는 것을 알게 되기 때문 만약 입력 채널을 끊어버리면? (내 입장에선 출력 채널이 상대방에 의해 끊기면) 파이프라인 커넥션 상황에서 계속 요청을 보내다가 상대방이 끊게 되면 어느 순간 connection rest by peer 메시지를 받게 된다. 이 리셋 메시지는 입력 버퍼에 있는 (아직 읽히지 않은)데이터를 지우게 된다. 우아하게 커넥션 끊기: 일반적으로 좋은 방법은 자신의 출력채널을 먼저 끊고 상대방의 출력채널이 끊기기를 기다리는 것. 만약 timeout 내에 상대방이 끊지 않으면, 나의 리소스 보호를 위해 커넥션을 강제로 끊을 수도 있다.Reference)HTTP 완벽가이드" }, { "title": "프로세스의 상태변화", "url": "/posts/%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4_%EC%83%81%ED%83%9C%EB%B3%80%ED%99%94/", "categories": "Study, OS", "tags": "os, 운영체제", "date": "2021-07-20 00:00:00 +0900", "snippet": " new -&amp;gt; ready : 장기 스케줄러에 의해 Ready Queue에 올라감 ready -&amp;gt; running : 단기 스케줄러에 의해 CPU에 할당된 상태.(dispatch) running -&amp;gt; ready : 다른 프로세스에 의해 선점당하면(interrupt) 다시 Ready Queue로 이동 스케줄링 알고리즘이 우선순위 스케줄링인 경우 running -&amp;gt; waiting : 입출력(I/O) 이벤트 발생시 block waiting -&amp;gt; ready : 입출력(I/O) 이벤트 종료 시 다시 Ready running -&amp;gt; terminate : 프로세스 종료ready, waiting 상태에는 여러 프로세스 존재할 수 있으나, 싱글 코어CPU라고 가정했을 때 running 상태의 프로세스는 단 하나 존재이외에도, suspend라는 state가 있다. 중기 스케줄러에 의해 디스크로 swap out 된 상태 waiting(blocked) 상태는 I/O 작업을 기다리는 상태이기 때문에 스스로 ready 상태로 돌아가지만, suspend는 다른 이유로 직접 swap된 것이기 때문에 스스로 ready가 되지 못한다.context switch 에 소요되는 시간을 측정하는 방법: 프로세스를 일부러 wait로 보내는 방식을 사용하면 된다. P1, P2 두개의 프로세스를 실행하는 환경이라고 가정하자. 먼저 P1에서 타임스탬프를 기록하고 곧바로 P1이 P2에게 데이터 토큰을 요청한다. 이 때 IPC(I/O) 발생으로 P1은 waiting 상태가 된다. P2가 CPU 제어권을 받고, P2는 바로 다시 P1에게 데이터 토큰을 보내도록 한다. 다시 제어권은 P1에게 넘어오고, 타임스탬프를 확인한다. 두 타임스탬프 차이는 “2 * (보내는 시간 + 받는 시간 + Context switch 시간)“이 된다. P1이 자기 자신에게 데이터를 보내고 받는 시간을 측정해서 위의 시간에서 빼면 오차를 제외한 근사 값의 context switch 시간을 알 수 있다. 보다 정확하게 하기 위해 여러번 반복해서 평균을 구하면 된다. Reference)코딩인터뷰 완전분석https://blockdmask.tistory.com/22https://github.com/uzzzzzin" }, { "title": "모던 JavaScript 튜토리얼 - &#39;use strict&#39;", "url": "/posts/%EB%AA%A8%EB%8D%98_Javascript_%ED%8A%9C%ED%86%A0%EB%A6%AC%EC%96%BC_use_strict/", "categories": "Study, JavaScript", "tags": "javascript, js", "date": "2021-07-20 00:00:00 +0900", "snippet": ": 엄격한 모드로, 기존에 무시해왔던 것들을 엄격하게 잡아낸다고 이해.About 2009년 ES5에서 새로운 기능이 추가되면서 기존 기능 일부가 변경되어 호환성 이슈가 있었다. JS에서는 그 변경 사항을 항상 활성화시키지 않고, &#39;use strict&#39;라는 지시자를 사용하는 경우에만 활성화되도록 했다. 따라서, 해당 지시자를 사용하면서 좀더 자바스크립트를 모던하게(현대적으로)(모던 자바스크립트) 사용할 수 있게 함. 기본 모드는 sloppy mode(느슨한 모드)라고 부른다. 전통방식?? if (false) { var x = &quot;hello&quot;;}console.log(x); 이와같은 코드에서 block scope 내의 변수에 접근 시 error가 아닌 undefined가 띄워졌었다. 특징 항상 스크립트 최상단이 아니라, 함수 본문 맨 앞에 올 수도 있고, 이 경우 해당 함수만 엄격 모드. 그렇지 않을땐 항상 스크립트 최상단. (function() { &#39;use strict&#39;; // 이 함수는 엄격 모드})() use strict를 선언하면, 취소할 방법은 없음. Class와 Module을 사용한다면 &#39;use strict&#39; 사용하지 않아도 이미 자동 적용됨. 느슨한 모드와의 연결은 최대한 피해야한다. 관련 이슈 : https://bugzilla.mozilla.org/show_bug.cgi?id=579119 use strict 사용시 어떻게 변화? 기존 조용히 무시되던 에러들을 throw한다. JS 엔진의 최적화를 어렵게 만드는 실수들을 엄격히 잡아냄 - 따라서 성능상 더 빨라질 수 있음 차기 ECMA Script 버전들에서 정의될 문법 금지실제 변경사항 선언하지 않은 변수(전역변수) 불가능 사용불가능한 변수에 할당 불가능 &quot;use strict&quot;; // 쓸 수 없는 프로퍼티에 할당var undefined = 5; // TypeError 발생var Infinity = 5; // TypeError 발생 // 쓸 수 없는 프로퍼티에 할당var obj1 = {};Object.defineProperty(obj1, &quot;x&quot;, { value: 42, writable: false });obj1.x = 9; // TypeError 발생 // getter-only 프로퍼티에 할당var obj2 = { get x() { return 17; } };obj2.x = 5; // TypeError 발생 // 확장 불가 객체에 새 프로퍼티 할당var fixed = {};Object.preventExtensions(fixed);fixed.newProp = &quot;ohai&quot;; // TypeError 발생 모든 프로퍼티, 파라미터 네이밍이 unique해야함. delete 호출 막음 primitive values의 프로퍼티 설정 불가능 with 사용 불가 예약어, eval, artuments로 네이밍 불가 이외의 것들은 더 MDN 문서 찾아볼것Reference)모던 JavaScript 튜토리얼 https://ko.javascript.infoNode.js 디자인패턴https://developer.mozilla.org/ko/docs/Web/JavaScript/Reference/Strict_mode" }, { "title": "JPA와 Proxy", "url": "/posts/JPA%EC%99%80_Proxy/", "categories": "Study, JPA", "tags": "jpa, spring boot jpa", "date": "2021-07-20 00:00:00 +0900", "snippet": "Proxy사용 이유: 엔티티를 실제 사용하는 시점에 DB에서 가져오기 위해 사용한다. e.g ) Team과 Member 클래스가 있다고 가정할 때, 1 : n 연관관계를 갖게 되고, 각 멤버는 해당하는 팀 객체를 ManyToOne으로(FK) 갖는다. 이 때 Member에 대한 정보를 조회하기 위해 Team 정보까지 조회하는 것은 불필요한 오버헤드 해결방안: lazy loading lazy loading(지연로딩) : 엔티티 실제 사용 시점까지 조회를 지연하기 JPA에서는 지연 로딩을 하이버네이트에 위임한다. DB 조회를 미루기 위해, 조회 발생 시 하이버네이트 내부에서는 EntityManager.getReference() 를 통해 프록시 객체를 반환한다. Client는 이를 참조하게 된다. 프록시 객체는 실제 객체를 상속받으므로(실제 객체의 참조를 보관) 생김새가 같다. Kotlin + Spring에서 클래스를 open해놓아야 하는 것이 이것 때문이다. 프록시 객체의 초기화 프록시 객체는 member.getName() 이처럼 엔티티 실 사용 시점에 DB 조회해 실제 엔티티 객체를 생성한다. 이 때 영속성 컨텍스트에 엔티티 생성을 요청하고, 생성 후에는 프록시가 진짜 엔티티(진짜 데이터)를 참조하게 된다. 따라서, 참조가 바뀌는 과정은 딱 한번 발생한다. 만일 이미 영속성 컨텍스트가 존재하는 경우 DB 조회는 불필요하므로 위에서 proxy 객체를 반환하는 메서드인 em.getReference() 시에도 실제 엔티티 객체를 반환하게 된다. 초기화는 영속성 컨텍스트의 도움을 받아야한다. Transactional과 life cycle을 같게 갖는 영속성 컨텍스트가 끝나고 준 영속 상태로 변하게 되면 LazyInitializationException 발생한다. 프록시로 엔티티 조회 시 PK를 파라미터로 전달하고, 프록시는 이를 보관한다. 이미 갖고 있는 Id값이므로 getId시에 프록시 초기화하지 않음(단, 옵션 설정시 AccessType.PROPERTY) Reference)자바 ORM 표준 JPA 프로그래밍" }, { "title": "모던 JavaScript 튜토리얼 - Prototype", "url": "/posts/%EB%AA%A8%EB%8D%98_Javascript_%ED%8A%9C%ED%86%A0%EB%A6%AC%EC%96%BC_prototype/", "categories": "Study, JavaScript", "tags": "javascript, js", "date": "2021-07-18 00:00:00 +0900", "snippet": ": 자바스크립트는 프로토타입 기반 언어이다. 모든 객체들이 클래스로 정의해놓은 메소드와 속성을 상속받기 위한 템플릿으로써 프로토타입 객체를 가진다.Prototype: 모든 객체들이 클래스의 정보들을 상속받을 수 있도록 템플릿 역할을 수행한다. 기본적으로 Class로 객체를 정의한다고 해도 자바스크립트 내부적으로는 프로토타입으로 관리된다. ES2015 클래스 구문으로 조금더 편리하게 볼 수 있도록 제공하는것 class Person { constructor(name, age) { this.name = name; this.age = age; } getName() { return this.name; }} // ---------------------- 위의 방식으로 class를 선언한다고해도 사실은 아래와같이 관리됨 function Person(name, age) { this.name = name; this.age = age;} Person.prototype.getName = function() { return this.name;} 함수의 prototype 프로퍼티와 프로토타입 객체의 constructor 프로퍼티function Rabbit(name) { this.name = name;}// 기본 prototype// Rabbit.prototype = { constructor: Rabbit };let rabbit = new Rabbit(&quot;white rabbit&quot;); 위와같은 줄을 그림으로 표현하면 아래와 같다. Rabbit 함수에서는 Rabbit.prototype과 같이 Rabbit 프로토타입 객체로 접근 가능 Rabbit 프로토타입 객체에서는 constructur 속성은 Rabbit 함수를 참조한다. getName(), setName() 같은 프로퍼티들이 Rabbit 함수에 추가가 되면 프로토타입에 해당 프로퍼티를 유지한다. 따라서, 새로 만든 인스턴스들은 프로토타입 원형을 복사해 사용한다. function Rabbit(name) { this.name = name; alert(name);} let rabbit = new Rabbit(&quot;White Rabbit&quot;); let rabbit2 = new rabbit.constructor(&quot;Black Rabbit&quot;); 위와같은 경우 rabbit 객체의 constructor로 Rabbit 함수에 접근하는 것 자바스크립트는 알맞은 constructor 값을 보장하지 않는다.function Rabbit() {}Rabbit.prototype = { jumps: true};let rabbit = new Rabbit();alert(rabbit.constructor === Rabbit); // false 위처럼 기본 prototype 값을 다른 객체로 바꾸면 이 객체에는 contructor가 없을 것..깊이 이해하기 아래와같은 코드를 베이스로 변경하는 경우의 시나리오를 알아보기function Rabbit() {}Rabbit.prototype = { eats: true};let rabbit = new Rabbit();alert( rabbit.eats ); // true이미 만들어진 객체에 대해서는 영향을 주지 않는다 .function Rabbit() {}Rabbit.prototype = { eats: true};let rabbit = new Rabbit();Rabbit.prototype = {}; // add this linealert( rabbit.eats ); // trueRabbit.prototype이 참조하는 객체는 하나뿐이기 때문에 참조를 통해 객체 내용을 변경하면 다른 참조를 통해서도 변경 내용을 볼 수 있다.function Rabbit() {}Rabbit.prototype = { eats: true};let rabbit = new Rabbit();Rabbit.prototype.eats = false; // add this linealert( rabbit.eats ); // false객체의 프로퍼티를 제거해도 따로 변화가 없다. 그러나, 객체가 참조하는 prototype 객체를 변경하면 달라진다.function Rabbit() {}Rabbit.prototype = { eats: true};let rabbit = new Rabbit();delete rabbit.eats;alert( rabbit.eats ); // truedelete Rabbit.prototype.eats;alert( rabbit.eats ); // undefined 만약 rabbit에서 eats를 재정의해서 사용하고 있고, 그 때 rabbit.eats를 건드리면 그 객체의 프로퍼티가 변경 될 것시나리오로 이해하기function User(name) { this.name = name;}User.prototype = {}; // (*)let user = new User(&#39;John&#39;);let user2 = new user.constructor(&#39;Pete&#39;);alert( user2.name ); // undefined new user.constructor(&#39;Pete&#39;)는 user에서 constructor를 찾는데 아무것도 찾지 못한다. 객체에서 원하는 프로퍼티를 찾지 못했기 때문에 프로토타입 객체에서 검색을 한다. user의 프로토타입은 User.prototype인데, User.prototype은 빈 객체이다. User.prototype은 일반 객체 {}이고, 일반 객체의 프로토타입은 Object.prototype이다. Object.prototype.constructor == Object이므로 Object가 사용된다.Reference)모던 JavaScript 튜토리얼 https://ko.javascript.infoNode.js 디자인패턴" }, { "title": "모던 JavaScript 튜토리얼 - 테스트 자동화와 Mocha", "url": "/posts/%EB%AA%A8%EB%8D%98_Javascript_%ED%8A%9C%ED%86%A0%EB%A6%AC%EC%96%BC_%ED%85%8C%EC%8A%A4%ED%8A%B8%EC%9E%90%EB%8F%99%ED%99%94_Mocha/", "categories": "Study, JavaScript", "tags": "javascript, js", "date": "2021-07-14 00:00:00 +0900", "snippet": ": 개발한 내용의 신뢰성을 높여 궁극적으로 코드 전반의 신뢰도를 높이는 작업BDD ? 핵심: 테스트, 문서, 예시를 갖도록 테스트: 함수가 의도하는 동작을 제대로 수행하는지 하나의 테스트 패턴 - Given, When, Then 구조 시나리오 기반으로 테스트를 작성. 모든 시나리오를 작성하도록 문서(스펙) 함수가 어떤 동작을 수행하는지(describe, it 에 스펙 설명) 기존 함수 변경 시, 개발자는 스펙을 기준으로 함수를 보다 안전하게 변경 가장 중요한 것 - 기존에 구현된 기능들에 영향을 주지 않는다는 것을 보장할 수 있게 됨. 예시 실제 동작하는 예시를 이용해, 함수를 실제로 어떻게 사용할 수 있는지 설명하는 역할 테스트 실행 도구 Mocha Node.js 프로그램에서 사용되는 JavaScript test 프레임워크. describe, it 과 같은 테스트 실행 관련 주요 함수 제공 브라우저의 지원을 받으며, 비동기 테스트, 커버리지 report, assertion 라이브러리들을 지원 Chai Assertion 함수 제공 assert.equal, assert.strictEqual, assert.notEqual, assert.isTrue 등. 문서 참고해 작성하기 Chai - https://www.chaijs.com/api/assert/ Sinon 내장함수라던지, 실제로 만들기 어려운 가짜 객체를 만들어 테스트에 용이하도록 Mock 객체를 이용하는 것이 불가피한 경우가 있지만, 아닌 경우엔 최대한 지양하는게 좋다는 의견이 많음. “100% 실제 환경과 같을 수 있는가?” 를 생각한다면, 아닌 경우도 분명 존재하기 때문 명세서(Specification == Spec)describe(&quot;foo&quot;, function() { brfore(() =&amp;gt; console.log(&quot;before test&quot;)); after(() =&amp;gt; console.log(&quot;after test&quot;)); beforeEach(() =&amp;gt; console.log(&quot;before unit test&quot;)); it(&quot;bar&quot;, function() { assert.equal(myFunc(2), 10); });}); describe(&quot;title&quot;, function() {...}) 구현하고자 하는 기능에 대한 설명. 비슷한 유즈 케이스에 관한 it 유닛 테스트들을 한데 모아놓음 중첩 describe 를 통해 하위 그룹을 정의할 수 있다. 각 중첩 describe 컨텍스트에서 정의한 변수, 함수들에는 다른 곳에서 접근X it(&quot;use case&quot;, function() {...}) 이 it 테스트가 테스트 할 하나의 유즈 케이스를 명시 하나의 유닛 테스트라고 생각 이 하나의 유닛 테스트에서 하나만 확인할 것 .only를 통해 해당 키워드를 준 유닛테스트들만 따로 테스트 가능 assert 예상한대로 동작하는지 확인하는 것 before, after 전체 테스트 시작 전, 후 주로 초기화 용도 beforeEach, afterEach 각 unit test 시작 전, 후 주로 초기화 용도 개발 순서 명세서 초안 작성: 가능한 모든 시나리오를 구상해 작성 명세서 코드 작성 Mocha 프레임워크를 이용해 명세서 실행 후 모두 통과하는지 확인 테스트 추가, 커버리지 높이면서 테스트 성공하는지 확인describe(&quot;foo&quot;, () =&amp;gt; { beforeEach(() =&amp;gt; { }) it(&quot;bar1&quot;, ()=&amp;gt; { // ... }) it(&quot;bar2&quot;, () =&amp;gt; { // ... }) it(&quot;bar3&quot;, () =&amp;gt; { });});Reference)모던 JavaScript 튜토리얼 https://ko.javascript.info" }, { "title": "HTTP 완벽가이드 4장 - 1. TCP 커넥션", "url": "/posts/HTTP_%EC%99%84%EB%B2%BD%EA%B0%80%EC%9D%B4%EB%93%9C_4%EC%9E%A5_1_TCP_%EC%BB%A4%EB%84%A5%EC%85%98/", "categories": "Study, HTTP", "tags": "http, tcp, tcp connection", "date": "2021-07-14 00:00:00 +0900", "snippet": "TCP 커넥션: 클라이언트와 서버가 TCP 소켓 인터페이스를 사용해 상호작용하는 과정 위쪽(S1~C2) 에서 소켓 열고, 가운데에서(C3, S5, C4) TCP 핸드셰이크, 아랫쪽 실제 통신 HTTP 커넥션은 몇몇 사용 규칙을 제외하고는 TCP 커넥션에 불과하다. TCP는 HTTP에게 신뢰성 있는 통신을 제공 네트워크 계층의 IP로 해당 컴퓨터에 연결, 전송 계층의 Port로 해당 애플리케이션에 연결 TCP는 포트번호를 통해 여러개의 커넥션을 유지한다.(구분한다) &amp;lt;발신지 IP, 발신지 Port, 수신지 IP, 수신지 Port&amp;gt; 를 통해 유일한 커넥션을 생성한다. - 둘은 있을 수 없다. 위 그림 기준 HTTP 트랜잭션을 처리하는 시간은 C6~S7 사이의 과정으로 TCP 커넥션 설정, 요청 전송, 응답 전송과 같은 과정에 비해 짧다. 실제로 대부분의 HTTP 지연은 TCP 지연 때문에 발생한다. 원인: DNS loop up, TCP 커넥션 생성(핸드셰이킹), HTTP 요청, 처리, 응답 TCP 지연에 관련된 중요 요소1. TCP 핸드셰이크 지연 TCP 패킷(SYN)을 보내고, SYN, ACK 패킷을 받고, ACK 패킷 전송 웬만하면 HTTP 요청 메시지 전체를 담을만큼 ACK 패킷은 큰 경우가 많아 같이보내고, 많은 응답 메시지 역시(html 파일 혹은 리다이렉션) 하나의 IP 패킷에 담긴다. 따라서, 일반적인 경우 TCP 핸드셰이크가 (눈에 띌만큼 충분히 큰) 지연을 발생시킨다고 말하는 것2. 확인응답 지연 TCP의 신뢰성있는 통신을 위해 ACK를 전송하고, ACK 순번에 오류가 있거나 중복인 경우 다시 보낸다. ACK는 크기가 작기 때문에, 같은 방향으로 송출되는 패킷에 편승(pickyback) 시켜 한번에 보낸다. 확인응답 지연 알고리즘 : 0.1~0.2초 동안 버퍼에 저장해 기다린다. 찾으면 함께, 찾지 않으면 그냥 별도로 패킷을 만들어 보낸다.3. TCP 느린 시작(slow start) (혼잡 제어)인터넷의 부하와 혼잡을 방지하기 위해 자체적으로 튜닝된다. 튜닝된 커넥션: 느린시작이 적용되고 이미 몇번 사용되어 많이 전송하도록 변한 커넥션 - 지속 커넥션과 연관 혼잡 윈도우를 연다 : 처음에는 패킷 하나, ACK를 받으면 2개를 보낼 권한, 또 받으면 4개를 보내는 권한이 생긴다.4. 네이글 알고리즘 애플리케이션이 작은 크기의 데이터를 전송할 수 있도록 TCP는 데이터 스트림 인터페이스 를 제공한다. (버퍼 방식과 다르다). 그러나, 작은 크기의 데이터를 포함하고 있는 많은 수의 패킷을 보내는 것은 성능을 크게 떨어트릴 수 있다. 네이글 알고리즘 : 세그먼트가 최대 크기가 되지 않으면 전송하지 않음. 앞으로 생기지 않을 데이터를 기다리게 될 수 있다. 확인 응답 지연 알고리즘과 함께 쓰이면 더욱 성능 저하를 초래한다. -&amp;gt; 확인 응답 알고리즘은 패킷을 받기를 기다리고, 네이글 알고리즘은 세그먼트가 다 채워지기 전까지 보내기를 미루기 때문에 5. 포트 고갈 심각한 성능 저하를 발생시키지만, 실 상황에선 많이 없다. TCP 커넥션이 끊기고 나서 인터넷 상에 있는 전달되지 못한 패킷이 해당 port, ip를 사용하는 새로운 커넥션에 잘못 유입될 수 있다. 이 것을 방지하고자 2MSL(보통 2분) 동안 같은 ip, port를 사용하는 커넥션을 생성하지 못하게 한다. 성능 테스트에서 문제 : 발신지 IP, 수신지(서버) IP, Port는 고정이므로 발신지 Port만 변수가 되는데, Port(6만개) / 2MSL(120초) = 약 500개로 초당 커넥션이 제한된다.Reference)HTTP 완벽가이드" }, { "title": "DAO vs Repository", "url": "/posts/DAO_Repository/", "categories": "Study, Spring boot", "tags": "spring, spring boot, 스프링, 스프링부트", "date": "2021-07-12 00:00:00 +0900", "snippet": "Repository DDD에서 나왔다고 한다. aggregate 하나당 repository 하나 객체-지향적인 인터페이스를 제공. domain layer에 속하는 순수한 도메인 모델 객체 의존성 제거를 위해 Interface, persistence(구현부) 로직으로 분리. 인터페이스(JPA Interface): domain layer 구현부(Hibernate): persistence layer Separated interface : DIP(dependency Inversion Principle)에 기반한 방법 ORM 사용시 객체 단위로 테이블 관리하고, 이때 repository가 DAO 역할 수행DAO persistence layer에 속함. persistence layer에 대한 facade 역할을 수행 위의 repository와 같이 도메인 로직과 persistence 로직을 분리해 separation of concerns 원리 충족의 목적. 하부의 persistence 메커니즘이 DB라는 사실을 숨기지 않는다. DAO의 인터페이스는 CRUD 쿼리와 1:1 매핑되는 세밀한 오퍼레이션 제공 DB 쿼리 단위.(service == 트랜젝션 단위, controller == 업무 단위) 단일 데이터 접근. 실제 비즈니스 로직 처리 : 하나 이상의 DAO 조합 == 트랜젝션 단위 결과적으로 repository의 하나의 오퍼레이션은 DAO의 여러 오퍼레이션에 매핑되는 것이 일반적Refence)http://egloos.zum.com/aeternum/v/1160846https://velog.io/@leyuri/DAO%EC%99%80-Repository-DTO-VO" }, { "title": "모던 JavaScript 튜토리얼 - Javascript란?", "url": "/posts/%EB%AA%A8%EB%8D%98_Javascript_%ED%8A%9C%ED%86%A0%EB%A6%AC%EC%96%BC_Javascript%EB%9E%80/", "categories": "Study, JavaScript", "tags": "javascript, js", "date": "2021-07-12 00:00:00 +0900", "snippet": ": html 안에 “스크립트”로 작성하고, 브라우저에서 실행할 수 있는 언어. Javascript 엔진: 브라우저 뿐 아니라, 자바스크립트 엔진이 있는 서버, Chrome(V8 엔진), Firefox(스파이더몽키) 등에서 모두 동작 가능. 엔진은 스크립트를 읽고(파싱), 기계어로 전환(컴파일)하고, 실행시킨다. 브라우저를 대상으로 하는 언어이기 때문에 메모리, CPU 등 low-level 영역 조작을 허용하지 않음 공식 명세: ECMA-262, 매뉴얼: MDN, 튜토리얼: 모던 자바스크립트 튜토 참고하면 좋음강점 모든 브라우저에서 지원하고, 기본 언어로 사용되기 때문에 웬만한 브라우저(프론트) 연관 기술은 자바스크립트 간단한 서버를 구성하면 한가지(javascrtip)언어만으로 간단하게 구성 가능 html, css와 통합 가능 - 아래처럼 script 태그에 자바스크립트를 삽입해 간단하게 작성도 가능 혹은 &amp;lt;script src=&quot;/etc/path/exam.js&quot;&amp;gt;&amp;lt;/script&amp;gt; 처럼 링크로하면 내부코드는 무시 그런데, 별도로 만든 스크립트 파일을 브라우저가 받아서 캐시에 저장하기 때문에 성능상 이점이 있다. 따라서, 별개의 파일로 만들어 저장하는 것이 좋음. &amp;lt;!DOCTYPE HTML&amp;gt;&amp;lt;html&amp;gt;&amp;lt;body&amp;gt; &amp;lt;script&amp;gt; alert( &#39;Hello, world!&#39; ); &amp;lt;/script&amp;gt; &amp;lt;/body&amp;gt;&amp;lt;/html&amp;gt; Javascript로 브라우저에서 할 수 있는 일 Node.js 환경에서는 네트워크 요청을 하거나, 임의의 파일을 읽거나 쓸 수 있다. HTML 조작 가능(추가, 수정 등) AJAX같은 기술을 통해 서버에 요청보내기, 파일 업로드, 다운로드 등 가능 쿠키 설정, 브라우저(로컬 스토리지 등)에 데이터 저장, CORS 제어를 통해 탭간 정보 공유 등 CORS같은건 보안때문에 원래는 안됨 Reference)모던 JavaScript 튜토리얼 https://ko.javascript.info/intro" }, { "title": "Sequelize 연관관계", "url": "/posts/Sequelize_%EC%97%B0%EA%B4%80%EA%B4%80%EA%B3%84/", "categories": "Study, Node.js", "tags": "node.js, sequelize", "date": "2021-07-10 00:00:00 +0900", "snippet": "테이블 연관관계와 객체 연관관계: JPA를 공부할 때에도 보았듯 두 연관관계의 차이점은 테이블은 외래키로 양방향 연관관계를 갖지만, 객체는 참조를 통해 단방향 연관관계를 두 개 갖는 것과 같다.Sequelize에서 연관관계 맵핑 방법belongsTo 의미 그대로 A가 B에 속해있을 때 A.belongsTo(B)와 같이 맵핑한다. 이 때 FK는 A의 테이블에 형성된다.hasOne 1 : 1-0 맵핑에서, A가 B를 갖고 있을 때 A.hasOne(B) 이러한 방식으로 맵핑한다. belongsTo와 반대로, target인 B의 테이블에 FK가 생성된다.hasMany 1 : N 맵핑에서 사용된다. 마찬가지로 target의 테이블에 FK가 생성belongsToMany N : M 관계에서 사용되는 듯 하다. 주로 N : M 관계에서는 JPA에서와 마찬가지로 연결 테이블(중간 테이블)로 관리하는게 좋아보이고, 이 때 연결되는 두 테이블에서는 belongsToMany를 갖게 될 것 같다.FK의 주체(연관관계의 주인): JPA에서 연관관계의 주인이라는 개념을 사용하는데, Sequelize에서는 딱히 그러한 용어를 사용하진 않는 것 같다.객체 연관관계에서 어디에 FK를 유지할 것인가?A, B 테이블 중 B 테이블의 컬럼에 A에 대한 FK가 있는 상황에서, A 객체가 갖는 B의 필드값을 변경하고 UPDATE와 같은 쿼리를쳐도 B에 업데이트 되지 않고 B를 통해 업데이트해야한다. join 쿼리로 조회는 되는 것 같다. 생각해봐야 할 것 필요에 따라 양방향으로 객체를 갖을 수 있다. 그런데 A, B 객체 둘다 서로 의존하도록 하면 circular dependency 이고, 이 것에 대한 문제가 발생할 수 있다는 것을 인지하고, 어떻게 처리할 것인지를 생각해야 할 것 같다. 양방향 객체참조를 유지하고 join Query를 가능하게 하기 vs 단발성 조회 Query 두번 날리기 무엇이 더 이득일지 benchmark 테스트 해보기 npm test 시 쿼리 디버깅하기 CLI : DEBUG=${서버 컨테이너이름} npm test e.g) DEBUG=meeting:* npm testReference)https://sequelize.org/master/manual/associations.html" }, { "title": "REST API 특징과 6가지 원칙", "url": "/posts/RESTAPI_%ED%8A%B9%EC%A7%95_6%EA%B0%80%EC%A7%80_%EC%9B%90%EC%B9%99/", "categories": "Study, REST API", "tags": "rest, rest api", "date": "2021-07-07 00:00:00 +0900", "snippet": ": API를 설계 할 때 자원을 나타내는 URI가 있고, http method를 통해 자원을 어떻게 처리할 지 설계하는 방식의 아키텍처자원(resource) - URI / 행위 - HTTP method / 표현 representations특징 URI로 지정된 리소스에 대한 조작을 한정적인 Interface를 통해 수행하는 아키텍처 Stateless client의 상태정보를 따로 저장 안하고 단순히 들어온 요청만을 처리 -&amp;gt; 불필요한 정보 관리 x 만약 stateful하다면 서버가 클라이언트의 현재 상태를 저장해야한다. 따라서 클라이언트의 상태는 서버에 종속된다. 이 상황에서 LB같은걸 하는 경우에 서버 간 클라이언트의 상태를 공유할수있는 redis같은 별도 시스템이 필요. Stateless하기 때문에 어느 서버가 처리하던 클라이언트의 요청은 동일하게 처리 가능. Client-Server 구조: 서버는 API를 제공, 클라이언트는 로그인 정보(토큰)를 관리. 각각의 역할이 구분되고 의존성이 줄어들게 됨장점 원하는 타입으로 데이터를 주고받을 수 있다. -&amp;gt; 보통 JSON http method 타입과 URI만 읽어도 해당 인터페이스가 어떠한 기능과 연결되는지 파악이 용이 Client-Server구조. api로 들어오는 요청을 처리해 요청한대로 보내주기만 하면 된다. 각자의 역할이 명확히 분리단점 복잡한 비즈니스에서 HTTP method의 한계로 인해 모든 경우를 cover할 수 없을 것 같다. 공식화 된 Rest API 표준이 존재하지 않다는 점도 아쉬운 점 중 하나.REST API 6가지 원칙 Uniform Interface - RESTFUL하게 만드는 특징 URI로 지정한 리소스에 대한 조작을 일관된 인터페이스로 수행 이러한 인터페이스를 정하는 원칙들이 있다. 이게 잘 지켜지면, URI등 인터페이스에 관계없이 서버와 클라이언트가 독립적으로 진화 가능 수정사항이 생겨도, 웹을 망가트리지 않고 수정 가능 Stateless 상태가 없다: 세션이나 쿠키를 별도로 저장하고 관리하지 않음. 그저 요청만 처리한다. 서비스의 자유도가 높아지고 구현이 단순해짐 Cacheable HTTP 웹 표준을 그대로 사용하기 때문에 HTTP 웹 기존 인프라를 활용. 따라서 캐시 기능 가능. 응답 메시지에 해당 요청에 대한 캐시 가능여부를 명시해서 준다. 개발자 도구에서 Res 헤더에 cache-control 를 통해 캐시 여부 명시 Client-Server Client(UI)와 Server(데이터 스토리지, 비즈니스 로직) 등 작업을 명확하게 분리 이식성: UI는 여러 플랫폼에서 이식될 수 있다. 확장성: 서버의 확장성(Extensibility) Server는 API를 제공하고 요청에 대한 응답을 준다. Client는 사용자 인증이나 컨텍스트(세션, 로그인 정보)등을 관리한다. Layered system 다중 계층으로 구성 가능하다. 따라서, Proxy, 게이트웨이 등 중간 계층이 있을 수 있다. 클라이언트에서는 본인이 Proxy에 캐싱된 것을 받는지, 웹 서버를 통해 받는지 진짜 WAS까지 요청이 가는지 알 수 없고, 알 필요도 없다. Code on demand (optional) 보통 Xml, Json과같은 데이터(IDL)를 client로 보내주고 client가 이것을 가공하는데, code on demand라는 것은 Client에 보내는 데이터를 바로 실행 가능한 코드를 보내서 이것을 Client에서 그냥 실행하는 것을 말한다. 클라이언트의 구현을 간소화하는 것이다. 선택적 사항 Reference)https://sabarada.tistory.com/9https://meetup.toast.com/posts/92https://mizzo-dev.tistory.com/entry/RESTfulAPIhttps://www.rocketpunch.com/cards/post/436146" }, { "title": "HTTP 완벽가이드 3장 - 3. HTTP 상태코드", "url": "/posts/HTTP_%EC%99%84%EB%B2%BD%EA%B0%80%EC%9D%B4%EB%93%9C_3%EC%9E%A5_3_HTTP_%EC%83%81%ED%83%9C%EC%BD%94%EB%93%9C/", "categories": "Study, HTTP", "tags": "http, http status", "date": "2021-07-05 00:00:00 +0900", "snippet": ": 클라이언트에게 서버에서 무슨일이 일어났는지 말해주는 것 사람이 읽기 편한 사유구절(OK, CREATED)과는 다르게 숫자로 되어있어 프로그램이 에러처리하기에 용이 대략적인 구성: 일반적으로 아래의 구성을 따른다. 따라서, 누군가 상태코드를 확장해 사용하더라도 아래의 범주내에 속한다면 해당 관련 내용으로 이해해야 한다. 100~199: 정보 200~299: 성공 300~399: 리소스 옮겨짐(리다이렉션) 400~499: 클라이언트 에러(잘못된 요청) 500~599: 서버 에러 100 - 199 : 정보성 상태 코드 HTTP/1.1에서 도입100 Continue 요청의 시작부분 일부가 받아들여짐 애플리케이션이 서버에 엔터티 본문을 전송하기 전에 그 본문을 서버가 받아들일지를 확인 이것을 보낸 후 서버는 반드시 요청을 받아 응답해야 한다.클라이언트 클라이언트는 100-continue라는 expect 헤더를 보내고, 100 Continue 상태코드를 받을 것을 기다린다. 그러나, 응답을 막연히 기다리기만 해서는 안되고, 약간의 타임아웃 후에 그냥 엔터티를 보내야 한다. 엔터티 본문을 보내지 않으려면 expect 헤더를 보내지 않아야 한다.서버 서버는 100-continue 응답을 받을 것을 의도하지 않은 클라이언트에게 이 상태코드를 보내서는 안된다. 어떠한 이유로 이미 엔터티를 수신했다면, 이 상태코드를 보낼 필요가 없다. (에러 등의 이유로) 서버가 엔터티 본문을 읽기전에 요청을 끝내기로 결정했다면, 그서버는 그냥 응답을 보내고 연결을 끊어서는 안된다. TCP 끊기와 리셋 에러를 살펴보기 프록시 넥스트 홉 (전달할 다음 서버)가 HTTP/1.1을 따르거나, 어떤 버전을 따르는지 모른다면 Expect 헤더 포함시켜 보낸다. 넥스트 홉 서버가 이전 버전을 따른다는 것을 안다면 클라이언트에게 417 Expectation Failed 에러로 응답. 마찬가지로, 클라이언트가 이전 버전을 따른다는 것을 안다면, 100 Continue 응답을 클라이언트에게 전달해서는 안된다.101 Switching Protocols 서버가 프로토콜을 바꾸었음을 의미200 - 299 : 성공 상태 코드200 OK 요청은 정상이고 엔터티 본문은 요청된 리소스를 포함하고 있음201 Created 서버에 개체를 생성하라는 요청(주로 POST, PUT에 대한 응답) 주로 생성된 리소스에 대한 구체적인 참조 Location 헤더(엔터티 정보 헤더 중 하나), 리소스를 참조할 수 있는 여러 URL을 엔터티 본문에 포함 상태코드 보내기에 앞서 반드시 객체를 생성해야함.202 Accepted 요청은 받아들여졌지만, 서버는 아직 그에 대한 어떠한 동작도 수행하지 않음(무엇을 할 것인지도 모름) 요청이 받아들여지기에 적합하다는 것을 보임203 Non-Authoritative Information 서버의 실제 리소스가 아닌 사본 프록시가 리소스의 사본을 갖고 있다가 전달한 것 등 따라서 메타 정보(헤더)를 검증하지 못한 경우이다. 204 No Content 응답 메시지는 시작줄과 헤더를 포함하고 엔터티 본문 포함X205 Reset Content 브라우저에게 현재 페이지에 있는 HTML 폼의 모든 값을 비우라고 말한다.206 Partial Content 부분 혹은 범위 요청 성공300 - 399 : 리다이렉션 상태 코드 클라이언트가 요청하는 리소스에 대해 다른 위치를 사용하라고 말해주거나, 리소스의 내용 대신 다른 대안 응답 만약 리소스가 옮겨졌다면, 옮겨진 위치(Location 헤더)를 보낼 수 있다. 받은 브라우저는 알아서 새 위치로 이동시켜줌 일반적으로 이 상태코드와 함께 응답을 보낼때는 리다이렉트 될 URL에 대한 링크와 설명을 포함시키는 것이 좋은 습관300 Multiple Choices 여러 리소스를 가리키는 URL을 요청한 경우, 리소스의 목록과 함께 반환 Location 헤더에 선호하는 URL을 포함시킨다. 목록 중 하나를 사용자가 선택301 Moved Permanently 요청 URL이 옮겨졌을 때 사용. Location 헤더에 현재 리소스의 위치 URL을 포함해야한다.302 Found 301과 같으나, 요청한 리소스의 URI가 일시적으로 변경되었음을 의미303 See Other 리소스를 다른 URL에서 GET 요청을 통해 얻어야 할 때 사용 새 URL은 응답 메시지의 Location 헤더에 존재304 Not Modified 캐싱되어있는 리소스가 수정되지 않았다면, 클라이언트는 이것을 받고 계속해서 캐시된 버전을 사용하면 됨305 Use Proxy 보안을 목적으로, 리소스를 반드시 Proxy를 통해 접근해야 함을 나타낸다. 프록시의 위치는 Location 헤더에 존재 307 Temporary Redirect 302 Found와 동일한 의미.302, 303, 307의 관계 HTTP/1.0 클라이언트가 POST 요청을 보내고 302를 받으면, Location 헤더의 리다이렉트 URL을 GET 요청으로 따라갈 것이다. HTTP/1.1에서는 그러한 리다이렉션에 303을 사용한다. 이 혼란을 막기 위해 HTTP/1.1에서는 일시적인 리다이렉트를 위해 302 대신 307을 사용 여전히 302는 HTTP/1.0를 위해 남겨놓음 서버는 적절한 상태 코드를 선택하기 위해 클라이언트의 HTTP 버전을 검사할 필요가 있다.400 - 499 : 클라이언트 에러 상태 코드 많은 클라이언트 에러가 브라우저에 의해 처리400 Bad Request 클라이언트가 잘못된 요청을 보냈다고 말해줌 Invalid parameter 등401 Unauthorized 클라이언트에게 스스로를 인증하라고 요구하는 것402 Payment Required 아직 사용되지 않고, 미래를 위해 만들어 둔 것. 디지털 결제 시스템에 사용될 것403 Forbidden 요청이 서버에 의해 거부되었음 Reason을 엔터티 본문에 포함시킬 수 있음. 그러나, 보통 서버가 거절의 이유를 숨기고 싶을 때 사용 401과는 다르다.(서버 입장에서 클라이언트가 누군지는 알고 있음)404 Not Found 요청받은 URL에 해당하는 리소스를 찾을 수 없음 이 경우 엔드포인트는 적절하지만, 리소스 자체는 존재하지 않음을 의미할 수도 있음405 Method Not Allowed 요청한 URL에 대해 지원하지 않는 메서드로 요청 받았을 때 예를들어 어떤 리소스를 삭제하는 것을 금지해놓을 수 있다. Allow 헤더(엔터티 정보 헤더 중 하나)가 포함되고, 여기에 어떤 메서드가 허용되는지가 포함되어야 한다.406 Not Acceptable 서버주도 콘텐츠 협상 이후, User agent에서 정해준 규격에 따른 어떠한 콘텐츠도 찾지 못했을 때 콘텐츠 협상: 사용자 에이전트가 사용자에게 제일 잘 맞는 것이 무엇인지(문서의 언어, 이미지 포맷 혹은 인코딩 등에 있어 어떤 것이 적절한지) 협상하는 것 주어진 URL에 대한 리소스 중 클라이언트가 받아들일 수 있는 것이 없는 경우 407 Proxy Authentication Required 401과 같으나, 프록시에 의한 인증이 필요408 Request Timeout 클라이언트의 요청을 완수하기에 시간이 너무 많이 걸리는 경우, 서버는 이 상태코드로 응답하고 연결을 끊음409 Conflict 요청이 현재 서버에 충돌을 일으킬 염려가 있다고 생각될 때410 Gone 404와 비슷하나, 서버가 한때 그 리소스를 갖고있었는데 제거된 경우411 Length Required 서버가 필요로하는 Content-Length 헤더 필드가 요청 메시지에 정의되지 않은 경우412 Precondition Failed 클라이언트가 조건부 요청을 했는데 그 중 하나가 실패했을 때417 Expectation Failed Expect 헤더에 서버가 만족시킬 수 없는 expect가 담겨있는 경우500 - 599 : 서버 에러 상태 코드 프락시는 서버의 문제를 설명하기 위해 500번대 서버 에러 상태 코드를 생성한다.500 Internal Server Error 서버가 요청을 처리할 수 없게 만드는 에러를 만났을 때501 Not Implemented 서버가 처리 방법을 모를 때 e.g) 서버에서 지원하지 않는 메서드를 요청에 사용한 경우502 Bad Gateway 게이트웨이나 프락시가 잘못된 응답을 얻은 경우. e.g) 부모 게이트웨이에 접속이 불가능할 때503 Service Unavailable 현재는 요청을 처리해줄 수 없지만, 나중에 가능한 경우 나중이 언제일지를 안다면 Retry-After 헤더를 응답에 포함504 Gateway Timeout 408 Request Timeout과 비슷하지만, 게이트웨이나 프락시가 응답을 기다리다 타임아웃이 난 경우505 HTTP Version Not Supported 서버가 지원할 수 없는 버전의 프로토콜 요청을 받았을 때Reference)HTTP 완벽가이드https://developer.mozilla.org/ko/docs/Web/HTTP/Status" }, { "title": "HTTP 완벽가이드 3장 - 2. HTTP 메서드", "url": "/posts/HTTP_%EC%99%84%EB%B2%BD%EA%B0%80%EC%9D%B4%EB%93%9C_3%EC%9E%A5_2_HTTP_%EB%A9%94%EC%84%9C%EB%93%9C/", "categories": "Study, HTTP", "tags": "http, http method", "date": "2021-07-05 00:00:00 +0900", "snippet": ": 서버에게 무엇을 해야할지 말해주는 것 HTTP의 일곱가지 기본 메서드 메서드 설명 (일반적으로)본문 포함하는가? GET 서버에서 데이터를 가져옴 X POST 서버에게 해당 데이터 처리를 요청 O PUT 서버에 요청 메시지의 본문을 저장 O DELETE 서버에서 데이터 제거 X HEAD 서버에서 데이터에 대한 헤더를 가져옴 X TRACE 메시지가 프락시를 거쳐 서버에 도착하는 과정 추적 X OPTIONS 서버가 어떤 메서드를 수행할 수 있는지 확인 X 확장 메서드: 이외에도 서버마다 각 메서드를 추가로 구현해놓았을 수도 있음 LOCK(리소스 잠금), COPY(복사), MOVE(옮김) 등 이걸 사용할 땐 프록시 등 중간 매체는 모르는 메서드에 대해 관용적이어야 한다. 엄격하게 보내고 관대하게 받아들여라 마찬가지로, 모든 메서드가 다 구현되어있지 않을 수 있음. 안전한 메서드: GET, HEAD. 이 두 메서드는 서버에 어떠한 변화(side effect)를 주지 않는다. 안전하지 않은 메서드 사용 시, 영향이 있을 수 있음을 사용자에게 알리도록 애플리케이션을 만들어야한다. e.g 경고 메시지GET 초기에 (HTTP/0.9 까지) 이 메소드밖에 없었다. 일반적으로 POST보다 빠르다. 일반적으로 브라우저 캐시나 프록시, 웹서버에 의해 캐싱되어 사용되기 때문 패킷이 가볍다: 본문이 없고, 때문에 content-type, content-length 등 내용(content)에 관한 헤더 또한 없다.HEAD 서버는 헤더만을 응답으로 돌려주고 엔티티 본문은 절대 반환되지 않는다. 리소스를 가져오지 않고도, 타입 등 정보를 알 수 있다. 리소스 존재 여부를 확인하고자 할 때 리소스 변경 여부 검사할 때 반환받는 응답 헤더가 반드시 GET과 정확히 일치해야 한다.PUT: 리소스 존재하면 수정. 리소스 없다면 만들어 저장하기도 함. 데이터 변경 가능성 있기 때문에 일반적으로 인증을 필요로 함.POST: 생성의 의미로 많이 쓰이지만, 원래는 서버에 입력 데이터를 전송(수행) 하기 위한 목적 서버는 전송받은 데이터를 처리할 서버 게이트웨이 프로그램에 전달한다. HTTP/1.0 에서 추가됨. 일반적으로 멱등하지 않다.(계속 요청하면 계속 리소스 생성)TRACE: 어떤 경로로 서버까지 전달되었는지 추적. 진단의 목적 클라이언트의 요청은 방화벽, 프록시, 게이트웨이 등을 통해 서버까지 가고, 서버는 자신이 받은 요청 메시지를 본문에 넣어 TRACE 응답을 되돌려준다. 클라이언트가 보낸 메시지가 변조되었는지, 유실되었는지 등을 확인 가능 중간 애플리케이션들이 서로 다른 HTTP 메서드들에 대해 일관되게 다룬다고 가정하는 문제. 실제로 Proxy는 POST는 바로 통과, GET은 웹 캐시와 같은 애플리케이션으로 전송 OPTIONS: 어떤 메서드가 지원되는지를 물어볼 때 CORS의 preflight를 이거로 날려서 가능한지 확인 여러 리소스에 실제로 접근하지 않고도, 어떻게 접근하는게 최선인지를 확인 가능.Reference)HTTP 완벽 가이드" }, { "title": "Redis Replication / Cluster와 Sentinel", "url": "/posts/Redis_cluster_sentinel/", "categories": "Study, Redis", "tags": "redis, 레디스", "date": "2021-07-03 00:00:00 +0900", "snippet": "배경 언제사용? 물리 머신이 가진 메모리보다 더 많은 데이터를 저장해야 할 경우 Failover를 통해 HA(high availability)를 보장해야 할 경우 Redis master-slave(using sentinel) vs Redis cluster1. Master Slave(Replication) Master : slave = 1 : n 가능 마스터는 Read Write, 슬레이브 Read Only replica-read-only를 사용해서 슬레이브 RO / RW 설정 가능 이 때 RO / RW 정보를 Client가 알아야하는데, 이 때 HA Proxy를 사용 Master는 Data 변경시 변경 내용을 backlog에 기록하고 slave는 backlog 를 바탕으로 replication. HA시에 데이터를 유지하려면 persistence 기능을 사용해야 한다. 디스크에 저장하거나 repl-diskless-sync로 디스크를 사용하지 않고 동기화 가능 요청을 받는 프로세스가 아닌, 별도의 자식 프로세스를 통해 복제가 이루어지기 때문에 이것이 성능에 영향을 미치지는 않음. Master가 죽으면 slave가 master에게 주기적으로 connection 요청 복구 가능 - Master 살아나고 slave는 replication 수행해 Master와 동기화 살아날 때 까지 기다리면 성능 저하 복구 불가 - Slave중 하나를 master로 승격, 기존의 master를 slave로 강등(Sentinel 방식) 2. Sentinel 위의 Replication 방식에서 Master의 downtime은 redis cluster의 가용성을 저하(그 동안 write 동작 수행 불가하기 때문), sentinel방식은 이를 해결해줌. 주로 Replication보다 더 효율적으로 HA를 얻고자 할 때 사용 HA 정책만 다르고 Replication과 마찬가지로 Master는 RW / Slave는 RO HAProxy 이용 HA : Redis 관리자 간섭 없이 자동으로 failover redis와 별도로 여러 Sentinel process.(fail over를 위해 보통 최소 3개, 홀수 개) 홀수 개수로 split brain(additional master)를 방지 Kafka에서의 정책과 같음(투표 동률 방지) 2개 이상으로 SPOF(Single point of failure) 방지 SPOF(단일 장애점): 한 노드로 구성되어있는 시스템에서 이 노드 오작동으로 전체 시스템 중단을 야기 HAProxy master RW(Read/Write), slave RO(Read only) 이기 때문에 client는 각각의 IP, Port를 알고 적절히 붙어서 동작을 해야한다. 따라서 master 교체상황에서 client의 redis 설정 또한 변경. → 일일히 계속 바꾸는것은 쉬운 일이 아니기 때문에 HAProxy 이용.(HAProxy가 tcp-check로 주기적으로 master, slave 동작 파악) HAproxy는 client에게 redis의 master, slave에 일정하게 접근 할 수 있는 end-point를 제공.3. Redis Cluster 주로 대용량 트래픽을 감당해야 할때 데이터를 나누어 저장 Redis에서 제공하는 replication 중 샤딩을 이용한 메커니즘. Sentinel과는 다른 용도로 사용됨 각 redis는 다른 모든 redis들과 직접 연결하여 gossip protocol을 통해 통신. → Multi-master, multi-slave. client 또한 모든 redis와 직접 연결해 data 주고받음. gossip Protocol 기본 port는 16379 → (Redis보다 10000 높은 번호를 사용) 각 master는 Hash Slot이라는 data 저장구역을 다른 master와 나누어 소유.(위 그림은 hash slot을 3개로 균등 분할해 구성한 모습) CRC16을 이용해 16384개의 슬롯 균등 분배 운영 중단 없이 Hash slot 다른 노드로 이동 가능 각 Master에 할당된 hash slot은 redis 관리자에 의해 동적으로 변경 가능 Master와 Slave 추가삭제 또한 동적으로 가능 위 그림은 1:1이지만, Slave 추가를 통해 Master : slave = 1 : n 가능 Client는 cluster에 포함된 아무 redis에게 요청을 보냄. 처리 가능할 경우 - redis에선 처리 가능한 요청은 처리 처리 불가할 경우 - 처리가능한 redis의 정보를 client에게 전달. e.g. slave에게 write를 보내면 해당 slave는 처리가능한 master redis 정보를 client에게 전달 하고 redirection master 죽을 시 slave는 gossip Protocol을 통해 master의 죽음을 파악한 뒤 스스로 master로 승격. → 이 때 replication은 async이기 때문에 죽음으로 data 정합성이 깨질 수 있다. 깨진 정합성으로 인해 data 충돌이 발생할 경우 무조건 나중에 master가 된 data 기준으로 정합성을 맞춤. #### References https://redis.io/topics/cluster-tutorial https://www.letmecompile.com/redis-cluster-sentinel-overview/ http://redisgate.kr/redis/configuration/replication.php#diskless_replication https://goodgid.github.io/Redis-Master-Slave-and-Cluster/ https://medium.com/garimoo/redis-documentation-2-레디스-클러스터-튜토리얼-911ba145e63 " }, { "title": "HTTP 완벽가이드 3장 - 1. HTTP 메시지", "url": "/posts/HTTP_%EC%99%84%EB%B2%BD%EA%B0%80%EC%9D%B4%EB%93%9C_3%EC%9E%A5_1_HTTP_%EB%A9%94%EC%8B%9C%EC%A7%80/", "categories": "Study, HTTP", "tags": "http, http message", "date": "2021-07-02 00:00:00 +0900", "snippet": ": HTTP가 인터넷 배달원이라면, HTTP 메시지는 실제 보내지는 배달물메시지의 흐름 방향: 인바운드, 아웃바운드, 업스트림, 다운스트림 인바운드: 클라이언트(사용자 에이전트) -&amp;gt; 원 서버. 서버(파드) 입장에서 볼 때 들어오는 것 아웃바운드: 원 서버 -&amp;gt; 사용자 에이전트(클라이언트). 서버(파드) 입장에서 볼 때 나가는 것 업스트림, 다운스트림: 메시지는 항상 다운스트림으로 흐른다. 발송자는 수신자 입장에서 업스트림 서버 &amp;lt;-&amp;gt; 프락시 &amp;lt;-&amp;gt; 클라이언트 사이를 흐른다.메시지의 구조시작줄, 헤더, 본문e.g ) 응답메시지 예.시작줄 : HTTP/1.1 201 CREATED헤더 : Content-type: text/plain Content-length: 19빈줄본문 : Hello world! 시작줄과 헤더에는 캐리지 리턴(Carriage Return. \\r), 개행문자(Line Feed. \\n)로 끝난다.(CRLF) 항상 CRLF는 아니다(LF - 윈도우에서) \\r (캐리지 리턴) : 커서를 맨 앞으로 이동 \\n (라인 피드) : 커서를 아래로 이동. 둘을 함께 사용하면(CRLF) - 다음줄의 가장 앞으로 커서를 이동 본문이 없는 경우에도 CRLF로 끝나야 함. 그러나, 휴먼에러 방지를 위해 마지막 CRLF 없이도 메시지를 잘 받아들일 수 있어야 한다. 헤더는 여러 줄 가능. 빈줄 : 헤더와 본문 구분 본문 : 메시지(데이터) 덩어리 엔터티 본문 요청 메시지와는 시작줄의 문법만 다르다.e.g) 요청 메시지 시작 줄&amp;lt;메서드&amp;gt; &amp;lt;요청 URL&amp;gt; &amp;lt;버전&amp;gt; 요청 URL에 host, port가 생략되어있어도 서버는 자신을 가리키는 것으로 간주e.g) 응답 메시지 시작 줄&amp;lt;버전&amp;gt; &amp;lt;상태 코드&amp;gt; &amp;lt;사유 구절&amp;gt; 버전: HTTP/&amp;lt;메이저&amp;gt;.&amp;lt;마이너&amp;gt; 소수라고 헷갈리지 말 것 : HTTP/2.22는 HTTP2.3보다 큰 버전(22는 3보다 크니까) 사유 구절: 사람에게 읽히기 위한 목적으로 설명하는 문구. HTTP1.0 200 NOT OK 와 HTTP1.0 200 OK는 둘다 성공을 의미하는 것으로 처리되어야 한다. 상태코드와 일대일 대응 Reference)HTTP 완벽가이드" }, { "title": "HTTP 완벽가이드 2장 - URL과 리소스", "url": "/posts/HTTP_%EC%99%84%EB%B2%BD%EA%B0%80%EC%9D%B4%EB%93%9C_2%EC%9E%A5_URL_%EB%A6%AC%EC%86%8C%EC%8A%A4/", "categories": "Study, HTTP", "tags": "http, url, http resource", "date": "2021-07-01 00:00:00 +0900", "snippet": "URL(uniform resource locator): 인터넷 상에서의 리소스의 위치. 애플리케이션은 URL을 사용하여 정보에 쉽게 접근 가능. URI(Uniform Resource Identifier)의 부분집합으로 본다. 인터넷에 존재하는 어떤 리소스든지 가리킬 수 있다. 대충 스킴://서버위치/리소스경로 구조. e.g ) https://www.github.com/hungry-jay?tab=repositoriesURN : 리소스가 어디에 존재하든 상관없이 “이름만으로” 리소스 식별 이걸 사용하면 리소스의 위치가 바뀌어도 계속 URN으로 접근 가능 바꿔말하면 URL은 리소스의 위치가 바뀐다면 더이상 사용 불가 URN을 지원하려면 많은 변화가 필요하므로 부담URL의 구조&amp;lt;스킴&amp;gt;://&amp;lt;사용자이름&amp;gt;:&amp;lt;비밀번호&amp;gt;@&amp;lt;호스트&amp;gt;:&amp;lt;포트&amp;gt;/&amp;lt;경로&amp;gt;;&amp;lt;파라미터&amp;gt;?&amp;lt;질의&amp;gt;#&amp;lt;프래그먼트&amp;gt;http://joowon_son:1234@192.168.0.1:8080/index.html;page=1?key=value#abc 스킴: 어떤 프로토콜을 사용할지(http, ftp, smtp 등) 사용자 이름, 비밀번호: 몇몇 스킴에서는 이러한 credential을 사용 ssh -i ${key} ubuntu@${서버주소} 이러한 ssh cli를 생각해보면, key의 자리에 credential 호스트: IP 혹은 호스트명(리소스가 어디에 호스팅 되어있는지) 포트: 리소스를 호스팅하는 서버가 열어놓은 Port 경로: 리소스가 서버 어디에 있는지 가리킨다. 파라미터: 특정 스킴에서 입력 파라미터 기술 용도. key - value 쌍. 애플리케이션이 리소스에 접근할때 필요한 추가 정보(어떤 포트를 열었는지, 사용자 이름을 명시하는지 등) e g) http://www.abc.com/hammers;sale=false/index.html;graphics=true 여기서 두 경로조각(hammers, index.html)은 각 다른 파라미터를 가진다. 질의: 요청받을 리소스 형식의 범위를 좁히기 위해 애플리케이션에 parameter 전달 용도 e.g) ?item = 1234&amp;amp;color=red 프래그먼트: 리소스 일부분 가리키는 이름 .html 같은 리소스에서, 보다 특정된 일부분을 가리킬 때 일반적으로 http는 객체 전체를 다루기 때문에 프래그먼트 전달 X이고, 브라우저가 리소스의 일부를 보여줌. 상대 URL: 리소스 위치 전체를 사용하지 않음. 기저(Base) URL 필요 상대 URL은 프래그먼트이거나 URL 일부 e.g) http://127.0.0.1:8000/index.html 에서 상대 URL로 ./main.html을 가리키고 있다면, 절대 URL은 http://127.0.0.1:8000/main.html이 되는 것 장점 : 리소스 집합 경로를 바꾸더라도, 새로운 기저(base) URL에 의해 해석되기 때문에 변경에 용이URL 확장: 브라우저에 입력하고 있는데 자동 완성시켜주는 것. 이는 Proxy와 같은 다른 HTTP 애플리케이션 사용 시 다른 문제가 있을 수 있다고 함. 호스트 명 확장: naver를 입력하면 자동으로 www. , .com을 붙여 전체 URL을 만들어준다. 히스토리 확장: URL 기록을 저장해 놓는 것. URL을 입력하면 그 입력된 URL 앞 글자들을 포함한 완결형태의 URL 선택하게 해줌.URL 인코딩 규칙(안전하지 않은 문자) URL에는 출력되지 않은 문자(공백 등)이 포함될 수 없다. 영어와 이스케이프 문자(\\n, \\t 등) 포함 안전하지 않은 문자를 표현할 수 있는 인코딩 방식: 기호 %로 시작해, 두개의 16진수 숫자인 이스케이프 문자로 바꾼다. http://www.abc.com/%20tools.html 문자 제한: %, /, ., ? 등 몇 문자들은 예약어이므로, 사용하기 위해서는 인코딩 되어야한다. 이외에도 안전하지 않거나 제한된 문자는 변환(인코딩)해야한다.스킴 http:하이퍼 텍스트 전송 프로토콜. 사용자 이름, 비밀번호가 없다 https: 양 끝(client, server)에서 암호화와 복호화를 위해 SSL(secure socket layer)을 사용 ftp: FTP 서버에 있는 파일을 내려받거나 올리기 위한 파일전송 프로토콜 rtsp, rtspu: 실시간 스트리밍 프로토콜 telnet: 대화형 서비스 smtp: 이메일Reference)HTTP 완벽가이드" }, { "title": "HAProxy Config (Redis LB)", "url": "/posts/HAProxy_Config_(Redis_LB)/", "categories": "Study, Redis", "tags": "redis, 레디스", "date": "2021-06-28 00:00:00 +0900", "snippet": "HAProxy에서의 LB 기본적으로 Reverse Proxy 방식으로 동작한다. 별도 conf 파일을 구성해 사용해야 한다.Config 특징 로컬에 설치하면 /etc/haproxy/haproxy.cfg에 존재 도커로 설치하면 따로 config 구성해서 proxy 컨테이너 올릴 때 볼륨 마운트 해주어야 함. 가장 중요한 네가지 global, defaults, frontend, backend swarm과 같이 별도의 DNS 맵핑이 필요한 작업에서는 resolvers라는 것을 통해 따로 맵핑작업을 수행해야 한다. c f) Swarm 환경에서 DNS 네임서버는 127.0.0.11:53 1. global HAProxy에게 low한 level로부터 영향을 미치는 전체적인 보안이나 퍼포먼스 관련된 config e.g) global maxconn 50000 # HAProxy와 붙을 수 있는 최대 커넥션. Out of mem 방지 log /dev/log local0 # 로그 어디에 저장할지(IP 혹은 디렉토리) user haproxy # Root 권한 누구에게 줄지 group haproxy # Root 권한 누구에게 줄지 stats socket /run/haproxy/admin.sock user haproxy group haproxy mode 660 level admin # Runtime API 사용가능하게 함(런타임에 config 변경 등) nbproc 2 # Process, Thread 수 nbthread 4 # Process, Thread 수 ssl-default-bind-ciphers ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE- ... # 보안 관련 ssl-default-bind-options ssl-min-ver TLSv1.2 no-tls-tickets # 보안 관련 2. defaluts front, back의 디폴트를 설정. 즉, 중복을 줄이기 위한 목적 물론 오버라이드 가능. HTTP, TCP 모드를 고를 수 있는데, 둘다 설정하면 TCP, HTTP 따로도 가능 e.g) defaults timeout connect 10s # 서버로의 TCP 연결 지연시간 설정 timeout client 30s # Client와의 연결 지연시간. TCP 에선 timeout이 server와 같아야한다 timeout server 30s # Server와의 연결 지연시간 log global # Global section의 로그 설정을 따른다. mode http # HTTP 모드(더 높은 레벨의 트래픽 감지 필요 시.) or TCP 모드 option httplog # 잘 사용되지 않는 TCP로그보다 더 자세하게 maxconn 3000 # 디폴트 2천. 얼마나 front 연결의 최대 커넥션 3. frontend client가 연결할 수 있는 IP와 port를 정의한다. HAProxy는 백엔드 서버 앞에서 Reverse Proxy 방식을 사용 많은 웹사이트에 노출시키기 위해서는 그만큼 많은 frontend서버를 사용할 듯 e.g) frontend www.mysite.com # 각 웹사이트마다 www.mysite.com 처럼 네이밍가능 bind 10.0.0.3:80 # IP, Port 리스너 bind 10.0.0.3:443 ssl crt /etc/ssl/certs/mysite.pem # SSL 보안 http-request redirect scheme https unless { ssl_fc } # client가 redirect를 할 수 있도록 다른 URL제공 use_backend api_servers if { path_beg /api/ } # 어떤 백엔드 풀과 연결할지 default_backend web_servers 4. backend LB 되기 위한 서버의 그룹에 대한 사항을 정의 e.g) backend web_servers balance roundrobin # 서버 선택 알고리즘. roundrobin, leastconn cookie SERVERUSED insert indirect nocache # Sticky Session 유지를 위해 쿠키 전달 option httpchk HEAD / # 헬스체크. TCP는 connection 관련 체크만, HTTP는 # 성공적 HTTP 응답까지 오는지 체크. 디폴트로는 OPTTIONS 메서드를 # 통해 헬스체크 (2~300대 응답이 오는지) default-server check maxconn 20 # 헬스체크, maxconn 등 default config 설정 server server1 10.0.1.3:80 cookie server1 # 핵심 부분. IP 대신 도메인을 사용하면 시작시에 resolve된다. server server2 10.0.1.4:80 cookie server2 # 혹은 직접 resolvers를 통해 runtime에 업데이트되도록 구현 # 포트가 명시되지 않으면 클라이언트가 접속한 포트 사용 # maxxconn을 설정해야한다.(여기선 default-server에 설정) Reference)https://www.haproxy.com/blog/the-four-essential-sections-of-an-haproxy-configuration/" }, { "title": "Scope function(let, also, run, apply, with)", "url": "/posts/Scope_function/", "categories": "Study, Kotlin", "tags": "kotlin", "date": "2021-06-28 00:00:00 +0900", "snippet": "letval numbers = mutableListOf(&quot;one&quot;, &quot;two&quot;, &quot;three&quot;, &quot;four&quot;, &quot;five&quot;)numbers.map { it.length }.filter { it &amp;gt; 3 }.let { println(it) // and more function calls if needed} 타입 T의 확장함수 lambda result: Block의 마지막 return값에 따라 let의 return도 변한다. T?.let { } 형태를 통해 null 관리 가능withval numbers = mutableListOf(&quot;one&quot;, &quot;two&quot;, &quot;three&quot;)val firstAndLast = with(numbers) { &quot;The first element is ${first()},&quot; + &quot; the last element is ${last()}&quot;}println(firstAndLast) 확장 함수가 아니라 일반 함수. 블록 내부에서 lambda result를 반환한다. it을 통해서가 아니라 블럭 안에서 곧바로 person의 프로퍼티에 접근 가능. 사용 용도: 람다 result를 반환하지 않으면서 이 객체로 무언가 수행하길 원할 때 “ with this object, do the following.”runval result = service.run { port = 8080 query(prepareRequest() + &quot; to port $port&quot;)} with처럼 인자로 람다 리시버를 받는다. T의 확장함수 어떠한 객체를 초기화하기 위한 명령문들을 하나의 블럭으로 묶어 가독성을 높이는 용도applyval adam = Person(&quot;Adam&quot;).apply { age = 32 city = &quot;London&quot; }println(adam) T의 확장함수, T를 그대로 반환 it, this를 사용할 필요 없다. 사용 상황: “apply the following assignments to the object.” 블럭에서 return값을 받지 않는다.alsoval numbers = mutableListOf(&quot;one&quot;, &quot;two&quot;, &quot;three&quot;)numbers .also { println(&quot;The list elements before adding new one: $it&quot;) } .add(&quot;four&quot;) T의 확장함수, T를 그대로 반환. 객체의 속성을 전혀 사용하지 않거나 변경하지 않을 때 also 사용 주로 프로퍼티가 아니라 객체 자체에 대한 참조가 필요할 때 사용하라고 권장 “and also do the following with the object.”Reference)https://kotlinlang.org/docs/scope-functions.htmlhttps://0391kjy.tistory.com/25" }, { "title": "Java Servlet", "url": "/posts/Servlet/", "categories": "Study, Java", "tags": "java, servlet, 서블릿", "date": "2021-06-23 00:00:00 +0900", "snippet": ": 웹 요청에 대해 동적인 처리가 가능한 Server Side에서 돌아가는 Java 프로그램 data processing(Controller) 역할? Java 코드 안에 HTML 코드가 들어가있는 형태(하나의 클래스) 서블릿이 한번 수정되면 다시 컴파일해 업데이트 한 후 재배포 해야함(개발 생산성 저하)동작 과정 웹서버가 HTTP request를 Web Container(서블릿 컨테이너)에 위임한다. WEB_INF/web.xml 설정에서 어떤 URL과 매핑되어 있는지 확인하고, 요청에 맞는 적절한 서블릿 실행 이 때 만약 서블릿 객체가 메모리에 없다면 2번 수행(초기화). 메모리에 있다면 3번 수행 Container는 service() 메서드 호출(실제 요청) 전에 servlet 객체를 메모리에 올린다(초기화). Web Container는 적절한 Servlet 파일을 컴파일(.class 파일 생성)하고, 메모리에 올려 Servlet 객체 만듦 메모리에 로드될 때 Servlet 객체를 초기화하는 init() 수행 Container는 request가 올때마다 스레드 생성해 처리 각 스레드 생성 후 서블릿의 service() 를 통해, 입력받은 메소드가 무엇이냐에 따라 doGet(), doPost() 등 적절한 메서드를 호출하고, 이 메서드만 수행하고 나면 스레드는 종료( destroy() ) 각 요청마다 하나씩 스레드를 만들기보다, Thread Pool을 만들어 WAS에게 관리를 맡김 따라서 WAS가 서블릿의 생명주기를 담당. 아래의 그림 참고 서블릿 메소드 init() : 초기화 역할 한 번만 수행 서블릿 객체가 메모리에 로드될 때 수행 service() : 요청에 맞는 메소드 수행 요청 개수 만큼 수행 구현체가 HttpServlet에 존재 HttpServlet의 service() 메서드는 템플릿 메서드 패턴으로 구현되어 있음 추상 클래스와 실제 구현체를 만들고, 추상 클래스를 다른 클래스들이 오버라이딩 하도록 하는 패턴 구현체는 HttpServlet에, 추상 메서드는 GenericServlet에 따라서 HttpServlet을 상속받은 Servlet 클래스에서 해당메서드를 오버라이드하지 않았다면, 그 부모인 HttpServlet의 service()가 호출 즉, 하위 클래스(Servlet)에서 개발자가 직접 doGet, doPost 등의 메서드를 오버라이드해두면 HttpServlet의 service() 메서드가 요청에 맞는 메서드(하위 클래스에서 오버라이드한 메서드)를 호출하게 됨 각 요청마다 수행되는 스레드에서 임계 영역 문제를 고려해야 함 각 스레드는 Stack(지역 변수)과 PC 레지스터를 독립적으로 갖고 나머지는 공유 따라서 Heap에서의 static 변수, 전역 변수 에 대한 고려 필요 destroy() : 객체 메모리에서 제거 한 번만 수행 웹 어플리케이션 갱신 or WAS 종료 시 수행 Reference)https://gmlwjd9405.github.io/2018/10/28/servlet.htmlhttps://github.com/WeareSoft/tech-interview/blob/master/contents/etc.md" }, { "title": "JPA Transaction", "url": "/posts/JPA_Transaction/", "categories": "Study, JPA", "tags": "jpa, spring boot jpa, transaction", "date": "2021-06-22 00:00:00 +0900", "snippet": "@Transactional : 선언적 트랜잭션 클래스나 메서드에 이 어노테이션이 추가되면 트랜잭션 기능이 적용된 프록시 객체가 생성 이 프록시 객체는 @Transaction 이 포함된 메소드 호출시 PlatformTransactionManager를 사용해 트랜잭션 시작 이후 commit or rollback 비즈니스를 하나의 트랜잭션 단위로.옵션 Isolation(격리 수준) transaction에서 일관성 없는 데이터를 허용하는 수준. 격리 수준이 올라갈수록 성능은 저하된다.(보다 엄격하게 수행하므로) 격리 수준 종류 0: READ_UNCOMMITED: 변경사항이 커밋되지 않는 데이터 읽기 허용 - 그냥 다 읽음 1: READ_COMMITED: 변경사항이 커밋되어 확정된 데이터만 읽음 - Shared Lock (X) 2: REPEATABLE_READ : 한 트랜잭션이 레코드를 읽고 있을 때 다른 트랜잭션은 해당 영역 수정 및 삭제 불가해짐. - Shared Lock (O) 3: SERIALIZABLE: 선행 트랜잭션이 읽는 데이터에 새로운 레코드 삽입까지 불가능 - Shared, Gap Lock (O) propagation 트랜잭션 도중 다른 트랜잭션 호출시 선택 옵션 readOnly 속성 트랜잭션 읽기 전용으로 설정해 commit 시 영속성 컨텍스트에 flush 하지 않는다. -&amp;gt; 성능 최적화 insert, update, delete 등 발생 시 예외 발생 e.g. ) @Transactional(readOnly = true) 트랜잭션 롤백 예외 Runtime Exception (UnCheckedException) 발생시 롤백 바꿔 말하면 CheckedException 발생 시에는 롤백되지 않음. 따라서 모든 예외에 대해서 모두 롤백하고 싶다면 아래와같이 명시해줘야 함 rollbackFor 속성: 특정 예외 발생시 강제로 Rollback @Transactional(rollbackFor=Exception.class) noRollbackFor 속성: 예외 발생시 rollback 처리 x @Transactional(noRollbackFor=Exception.class) Timeout 속성 @Transactional(timeout=10) JPA에서 디폴트 @Transactional JPA에서 제공하는 기본 메서드는 디폴트로 @Transaction이 선언되어있음 custom 메소드에 한해서는 모두 @Transactional 선언을 해줄 필요가 있다. 이 때, 사용부인 service에서 일일히 하는 방법, repository에서 미리 선언해주는 방법. 기본적으로 SingleJpaRepository (JPA interface 구현체부분)에 가보면 전체가 Transaction으로 감싸져있음.@Transactional(readOnly = true)public interface UserRepository extends JpaRepository&amp;lt;User, Long&amp;gt; { List&amp;lt;User&amp;gt; findByLastname(String lastname); @Modifying @Transactional @Query(&quot;delete from User u where u.active = false&quot;) void deleteInactiveUsers();} 전체에 readOnly를 감싸주고, writable하게 할 부분에(C,U,D) @Transactional 을 붙여 오버라이딩하면 writable해진다.Reference)https://docs.spring.io/spring-data/jpa/docs/current/reference/html/#transactional-query-methodshttps://stackoverflow.com/questions/39827054/spring-jpa-repository-transactionalityhttps://freedeveloper.tistory.com/159https://goddaehee.tistory.com/167https://pjh3749.tistory.com/269" }, { "title": "Lazy Evaluation", "url": "/posts/Lazy_Evaluation/", "categories": "Study, Java", "tags": "java, 지연실행, Lazy Evaluation", "date": "2021-06-16 00:00:00 +0900", "snippet": ": 변수가 function에 접근하는 순간이 아니라 실제로 그 값이 필요할 때까지 연산을 미뤄 불필요한 연산을 피하는 방법 함수형 프로그래밍 언어의 스트림에서 주로 사용한다. 중간 연산에는 결과값이 아직 없고, 최종 연산을 접하는 순간 연산이 수행된다. 중간 연산: filter, map, flatMap, … 최종 연산: allMatch, findFirst(first), collect, count … 등 특히 계산 관련 당장에 해결할 문제를 차례대로 수행하지 않고, 마지막 문제를 제공받을 때 까지 Lazy하게 기다리기코드 예시// 코드 이해를 위해 Kotlin으로 예시 작성val list: List&amp;lt;Int&amp;gt; = listOf(1, 2, 3, 4, 5, 6, 7, 8, 9);val count = list.filter { it &amp;lt;= 5 } .filter { it % 2 == 0 } .map { it * 10 } .count()// -- 만약 스트림을 사용 안했다면 아래와 같은 로직이 될 것 같다.for(it in list) { if(it &amp;lt; 5) { if(it % 2 == 0) { it * 10 } } } 위의 경우 결국 연산이 실제로 수행되는 순서는 다음과 같을 것 같다.1 - it &amp;lt;= 5 it % 2 == 02 - it &amp;lt;= 5 it % 2 == 0 it * 103 - it &amp;lt;= 5 it % 2 == 04 - it &amp;lt;= 5 it % 2 == 0 it * 105 - it &amp;lt;= 5 it % 2 == 06 - it &amp;lt;= 57 - it &amp;lt;= 58 - it &amp;lt;= 59 - it &amp;lt;= 5 count 또다른 예시: 만족하는 값을 얻으면 그냥 연산 끝.// 코드 이해를 위해 Kotlin으로 예시 작성val list: List&amp;lt;Int&amp;gt; = listOf(1, 2, 3, 4, 5, 6, 7, 8, 9);val count = list.filter { it &amp;lt;= 5 } .filter { it % 2 == 0 } .map { it * 10 } .first()// --1 - it &amp;lt;= 5 it % 2 == 02 - it &amp;lt;= 5 it % 2 == 0 it * 10 2 바로 위 예시는 아래와같이 first() 에 만족하는 답을 알아내는 순간 쓸데없는 연산을 피해버린다.그림으로 보는 예시 Eager Evaluation Lazy EvaluationReference)https://github.com/WeareSoft/tech-interview/blob/master/contents/java.mdhttps://sabarada.tistory.com/154" }, { "title": "Docker CLI", "url": "/posts/Docker_CLI/", "categories": "Study, Docker", "tags": "docker, 도커, 도커 CLI", "date": "2021-06-15 00:00:00 +0900", "snippet": "기본 CLI docker container inspect {container ID} 헬스체크 로그?같은걸 볼수있음 docker logs {container ID} sudo dockerd --debug 데몬 실행 안될때 디버깅 docker-compose 실행시 -d &amp;lt;– background로 실행 없이 실행하면 실시간 로그를 확인 할 수 있다. --build : 도커 컨테이너 이미지 생성 이미지는 불변이기 때문에 설정 변경 있을 때 이걸 해줘야 한다. 컨테이너 실행 docker exec -it ${containerId} /bin/sh docker exec -itu 0 ${containerId} /bin/sh : root 권한으로 bash shell을 실행. sudo 지원 안되는 경우 사용리소스 삭제 docker rm $(docker ps -a -q) sub CLI의 결과를 메인으로 전달 sudo docker system prune --volumes 로컬에 있는 데이터 볼륨 완전 제거 docker-compose down -v : -v 옵션으로 볼륨까지 내리기Docker registry에 이미지 업데이트하기 이미지 빌드 컨테이너 띄울 때 이미 빌드 했다면 할 필요 없음 docker build . -t {registry 경로}/{무슨 이름으로 올릴지}:{버전 명시} 레지스트리에 올리기docker push {registry 경로}/{무슨 이름으로 올릴지}:{버전 명시}컨테이너 상 npm 패키지 이슈 로컬에서 npm install 를 해줬었는데, 알고보니 직접 컨테이너 안에서 수행했어야 했다. dev환경 compose 설정 확인해보니, node_modules를 따로 관리해주고 있었음. node_modules:/root/server/node_modules/ 처럼 맵핑되어있었음볼륨 관련 docker volume ls : 현재 로컬에 있는 도커 볼륨 확인 docker volume inspect ${volume name} : 아래와같이 mount point 등등 확인 가능 도커 시스템, 이미지, 컨테이너, 볼륨 삭제 sudo docker system prune -af: all, force 옵션, 시스템 전부삭제 docker system prune --volume, --images 등 옵션 붙여줄 수 있음 docker volume prune docker images prune스웜 매니저노드 만들기 : docker swarm init --advertise-addr {만들 호스트 IP} 워커 노드 만들기 : docker swarm join --token {매니저노드가 만들때 발생한 Token} {매니저노드 IP} 스웜 환경 확인 : docker node ls 서비스 확인 : docker service ls 서비스 생성 : docker service create --name redis --replicas 2 -p 6379:6379 redis (2 레플리카) 스택 확인 : docker stack ls 스택 특정 노드 확인 : docker stack ps {스택}" }, { "title": "Transaction 적용이 안되는 몇가지 문제", "url": "/posts/JPA_transaction_%EC%A0%81%EC%9A%A9_%EC%95%88%EB%90%98%EB%8A%94_%EB%AA%87%EA%B0%80%EC%A7%80_%EB%AC%B8%EC%A0%9C/", "categories": "Study, JPA", "tags": "jpa, spring boot jpa", "date": "2021-06-14 00:00:00 +0900", "snippet": " Private - 오버라이딩 문제 Transaction 처리 과정에서 프록시 객체로 등록하기 때문에 private 불가 마찬가지로 final이 적용된 메서드도 불가능 Kotlin에서 allOpen을 통해, 혹은 Open을 통해 가능 inner Method 같은 클래스 내의 Transaction 적용되지 않은 메소드에서 @Transactional적용된 메소드은 Transactional로 생성된 proxy 객체를 통해 호출하는 것이 아니라, 내부 호출로 되기 때문에 transaction 적용 불가 해결 방법: @Transactional 을 Callee에서 Caller로 옮겨가면 된다. ReadOnly Method에서 Read-write method 호출 read-write 내부에서도 transaction은 readOnly로 동작하게 됨. 반대의 경우도.. 라는데 확인할 필요가 있음 Reference)https://www.whiteship.me/spring-transactional-and-spring-aop/https://www.whiteship.me/jpa-entitymanager-contains/https://handr95.tistory.com/3https://kapentaz.github.io/spring/Spring-Transaction-%EC%A0%81%EC%9A%A9-%EB%B2%94%EC%9C%84-%EC%A0%9C%EC%96%B4-%EB%B0%A9%EB%B2%95/#https://netframework.tistory.com/entry/Spring-Transactional%EC%97%90-%EB%8C%80%ED%95%98%EC%97%AC" }, { "title": "Proxy란", "url": "/posts/Proxy%EB%9E%80/", "categories": "Study, HTTP", "tags": "proxy", "date": "2021-06-14 00:00:00 +0900", "snippet": "프록시란? (대개) 보안상의 이유로 직접 통신을 지양하는 두 종단간 중계 기능을 하는 것 서버 입장에선 프록시가 클라이언트 역할, 클라이언트 입장에선 프록시가 서버 역할 하는 것으로 보임 캐싱 역할 요청을 기억하고 있다가, 동일한 요청이 올 때 같은 응답을 주도록 이 캐싱에서 요청에 대한 응답 처리가 된다면 실제 원격 서버까지 전달되지 않아도 됨. 다양한 기능을 수행 캐싱 - 공개 또는 비공개가 될 수 있음. (e.g. 브라우저 캐시) 필터링 - 바이러스 백신 스캔, 유해 사이트 차단 로드밸런싱 - 여러 서버들이 서로 다른 요청 처리하도록 인증 - 다양한 리소스에 대한 접근 제어 로깅 - 이력 정보 저장 애플리케이션 계층에서 동작Proxy serverForward Proxy: 목적지에 직접 접근하지 않고 프록시를 통해 데이터를 주고 받기 위해 사용하는 프록시 서버 입장에서 클라이언트가 누군지 모르게 됨 프록시의 IP를 통해 전달받음 사용자가 프록시에 리소스를 요청하면, 요청된 리소스를 원격 서버에서 가져와 사용자에게 돌려줌. 만약 캐시에 있다면, 캐싱된 데이터로부터 제공 사용자는 웹 브라우저를 이용해 프록시 서버 사용 설정. (사용자가 프록시 서버에 연결되었다는 것을 알 수 있음) 접근 정책 구현 측면에서 다루기 쉽고 비용 저렴forward proxy 사례: 아이폰에서 proxy 설정을 하게 되면 네이버로 http요청을 하든 넷플릭스로 http 요청을 하든 해당 Proxy로 응답을 받는다. 예를 들어, 해외 거주자의 경우 네이버 tv 캐스트가 지원이 되지 않는데(판권 문제로), 이 때 아이폰에서 proxy 설정을 해서 우리나라의 proxy로 받도록 하고, 아이폰은 이 proxy에 접속해 영상을 재생할 수 있다.Reverse Proxy(보안 측면): 사용자가 요청을 하는 End-point가 실 서버가 아니라 이 리버스 프록시 서버가 됨 프록시 서버를 인터넷 resource 앞에 위치 시켜, 클라이언트가 요청을 할 때 리버스 프록시를 호출하도록 함 클라이언트 입장에서 서버가 누군지 모르게 됨 - 사용자가 실제 리소스에 직접 접근하는 것 처럼 느껴짐 실제 서버의 IP 등 정보를 알 수가 없음 사용자가 reverse proxy로 설정된 서버에 데이터를 요청하면 프록시 서버가 요청을 받아, 실제 내부서버로부터 데이터를 받아옴. 리버스 프록시 서버를 두고 실제 서비스 서버는 내부망에 위치. 프록시 서버만 내부의 서비스 서버와 통신해 결과를 클라이언트에게 제공 e.g.) 아파치 웹 서버를 이용 시 웹 서버는 톰캣의 8080, 8009 포트만 접근하고, 아파치 웹 서버가 해킹당해도 내부망으로는 연결이 불가 각 요청에 대한 데이터가 캐싱되어, 부하 조절 기능reverse proxy 사례: 대부분의 서비스들의 아키텍처를 생각해보면, 웹 어플리케이션 서버는 웹 서버의 뒷단에 존재할텐데, 웹 어플리케이션 서버가 어디에 위치하는지는 사용자가 알 필요 없다. 그냥 사용자는 웹 서버에 요청하면 웹 서버가 WAS에 요청하고, 받아온 resource를 웹서버가 사용자에게 돌려줄테니Reference)HTTP 완벽 가이드http://blog.naver.com/PostView.nhn?blogId=alice_k106&amp;amp;logNo=221190043948&amp;amp;redirect=Dlog&amp;amp;widgetTypeCall=true&amp;amp;directAccess=falsehttps://milkye.tistory.com/202https://brownbears.tistory.com/191" }, { "title": "In Clause", "url": "/posts/In_clause/", "categories": "Study, JPA", "tags": "jpa, spring boot jpa", "date": "2021-06-13 00:00:00 +0900", "snippet": " findBy~~In 의 인자로 List를 받으면 자동으로 in clause로 변경 된다. where ~~ in (1, 2, 3) &amp;amp;&amp;amp; where in id=1 or id=2 or =id=3 Query와 같은 형태 그런데 여기서 ids는 고정된 크기의 객체가 아니다. e.g) 5개를 batch size로 받게 되면 아래와 같은 쿼리가 완성될 것이고, 결국 5개짜리 prepared, 2개짜리 prepared statement가 생긴다. 사용하면 사용할 수록 더 많은 prepared statement가 생길 것이다. select .... from Sample where id in (? ,? ,?, ?, ?);select .... from Sample where id in (? ,? ,? ,? ,?);select .... from Sample where id in (? ,? ); 문제점 임의의 n개의 리스트에 대한 in query가 생성되고, 이 때마다 preparedStatement 효과를 누리지 못하게 된다. 쿼리가 동적으로 계속 생성되므로 모든 것에 대해 힙 메모리가 점유된다. 따라서, 이 문제가 더 클 것으로 보인다. 1000개를 batch로 쿼리를 치면, 1000개의 다른 execution plan cache를 발생하게 될 것해결 in_clause_parameter_padding 옵션 지정 해주기 -&amp;gt; 2의 제곱 단위로 padding execution plan cache 사이즈 조정 이 경우에 2048부터해서 줄여가며 메모리 상황을 보아야 함SQL in절로 서브쿼리 시 성능 이슈 In절에 서브쿼리를 넣으면, 당연하게 서브쿼리를 먼저 수행하고 그 결과로 메인 쿼리를 수행한다. 이 때 row의 데이터들을 모두 확인하게 된다. 성능 향상을 위해 EXISTS나 JOIN으로 대체가능한 것은 대체하는 것이 좋음 In clause 동작방식 일단 findByIdIn과 같은 JPA 메서드는 쿼리로 변경되는데 .... WHERE IN 의 형태로 변경되긴 할텐데, 이 WHERE IN은 어떻게 동작하는가? 만약 IN절이 또다른 쿼리(서브쿼리)라면 일단 서브쿼리 먼저 수행하는 것이 당연한 것 제일 먼저 테이블에 접근해 한 레코드를 가져오며, 그 레코드의 해당 값이 IN절에서 뽑아낸 여러 요소들에 포함되는지하나라도 일치한다면 레코드에 대한 쿼리를 수행하는 것. Look up의 순서의 차이: 서비스 로직으로 for문을 돌면서 쿼리를 치는 것과 I/O의 관점 말고도 이런 차이가 있다. Reference)https://doorbw.tistory.com/222https://meetup.toast.com/posts/211https://wakestand.tistory.com/511https://eastglow.github.io/data-base/2018/09/07/Oracle-%EC%84%9C%EB%B8%8C%EC%BF%BC%EB%A6%AC%EC%99%80-IN-%EB%AC%B8%EC%9C%BC%EB%A1%9C-%EC%9D%B8%ED%95%9C-%EC%84%B1%EB%8A%A5-%EC%A0%80%ED%95%98.html" }, { "title": "DB 정규화 - 1, 2, 3 정규형(NF - Normal Form)", "url": "/posts/%EC%A0%95%EA%B7%9C%ED%99%94_1_2_3_BCNF/", "categories": "Study, Database", "tags": "database, db, 데이터베이스, 정규화", "date": "2021-06-10 00:00:00 +0900", "snippet": ": 함수적 종속성을 이용해 연관된 속성을 분리하고 이상 현상을 방지. 핵심은 테이블을 적절하게 나누는 것이다. 1NF, 2NF, 3NF, BCNF, 4NF, 5NF, 6NF까지 있다고 함 비공식적으로는 3NF까지 되었으면 정규화 되었다고 한다고 함제 1 정규형: 중복되는 항목이 없다. 보통 아래와 같은 규칙을 적용하면 중복되는 항목이 제거 될 수 있음 릴레이션에 속한 모든 속성(attribute)이 원자(atomic) 값으로만 구성되어있도록 모든 속성에 반복되는 그룹이 나타나지 않음.(tel1, tel2 이렇게 나타나지 않음) 기본 키를 사용하여 관련 데이터의 각 집합을 고유하게 식별할 수 있어야 함. Customer ID First Name Surname Telephone Number 123 Robert Ingram 555-861-2025 456 Jane Wright 555-403-1659555-776-4100555-123-4567 789 Maria Fernandez 555-808-9633 위의 경우 Tel 항목에는 여러 값을 두게 되는데, 1NF(RDBMS에서도 마찬가지로)에서는 행 도메인에서 한개의 값만을 허용함. 따라서, 1번을 위반해 아래와 같이 변경 Customer ID First Name Surname Tel. No. 1 Tel. No. 2 Tel. No. 3 123 Robert Ingram 555-861-2025     456 Jane Wright 555-403-1659 555-776-4100 555-123-4567 789 Maria Fernandez 555-808-9633     값이 없는 곳에는 Null값을 가질 수 있지만 Tel 정보가 세개나 들어가게 되고, 2번 규칙을 위반함으로써 이와같은 문제가 발생할 수 있다. 1. “전화번호 네개 있는 경우 저장을 못함”, 2. “동일한 값이 들어가는 경우가 발생” Customer ID First Name Surname Telephone Number 123 Robert Ingram 555-861-2025 456 Jane Wright 555-403-1659, 555-776-4100, 555-123-4567 789 Maria Fernandez 555-808-9633 그런다고 위와같이 여러 전화번호를 하나의 값으로 저장할 수 있도록 하면 의미상으로 모호해져서, “전화번호”를 표현할 수도, “전화번호 리스트”를 표현할 수도 있다. 1NF를 충족하는 디자인: 두개의 테이블로 나눠서 관리하는 것 Customer ID First Name Surname 123 Robert Ingram 456 Jane Wright 789 Maria Fernandez Customer ID Telephone Number 123 555-861-2025 456 555-403-1659 456 555-776-4100 456 555-123-4567 789 555-808-9633 그러나, 이게 해결된다고 이상 현상이 항상 없지는 않다.제 2 정규형: 제 1 정규형을 만족하고, 기본키가 아닌 모든 속성이 기본키에 완전 함수 종속성을 가진다. STUDENT_ID COURSE_ID PROFESSOR_NAME GRADE STUDENT_NAME 1 OS123 김ㅇㅇ B 김ㅇㅇ 1 ALG123 권ㅇㅇ F 김ㅇㅇ 2 ALG123 권ㅇㅇ A 이ㅇㅇ 3 NET123 최ㅇㅇ B+ 최ㅇㅇ 4 OS123 김ㅇㅇ A+ 손ㅇㅇ 위의 경우 학번 -&amp;gt; 이름 과 수업 -&amp;gt; 교수의 경우 부분함수 종속이 된다. 아래와 같은 방법으로 나누면 됨 이러한 규칙대로라면, { 학번, 수업, 성적 }, { 수업, 교수 }, { 학번, 학생 이름 } 테이블로 나뉠 것. 그러나, 마찬가지로 이게 해결된다고 이상 현상이 항상 없지는 않다.제 3 정규형: 제 2 정규형에 속하면서, 기본 키가 아닌 속성은 기본 키에만 의존해야 한다. STUDENT_ID COURSE_ID SCORE GRADE 1 OS123 80 B 1 ALG123 30 F 2 ALG123 90 A 이 테이블의 경우 기본키는 { 학생, 수업 }인데, grade는 score에 따라 달라진다. X -&amp;gt; Y 이고 Y -&amp;gt; Z 이면 X -&amp;gt; Z가 성립할 때가 이 경우에 속한다. 이걸 둘로 분리해주면 됨. { 학번, 수업, 점수 }, { 점수, 학점 } 마찬가지로 여전히 이상 현생은 발생할 수 있다.BCNF(Boyce Codd Normal Form): 모든 결정자는 Key여야 한다. 즉, “결정자이면서 후보키가 아닌 것”을 제거해야한다. 아래의 경우 (한 교수는 한 과목만 맡는다고 할 때) { 학번, 과목 } 이 기본키(후보키) 이지만, 교수가 과목을 결정하는 결정자가 된다. 학번 과목 교수 100 데이터베이스 홍길동 100 자료구조 임꺽정 200 네트워크 장영실 300 인공지능 유관순 갱신 이상: 교수가 과목 이름을 바꾸면 해당 교수의 과목을 다 바꿔야 한다. 삽입 이상: 200 학생이 데이터베이스를 수강하고자 할 때 현재 불필요한 홍길동 교수가 한번 더 삽입된다. 삭제 이상: 300학생이 자퇴해서 사라진다고 할 때 인공지능, 유관순 정보도 함께 사라진다.-&amp;gt; { 학번, 학수번호 }, { 학수번호, 과목, 교수 } 테이블로 변경해 해결Reference)https://ko.wikipedia.org/wiki/%EC%A0%9C1%EC%A0%95%EA%B7%9C%ED%98%95https://yaboong.github.io/database/2018/03/09/database-anomaly-and-functional-dependency/https://wkdtjsgur100.github.io/database-normalization/https://nirsa.tistory.com/107" }, { "title": "DB Key", "url": "/posts/DB_Key/", "categories": "Study, Database", "tags": "database, db, 데이터베이스", "date": "2021-06-06 00:00:00 +0900", "snippet": "후보 키 튜플을 유일하게 식별할 수 있는(유일성과 최소성을 만족하는) 속성들의 부분집합 기본키가 될 수 있는 것들기본 키 (PK) 후보키 중 뽑은 것 Null이면 안됨. (개체 무결성의 첫번째 조건) 기본키로 정의된 속에는 동일한 값이 중복되어 저장될 수 없음(개체 무결성의 두번째 조건)무결성? 개체 무결성: 릴레이션에서 기본키를 구성하는 속성은 1. 널(Null)값이나 2. 중복값을 가질 수 없다. 참조 무결성: 외래 키 값은 Null이거나(해당 튜플이 관계 릴레이션과 관계가 없을 때??) 참조하는 릴레이션의 PK와 같아야 한다.대체 키 (== 보조키) 후보키 중 기본키가 아닌 것 언제든 기본키 대신 대체가 가능(최소성, 유일성 만족) 마찬가지로 개체 무결성 만족부분 키 상위 entity의 키와 결합하여(단독으로 존재할 수 없다), 약한 개체타입을 고유하게 식별 가능한 키약한 개체타입: 한 엔티티가 다른 엔티티에 의존할 때 약한 개체타입.​ e.g) Article Favorite이 Article의 id와 결합되어 사용된다고 가정할 때, Article의 favorite(좋아요 수)은 Article에 약한 개체타입이라고 할 수 있다. 이 때 Article Favorite의 id는 부분 키슈퍼 키 유일성만 만족. 즉, 구별에 꼭 필요하지 않은 속성도 갖고 있음외래 키 (FK) 다른 릴레이션의 기본키를 그대로 참조하는 속성의 집합 참조 무결성을 만족해야한다: null이거나 참조 테이블의 PKReference)https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Database/%5BDB%5D%20Key.mdhttps://github.com/WooVictory/Ready-For-Tech-Interview/blob/master/Database/Key(%ED%82%A4).mdhttps://halfmoon9.tistory.com/59" }, { "title": "의존성 주입(Dependency injection)과 세가지 방법", "url": "/posts/%EC%9D%98%EC%A1%B4%EC%84%B1_%EC%A3%BC%EC%9E%85%EA%B3%BC_%EC%84%B8%EA%B0%80%EC%A7%80_%EB%B0%A9%EB%B2%95/", "categories": "Study, Spring boot", "tags": "spring, spring boot, 스프링, 스프링부트", "date": "2021-06-03 00:00:00 +0900", "snippet": " 스프링은 빈 컨테이너를 통해 빈 객체를 관리해준다 (IoC). 이 때, 필요한 곳에 적절히 객체를 주입해 사용해야 한다. (DI) 사실 스프링을 사용하지 않더라도, 객체 지향적 관점에서 사용되는 개념의존성: 어떠한 객체 A가 다른 객체 혹은 인터페이스 B를 사용할 때 A는 B에 대한 의존성이 발생하며, “A는 B에 의존한다.” 라고 말한다.강한 결합 A클래스에서 B 객체를 생성하고 있다고 가정 할 때 A는 B에 강한 의존 관계를 갖는다. e.g.) Person 클래스 내부에 Chicken 객체를 생성하는 부분이 있다고 할 때, Chicken이 아니라 Pizza가 되려면 Person 클래스 내부를 변경해야한다. 유연성을 떨어트리고, 변경을 어렵게 만든다.약한(느슨한) 결합 객체를 주입받음. 외부에서 생성된 객체를 Interface를 통해 넘겨받아 결합도를 낮추고, 유연한 구조를 갖으며 변경을 용이하게 만듦 위의 예시에서 Person 클래스는 Food Interface를 갖도록 하면, Chicken이든 Pizza든 Food에 주입(?)하도록 만들면 됨(implement) 이렇게 하면 Chicken -&amp;gt; Pizza로 변경할때 그 구현체만 변경하면 됨.의존성 주입 방법 세가지의존성 주입받을 클래스 A, 주입될 객체 B라고 가정.1. Field Injection: @Autowired로 의존성 주입받는 방법 일단 간편하다. 그러나 많은 단점이 존재. DI 컨테이너와의 결합성과 테스트 용이성 일단 의존성을 받았으면, 독립적으로 Instance화 가능한 POJO여야 한다. Test 환경에서 Spring Been 컨테이너 없이 돌아가야 하는데, 이 방식으로 사용한다면 일단 테스트에 용이하지 않다. 단일 책임 원칙 위반 가능성 의존성을 주입하기 쉬워지고, 의존 객체가 많아지면 하나의 클래스가 많은 책임을 갖게 될 수 있음 의존관계가 보이지 않음 DI 컨테이너에게 의존성 관리 책임을 위임하는 것이기 때문에 클래스 의존관계가 명확히 보이지 않는다. 불변성 불가 (자바 기준) final 선언 불가. 따라서 객체가 불변성이 아님. Contructor Injection에서는 final로 명시해 불변 객체로 만들 수 있다. 2. Setter Injection: setter를 통해 선택적으로 주입된 객체를 사용할 때 런타임에 수정자를 통해 의존성 주입을 하게 됨. -&amp;gt; 런타임 에러 우려 setter를 통해 주입하려는 객체가 주입 되지 않았어도 베이스 객체는 얼마든지 생성, 사용될 수 있다는 것이 문제 e.g) 만약 주입된 객체 본체(구현체)가 없는 상황이라고 가정할 때 일단 컴파일타임에는 생성, 사용 가능. 그러나 해당 의존 객체를 사용하려한다면 주입이 되지 않았기 때문에 NPE 발생 우려 3. Constructor Injection - 가장 권장.: 객체를 생성하는 시점에 바로 의존성 주입. Spring에서 가장 권장하는 방식 순환 의존성을 알 수 있다. 컴파일 단계에서 확인 가능. BeanCurrentlyInCreationException 발생 필수적으로 사용해야하는 것 없이는 Instance를 만들지 못하도록 강제할 수 있음. 항상 의존관계가 주입되기 때문에 Setter에서의 NPE 문제를 피할 수 있다. 의존성 주입이 번거롭다 따라서 만약 생성자에서 너무 의존관계가 많아진다면 SRP 원칙을 고려하게 되고, 리팩토링이 필요한 시점이라는 것을 알 수 있게 된다. 테스트 용이 DI 컨테이너와 결합도가 낮아 갖고 있는 의존성을 Instance화 할 수 있음. 불변으로 만들 수 있다. Kotlin에서는 기본적으로 val로 선언, java -&amp;gt; final Reference)https://velog.io/@gillog/Spring-DIDependency-Injection-%EC%84%B8-%EA%B0%80%EC%A7%80-%EB%B0%A9%EB%B2%95https://velog.io/@damiano1027/Java-%EA%B0%95%ED%95%9C-%EA%B2%B0%ED%95%A9%EA%B3%BC-%EC%95%BD%ED%95%9C-%EA%B2%B0%ED%95%A9https://ohjongsung.io/2017/06/02/%ED%95%84%EB%93%9C-%EC%A3%BC%EC%9E%85-field-injection-%EC%9D%84-%ED%94%BC%ED%95%98%EC%9E%90" }, { "title": "함수의 메서드 (call, apply, bind)", "url": "/posts/%ED%95%A8%EC%88%98%EC%9D%98_%EB%A9%94%EC%84%9C%EB%93%9C_call_apply_bind/", "categories": "Study, JavaScript", "tags": "javascript, js", "date": "2021-06-03 00:00:00 +0900", "snippet": ": 함수에 존재하는 기본 메소드. 첫번째 인자로 this를 대체할 수 있어, 실행 컨텍스트(window)를 다른 것으로 바꿀 때 사용가능. 이미 할당되어있는 “다른 객체의 함수나 메소드”를 “호출하는 해당 객체에 재할당” 따라서 window를 현재의 객체를 참조하도록. MDN예시 반복해서 보기call 보통 함수와같이 인자 목록을 넣어서 전달 e.g) func.call(this, a, b) 쓰이는 예시 객체의 생성자 연결에 사용(생성자 체이닝) ```javascriptfunction Product(name, price) { this.name = name; this.price = price; if (price &amp;lt; 10) { throw RangeError(‘Some range error’); }} function Food(name, price) { Product.call(this, name, price); this.category = ‘food’;} function Toy(name, price) { Product.call(this, name, price); this.category = ‘toy’;} var cheese = new Food(‘feta’, 5); // Errorvar fun = new Toy(‘robot’, 20); 익명함수 호출에 사용 let people = { name: &#39;AAA&#39;,}...(function(i) { this.print = function() { console.log(&#39;#&#39; + i + &#39;: &#39; + this.name); } this.print();}).call(people, i);... this 원하는 컨텍스트 지정 ```javascriptfunction greet() { var reply = [this.animal, ‘typically sleep between’, this.sleepDuration].join(‘ ‘); console.log(reply);} var obj = { animal: ‘cats’, sleepDuration: ‘12 and 16 hours’}; greet.call(obj); // cats typically sleep between 12 and 16 hours 인수 지정 없이(window 전달) ```javascript// ‘use strict’; strict 모드 사용 시 this는 undefined 값을 가지게 됨 var sData = ‘Wisen’;function display(){ console.log(‘sData value is %s ‘, this.sData);} display.call(); // sData value is Wisen apply call과 비슷하지만, call 은 인수 목록을, apply() 는 배열 하나를 전달한다는 점이 다르다. e.g) func.apply(this, [1, 2, 3]) 쓰이는 예시 배열관련 된 것들 처리할 때 좋음 JS엔진의 인수 길이 제한 오버플로우(65536)에 주의 1.var array = [&#39;a&#39;, &#39;b&#39;];var elements = [0, 1, 2];array.push.apply(array, elements); // [&#39;a&#39;, &#39;b&#39;, 0, 1, 2] 2.var numbers = [5, 6, 2, 3, 7]; var max = Math.max.apply(null, numbers); var min = Math.min.apply(null, numbers); +) 생성자 체이닝에도 마찬가지로 쓰임 bind this만 바꿔 반환하고, 호출하지는 않음. call(this, 1, 2, 3)은 bind(this)(1, 2, 3) 와 같음.쓰이는 예시 객체로부터 메소드 추출 뒤 함수 호출하면, 원본 객체는 그 함수의 this로 사용되는 것이 아님. this.x = 9;var module = { x: 81, getX: function() { return this.x; }}; module.getX(); // 81이 맞다. var retrieveX = module.getX;retrieveX();// 9 반환 - 함수가 전역 스코프에서 호출됐음 // module과 바인딩된 &#39;this&#39;가 있는 새로운 함수 생성// 신입 프로그래머는 전역 변수 x와 module의 속성 x를 혼동할 수 있음var boundGetX = retrieveX.bind(module);boundGetX(); // 81 setTimeout 과 사용 - this 는 window 객체로 설정됨 function LateBloomer() { this.petalCount = Math.ceil(Math.random() * 12) + 1;} // 1초 지체 후 bloom 선언LateBloomer.prototype.bloom = function() { window.setTimeout(this.declare.bind(this), 1000);}; LateBloomer.prototype.declare = function() { console.log(&#39;I am a beautiful flower with &#39; + this.petalCount + &#39; petals!&#39;);}; var flower = new LateBloomer();flower.bloom();// 1초 뒤, &#39;declare&#39; 메소드 유발 Reference)https://developer.mozilla.org/ko/docs/Web/JavaScript/Reference/Global_Objects/Function/callhttps://www.zerocho.com/category/JavaScript/post/57433645a48729787807c3fd" }, { "title": "디미터 법칙(law of demeter)", "url": "/posts/%EB%94%94%EB%AF%B8%ED%84%B0_%EB%B2%95%EC%B9%99/", "categories": "Study, OOP", "tags": "oop, 객체지향", "date": "2021-06-02 00:00:00 +0900", "snippet": " 객체가 자기 자신을 책임지는 자율적인 존재이다. 따라서 객체 내부 구조를 묻지 말고 무언가를 시켜라. 이렇게 하면 객체 내부를 바깥으로 노출시키지 않게 된다. 디미터 법칙을 어긴 코드object.getChild() .getContent() .getItem() .getTitle(); 기차 충돌(train wreck) : 이와 같이 getter 가 줄줄이 이어진 코드 이러한 설계는 객체들이 어떻게 연결되어있는지를 보여준다. 객체 구조(연결)이 변경될 수 있으므로 프로그램은 불안정해진다. 디미터 법칙이 하나의 .을 강제하는 규칙은 아니다.IntStream.of(1, 15, 2) .filter(x -&amp;gt; x &amp;gt; 10) .distinct() .count(); stream을 사용한 해당 코드는 하지만 of, filter, distinct 메서드는 모두 IntStream 이라는 동일한 클래스 인스턴스를 반환한다. 즉 이들은 IntStream 인스턴스를 또다른 IntStream인스턴스로 변환할 뿐.디미터 법칙은 객체 결합도와 관련 된 것. 객체의 내부구조가 외부로 노출되는 경우에 해당된다. object.getChild() .getContent() .getItem() .getTitle(); 디미터 법칙을 지킬수록 결합도는 느슨해진다. Reference)https://woowacourse.github.io/javable/post/2020-06-02-law-of-demeter/" }, { "title": "일급 컬렉션(first class collection)", "url": "/posts/%EC%9D%BC%EA%B8%89_%EC%BB%AC%EB%A0%89%EC%85%98/", "categories": "Study, Develop", "tags": "java, first class collection", "date": "2021-06-02 00:00:00 +0900", "snippet": "public class Cards { private List&amp;lt;Card&amp;gt; card; public Cards(List&amp;lt;Cards&amp;gt; cards) { this.cards = cards; } // ..}특징 컬렉션을 wrapping하면서 그 외 다른 멤버변수가 없는 상태. 비즈니스에 종속적인 자료구조. List&amp;lt;Card&amp;gt;로 관리하기보단 Cards 라는 컬렉션 객체로 관리하면 객체를 해당 비즈니스에 종속시킬 수 있다. 어떠한 객체에 대한 검증로직같은 것이 필요할 때 해당 객체를 쓸 때마다 검증로직을 구성해야하는데 일급 컬렉션을 통해 이를 방지 할 수 있음. 객체들에 대한 상태, 행위를 컬렉션에서 관리@Delegate 롬복의 해당 어노테이션을 사용하면 컬렉션 내의 Collection 필드를 제어하기 위한 함수들을 만들필요 없다. 그 Collection 필드의 메서드들이 전체 클래스로 위임된다.Reference)https://jojoldu.tistory.com/412" }, { "title": "TDD(Test Driven Develop)", "url": "/posts/TDD/", "categories": "Study, Develop", "tags": "backend, tdd", "date": "2021-06-02 00:00:00 +0900", "snippet": ": test 주도형 개발. 기능 개발 전 가능한 모든 경우에 대해 테스트를 먼저 작성해보는 것테스트 코드를 작성하는 방법들과는 다른, 소프트웨어 개발론적인 것장점 리팩토링에 용이. 크기가 커진 함수를 여러 함수로 나누는 과정에서 테스트 코드를 통해 계속 확인을 해가며 리팩토링을 해 중심을 잡을 수 있다. 새로운 기능을 추가했을 때 해당 기능에 대한 테스트는 물론, 기존의 테스트들도 다 잘 돌아가는지 확인해 새로운 기능에 대해 신뢰를 할 수있다. 객체지향적으로 작성할 수 있다: 시나리오를 먼저 생각하고 작성을 해본다. -&amp;gt; use case를 명확히 파악 가능하고 ‘객체’ 위주로 먼저 생각해볼 수 있게 된다. 객체지향을 연습할 때 TDD로 해보면 굉장히 도움이 된다고 한다. 단점 생산성이 줄어든다 시나리오를 먼저 생각하는 것 자체가 사람에게 익숙하지 않은 방식 프로덕션 코드를 작성하기 위해 테스트를 먼저 신경써서 작성한다는 것 자체가 일단 생산성 저하 모든 기능에 대해 100% 테스트코드를 작성할 수 없는 상황이 발생할 수 있다." }, { "title": "c++과 관련해 겪은 이슈들, 간단한 메모", "url": "/posts/Cpp_Issues/", "categories": "Study, C++", "tags": "c++, cpp", "date": "2021-06-02 00:00:00 +0900", "snippet": "200317 Vector는 memset 불가 cstring 라이브러리 C++ string string.erase(index부터, length만큼); string.replace(index부터, length만큼, &quot;&quot;얘로 변경); string.find(&quot;&quot;얘를 찾아라, index부터); 이외에도 여러 버전으로 오버로딩되어있으니 라이브러리를 공부하기 isupper(), isdigit(), toupper() 등 camel case가 적용이 안되어있으니 주의200405 c++ string replace Allwhile((pos = str.find(&quot; &quot;)) != string::npos) { str.replace(pos, size, str2); // str2로 대체} 백트랙킹 문제에서 굳이 visit 하나하나 바꾸지 말기. check할때 하나하나 접근하는게 이득 이분탐색에서 기본적으로 while 조건문은 left &amp;lt;= right" }, { "title": "OWT server 토큰 생성 과정 분석", "url": "/posts/OWT_server_%ED%86%A0%ED%81%B0_%EC%83%9D%EC%84%B1%EA%B3%BC%EC%A0%95/", "categories": "Study, WebRTC", "tags": "webrtc", "date": "2021-06-01 00:00:00 +0900", "snippet": ": 토큰 생성과정 이해되지 않을 때 아래의 과정 참조하기 Client API -&amp;gt; createToken(room, user, role, preference) 여기서 preference = {isp: &#39;isp&#39;, region: &#39;region&#39;}; 받은 token을 app.post(&#39;/token&#39;, () =&amp;gt; {}) (createToken 메서드 호출부) 전달 Server - v1/index 요청받아 tokenResource.create 전달 tokenResource req.user, role, body, origin(preference) 세팅 후 generateToken 토큰 생성 후 Portal 할당을 위해 requestHandler.schedulePortal requestHandler rpc Call -&amp;gt; cluster_name으로 schedule 메서드 호출. 1. portal, 2. tokenCode, 3. origin, 4. 60 * 1000 clusterManager schedule에서 schedulers[&quot;portal&quot;]에게 schedule(tokenCode, origin, 60 * 1000) scheduler - 실질적 토큰에 대한 worker 스케줄링 부분 reserveWorkerForTask 를 통해 tasks[task]에 worker, reserve time 등 할당. (해당 테스크에 워커 할당) that.add 를 통해 workers[worker] 에 state, load, info, tasks 할당. (해당 워커 추가 == 초기화) 메서드 호출부 : clusterManager.workerJoin topicMessage를 통해 portal에 대한 topic을 subscribe할 때 portal에 대한 worker 할당 tasks[task] (현재 토큰에 대해 수행할 worker를 이미 할당받은경우) newReserveTime = 새로 입력받은 reserveTime과 비교해 많이 남은 쪽으로 토큰에 대한 worker 초기화 되지 않았으면 tasks[task] 삭제후 2. tasks[task] 존재하지 않던 경우로 이동 토큰에 대한 worker 이미 초기화 되어 있으면 worker가 수행할 토큰들 중 해당 토큰 있다면 newReserveTime로 세팅하고 on_ok worker가 수행할 토큰들 중 해당 토큰 없다면 -&amp;gt; 현재의 토큰 수행할 worker 다시 할당(다시 초기화) 후 on_ok tasks[task] 애초에 존재하지 않던 경우(현재 토큰에 대한 task 수행할 worker가 애초에 없던 경우) 두 가지 과정을 통해 가능한 worker 리스트를 만들어줌 worker들 중 가용 worker를 모두 candidates에 push 가용 : worker capable하고, state == undifined or 2 인 것들 가능 worker 없으면 error(no worker available, all in full load) matcher.match (portalMatcher.match) 에서 worker origin(isps, regions)과 preference(사용자의 origin)가 적절한 것 선 isps는 무조건 적절한 것만. region은 최대한 적절한 것(적절하지 않아도 넣어줌). 가능 worker 없으면 error(no worker matches the preference). 1, 2 과정을 통해 리스트된 worker들 중 strategy 전략에 따라 하나의 worker 골라냄 토큰에 대한 task 수행할 worker 할당 후 on_ok dataAccess에 token 추가 후 tokenString 클라이언트에게 전달 " }, { "title": "Kafka 아키텍처", "url": "/posts/Kafka_%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98_Partition_Consumer_group_%EB%93%B1/", "categories": "Study, Kafka", "tags": "kafka, infra", "date": "2021-06-01 00:00:00 +0900", "snippet": "Topic과 Partition Topic 하나의 관심사. 이 것을 구독하여 사용 Partition topic를 쪼갠 작은 단위 HA를 위해 replication 설정을 할 경우 partition 단위로 각 서버들에 분산되어 복제 장애 발생 시 partition 단위로 fail over partition 내부의 데이터 순서대로 consumer가 받을 것을 보장 그러나 각각의 partition간 순서는 보장하지 않음. Partition 분산 Producer가 어떤 partition으로 메시지를 전송할지는 partition 분배 알고리즘에 의해 Round robin, 메시지 키를 통해 패턴 매핑, CRC32를 통해 modulo 연산 등 Partition replication? 위는 replication factor을 3으로 설정한 상태의 클러스터 위처럼 세개의 브로커에 leader가 균등하게 분배. 따라서 read,write를 모두 leader가 수행함에도 불구하고 부하가 균등 분배 됨 Replication factor의 수에 따른 상황(replication factor == n인 상황) n개의 replica는 1개의 leader(빨강), n-1개의 follower(파랑) 로 구성 읽기와 쓰기는 모두 leader에서 follower는 leader를 복제 leader 장애시 follower가 leader로 승격 Messaging model Queue model 메시지가 쌓여있는 큐로부터 메시지를 가져와 consumer pool에 있는 consumer 중 하나에 메시지를 할당하는 방식 서버 scaled 상황에서 이게 적절할 듯 Pub-Sub model topic을 구독하는 모든 consumer에게 메시지 브로드캐스팅 Consumer Group? 목적 HA를 위함(그룹 내 서버 하나 죽어도 나머지로 task 처리 가능) 컨슈머그룹간 각자만의 offset을 관리하기 위해 컨슈머 인스턴스들을 대표하는 그룹 consumer instance == 하나의 Process(server) 각 컨슈머 인스턴스들은 offset을 이용해 본인이 어디까지 데이터를 가져갔는지 관리 그룹 내 서버들끼리는 서로의 정보를 공유 이 개념을 통해 위의 두 모델을 pub-sub 모델로 일반화. Topic을 나눈 단위인 partition은 CG(consumer group) 당 하나의 consumer 접근만을 허용 이 때의 consumer는 partition owner. 한번 구성되면 broker, consumer 변동이 있지 않는 한 계속 유지 consumer 추가 시 CG 내 재분배 broker 추가 시 전체에서 재분배 동일한 CG의 consumer는 동일한 partition 접근 불가 CG에 다수의 consumer가 할당되면 각 consumer마다 별도의 partition으로부터 메시지를 받아오기 때문에 CG는 큐 모델로 동작Consumer Group과 파티션 수의 관계 파티션 수 &amp;lt; 컨슈머 인스턴스 이면 안됨(비효율적 사용) 1:1 맵핑이 가장 이상적 그러나 파티션을 무작정 늘리는 것은 좋지 않음 파티션은 토픽 생성 후 언제든 늘릴수 있지만 줄일수는 없음 Refenence)https://epicdevs.com/17https://www.popit.kr/kafka-consumer-group/" }, { "title": "JVM의 가비지 컬렉터", "url": "/posts/%EA%B0%80%EB%B9%84%EC%A7%80%EC%BB%AC%EB%A0%89%ED%84%B0/", "categories": "Study, Java", "tags": "java, gc, 가비지컬렉션", "date": "2021-06-01 00:00:00 +0900", "snippet": ": 유효하지 않은(더 이상 불필요한) heap의 객체 메모리를 JVM의 데몬이 정리해주는 것. JVM의 GC 예시. C++이나 C에서는 free()를 통해 직접 할당 해제해줘야 한다. 위의 그림에서 permanent 영역은 heap에서 제외GC 설계의 바탕: 대부분의 객체는 금방 unreachable 상태가 된다.e.g) 메서드 종료 시 그 메소드에서 생성된 객체는 더이상 사용하지 않는 경우e.g 2) User user = new User(); 과 같이 생성해 DB에 저장하거나 하는 등의 태스크를 수행하고 더이상 객체 자체는 사용이 안되는 경우GC 동작 방식Minor, Major GC? Young 영역의 각 하위 영역이 가득 차면 Minor GC 발생. Old 영역이 가득차면 Major GC(== Full GC) 발생.Stop the world: GC를 수행하는 데몬 스레드 외에 모든 스레드 작업 멈추는 상태이다. GC 완료 후 다시 스레드 들이 실행 상태된다. 따라서 당연하게 GC가 자주 수행 될수록 성능은 저하된다. 성능을 위해서라면 GC를 튜닝할 수도 있다.동작 기법: Mark and SweapGC는 객체를 돌면서 각각이 어떤 객체를 참조하고 있는지 reference를 탐색하면서 mark해 참조가 되는 객체와 아닌 것을 체크한다. 이후 Sweap 과정에서는 불필요한 객체를 제거한다.동작 과정 객체 생성 시 YG의 Eden으로 이동한다. Eden영역이 꽉차 Minor GC 발생하고, 살아남으면 Survivor 1로 이동한다. 이후 Survivor 1, 2 사이를 minor GC 발생에서 살아남을때마다 번갈아가며 이동한다. Minor GC에서 살아남은 횟수(age bit)가 지정해놓은 임계값을 넘게 되면, Old 영역으로 이동한다. Old 영역의 객체는 MajorGC때 참조 여부에 따라 살아남거나 제거된다.G1(Garbage first) GC java에서 사용되는 GC 멀티 쓰레드로 Stop the world가 동작Region 개념 도입 힙을 균등하게 region으로 나누고, 가비지가 많은 region에 우선적으로 GC Minor - Eden에 많다 싶으면 해당 지역 GC 하고, 살아남은 객체 다른 영역 이동. 복제되는 지역이 Available / Unused면 해당 영역은 Survivor이 되고, Eden이었던 곳은 Available/Unused 된다. Major - GC가 많은 지역을 조합해 해당 지역에 GC 수행 좋은 경우 Java heap 반 이상이 살아있는 객체일 때 GC가 너무 오래 걸려 튜닝이 필요할 때 Reference)https://velog.io/@hygoogi/%EC%9E%90%EB%B0%94-GC%EC%97%90-%EB%8C%80%ED%95%B4%EC%84%9Chttps://github.com/WeareSoft/tech-interview/blob/master/contents/java.mdhttps://deveric.tistory.com/64https://mangkyu.tistory.com/119" }, { "title": "OWT Websocket (socketIOServer) 코드 분석 및 시나리오별 정리", "url": "/posts/OWT_WebSocket_%EB%B6%84%EC%84%9D/", "categories": "Study, WebRTC", "tags": "webrtc", "date": "2021-05-31 00:00:00 +0900", "snippet": ": 로직 흐름 이해할 때 아래의 과정 참고하기 socket.on(&#39;login&#39;) (V11Client에 대한 로직) protocol 버전에 따라 client를 ws 초기화된 portal에 LegacyClient / V11Client / V10 Client로 초기화 이 Client에 대한 socket 만들고, 그 소켓들에 대한 eventListener들 등록 validation 후, login_info에서 token 뽑아서 client.join -&amp;gt; portal.join(id, token) 토큰, 시그니처 비교 validation 토큰 생성할 때 dataAccess에 저장해놓았던 해당 토큰 지우고 login 해당 유저 방에 대해 getController clusterManager를 통해 scheduler에게 전해지고, schedulers[&quot;conference&quot;].schedule scheduler는 해당 roomId에 대해(Token 발급시에는 TokenCode) worker 할당, worker, info 콜백 해당 worker(==controllerAgent) -&amp;gt; agent/nodeManager.getNode() roomId에 할당된 node 찾고, 준비되면 addTask addTask에서 해당 nodeId에 해당 room task가 없다면 할당(agent/index.addTask), nodeId return 위 과정에서 찾은 node(=controller) 로 join(controller, room_id, participant) rpc Call conference의 join room init -&amp;gt; 없으면 init, 있거나 만들어지고 있으면 냅두고 아니면 새로 만듦 방이 꽉찼거나 room role이 안맞는지 검사 후 참가(addParticipant) 여기서 participants[participantInfo.id] 에 추가, 다른 참가자들에게 message 전송 이후 permission, room 콜백 portal의 participants[participanteID]에 in_room: room_id와 controller: room_controller (현재 방 컨트롤러) 등록 return tokenCode, data(userInfo, role, permission, joinResult.room) 해당 결과 that에 roomId, tokenCode 저장, that return socketIO에서 reconnectionTicket 발급 dock.onClientJoined(client_id, client) observer.onJoin(client.tokenCode) 호출, clusterWorker에서 tasks에 해당 tokenCode 등록 reconnectionTicket과 함께 결과 전송 socket.on(&#39;relogin&#39;) reconnection ticket 검사 후 티켓의 참가자Id를 통해 client 찾아옴 client.connection.reconnect reconn_timer(disconnect시 set) 초기화 후 return pendingMsg, clientId, protocolVersion, reconnection reconnection 가능한지, Client로 부터 받은 ticket에 써있는 participantId가 같은지 validation pendingMsg, clientId, protocolVersion set, resetConnection(V11 or legacy) connection 새로 set, listenAt (새로운 connection의 socket에 대해 eventListener 등록) reconnectionTicket 생성, pending 상태의 메시지 다시 전송 socket.on(&#39;disconnect&#39;) - state에 따라 다르게 처리 (1)’connecting‘이거나 (2)’connected‘인데 reconnection은 불가능할 때 forceClientLeave() ‘connected` state에서 reconnection이 가능한 상태일 때 이 경우 : 1. 예기치 못하게 나가졌을 때, 2. mobile client로부터 connection이 초기화 되었을 때 해당 소켓 disconnect waiting_for_reconn 타이머 set. -&amp;gt; 추후 reconnection을 위해 forceClientLeave() forceClientLeave() 로직 client id를 통해 client를 받아오고, 현재의 connection 정보 === that 이라면 onClientLeft -&amp;gt; clusterWorker의 tasks에서 이 client의 tokenCode에 해당하는 task 제거 State, reconnection 변화 login 성공: initialized -&amp;gt; connecting -&amp;gt; connected / reconnection 가능 실패: initialized -&amp;gt; connecting -&amp;gt; initialized 로그인 도중 disconnect 사용자가 나갈 때 // 예기치 못한 실패 -&amp;gt; 일단 validation 통과했다면 reconnection 가능 validation 실패 -&amp;gt; reconnection 불가 relogin 성공: initialized -&amp;gt; connecting -&amp;gt; connected / reconnection 가능 실패: initialized -&amp;gt; connecting -&amp;gt; initialized 티켓 만료 / 유효하지 않은 티켓 시그니처 / ticket의 client 미존재 / reconnection 불가능 / 티켓의 client와 참가자 불일치 logout connected -&amp;gt; initialized / reconnection 불가능 " }, { "title": "IDL(Interface Definition Language)", "url": "/posts/IDL/", "categories": "Study, Network", "tags": "network", "date": "2021-05-30 00:00:00 +0900", "snippet": ": 다른 언어로 작성된 여러 서비스 들을 연결하기 위해 중간 인터페이스를 정의하는 언어 XML, JSON, Protocol Buffer 등이 있다. 구조화된 데이터를 IDL로 직렬화(Serialization) 해서 보내, 통신 환경에서 이종간 플랫폼 환경에도 원활한 통신이 잘 되도록 한다.XML 사람이 읽고 쓸수 있음 스키마 정보 없이 사용 가능 SOAP와 같은 표준이 있음 JSON에 비해 태그 등 때문에 같은 데이터라도 내용이(코드가) 더 많음 인코딩, 디코딩에 상대적으로 많은 리소스 소비JSON 사람이 읽기에 가독성이 좋음 -&amp;gt; 개발, 디버깅에 편리 스키마 정보 없이 사용 가능 간결함 좋음 웹 브라우저에 용이 XML에 비해 가벼움 표준이 없음PB(Protocol Buffer) Byte Stream으로 직렬화해 보냄 -&amp;gt; 이진 데이터라 사람이 읽을 수 없음 데이터 압축률 좋음 처리속도 빠름 스키마에 대한 정확한 지식 필요 구글에서 개발한 직렬화 프로토콜Reference)https://www.joinc.co.kr/w/man/12/ProtocolBufferhttp://gdthink.blogspot.com/2006/07/idlinterface-definition-language.htmlhttps://soulduo.tistory.com/91" }, { "title": "gRPC(Google RPC) framework.", "url": "/posts/gRPC/", "categories": "Study, Network", "tags": "network, grpc, rpc, rabbitmq", "date": "2021-05-29 00:00:00 +0900", "snippet": "RabbitMQ와 비교했을 때 GRPC의 특징 HTTP/2 프로토콜을 사용해 메시지 헤더 압축, server push 등으로 성능이 좋다. IDL은 protocol buffer(PB)를 사용해 data를 Byte형태의 스트림으로 변경해 보낸다. JSON 등 다른 직렬화 방식도 사용 가능 대기 시간이 짧고 처리율이 높은 통신에 필요(e.g. 효율성이 중요한 마이크로 서비스) 클라이언트 응용 프로그램을 서버에서 바로 호출 가능 -&amp;gt; 분산 MSA 쉽게 구현 가능 Best example: 대표적으로 많이 쓰이는 IoT 기기들 voice controller, 2. smart light switch, 3. smoke alarms lock, 4. camera RPC 특성상, 아키텍처가 아니라 server와 client의 관계에서 교류가 이루어짐 LB 지원받을 수 있다.직렬화 PB compiler가 .proto 파일을 컴파일하면 메시지는 직렬화되어 output stream 으로 나가고, parsing되어 input stream으로 들어옴왜 gRPC를 사용하는가? Protocol buffers를 이용해 직렬화 된 바이트 스트림으로 통신해 JSON 기반의 통신보다 가볍다. internal 통신이 빈번한 MSA에서 gRPC를 적용 시 latency 감소, 더 많은 트래픽 처리 많은 서비스간 API 호출로 인한 성능 저하를 개선 MSA 기반, 분산처리를 위해 필요한 보안, API gateway, 로그 추적, 모니터링, 상태체크 등의 기능 추가개발 용이Reference )https://blog.banksalad.com/tech/production-ready-grpc-in-golang/?gclid=Cj0KCQjw9_mDBhCGARIsAN3PaFMi15aVSQKdivgRBWUOygiy8oVfmp5IlsU0PA0eUQAwGLCGbwjskF8aAq4HEALw_wcB9437610https://medium.com/devops-dudes/graphql-vs-rest-vs-grpc-411a0a60d18dhttps://m.blog.naver.com/PostView.nhn?blogId=neos_rtos&amp;amp;logNo=30185472655&amp;amp;proxyReferer=https:%2F%2Fwww.google.com%2Fhttps://velog.io/@kyusung/grpc-web-examplehttps://chacha95.github.io/2020-06-15-gRPC1/https://chacha95.github.io/2020-06-16-gRPC2/https://brownbears.tistory.com/512" }, { "title": "JPA 벌크연산(update, delete)", "url": "/posts/%EB%B2%8C%ED%81%AC%EC%97%B0%EC%82%B0_Update_Delete/", "categories": "Study, JPA", "tags": "jpa, spring boot jpa", "date": "2021-05-29 00:00:00 +0900", "snippet": "벌크연산 벌크연산이란? 여러 건의 데이터를 한번에 변경한다. update, create, delete ORM마다 지원하는 벌크연산이나 실제로 수행되는 방식이 다르다고한다. 각 orm을 사용할 때 예상하는 동작방식이 실제로 맞는지를 확인해야한다. e.g) JPA에서는 기본적으로 Bulk DELETE를 지원하지 않는다고 한다. 이 경우 @Query어노테이션을 통해 벌크연산을 수행해야 함. 벌크연산에 대해서는 영속성 컨텍스트를 건너뛰고, DB에 직접 쿼리 발생할 수 있는 문제 한 테스트 내에서 1. entity 생성, 2. 변경, 3. assert로 변경확인과 같은 로직. 이 때 1은 영속성 컨텍스트에 해당 entity 저장, 3에서 find할 때는 DB가 아닌 영속성 컨택스트에서 꺼내와 확인 해결 방법 em.refresh() 사용 : 벌크 연산 직후 entity find 시, 해당 메서드를 통해 영속성 컨택스트 말고 DB에서 find하도록. 그런데 이 때도, 영속성 컨텍스트에 해당 엔티티가 존재한다면, DB에서 find한 결과를 버리고 영속성 컨텍스트에 있는 기존 엔티티를 반환. 이유: 영속성 컨텍스트가 영속상태의 DB 엔티티와의 동일성을 보장해야 하기 때문 DB의 엔티티를 새로운 엔티티로 추가하려고하면 기존 엔티티와 Id 중복이 발생하기 때문 영속성 컨텍스트의 엔티티를 modify한 것으로 대체하려고 하면, 영속성 컨텍스트의 수정중인 엔티티가 유실될 위험이 있기 때문 벌크 연산 수행 후 영속성 컨택스트 초기화 Modifying(clearAutomatically = true) flushAutomatically : 영속성 컨텍스트에 쌓여있던 변경사항을 DB에 반영해주는 것 영속성 컨텍스트의 범위 영속성 컨텍스트의 생명주기는 트랜잭션과 같음. 따라서, 같은 트랜잭션은 같은 영속성 컨텍스트를, 다른 트랜잭션은 다른 영속성 컨텍스트를 사용 따라서, 벌크 연산 수행 시 영속성 컨텍스트를 clear, flush할 지는 해당 트랜잭션 내부에서 조회연산을 또 수행할지를 보고 상황에 맞게 사용하면 될 듯.Reference)https://velog.io/@roro/JPA-JPQL-update-%EC%BF%BC%EB%A6%AC%EB%B2%8C%ED%81%AC%EC%99%80-%EC%98%81%EC%86%8D%EC%84%B1-%EC%BB%A8%ED%85%8D%EC%8A%A4%ED%8A%B8https://jojoldu.tistory.com/536https://data-make.tistory.com/617https://freedeveloper.tistory.com/154https://joont92.github.io/jpa/JPQL/https://ultrakain.gitbooks.io/jpa/content/chapter3/chapter3.7.html" }, { "title": "힙 정렬(Heap sort)", "url": "/posts/%ED%9E%99_%EC%A0%95%EB%A0%AC/", "categories": "Study, Algorithm", "tags": "algorithm, sort", "date": "2021-05-24 00:00:00 +0900", "snippet": ": 자료구조 힙(최대 힙, 최소 힙)을 이용한 정렬 방법 최대 힙, 최소 힙으로 내림차순, 오름차순 정렬을 할 수 있다. O(n log n) 의 시간복잡도를 가져, 가장 빠른 정렬 방법 중 하나이다. 비교할 때 자식, 부모 노드로 이동 log N * 모든 노드 N개에 대해 수행 N 힙은 완전 이진 트리 구조를 가진다. 힙의 특성상 가장 앞의 값이 항상 많이 쓰인다. 따라서, 가장 유용할 때는 가장 큰 몇개만 필요할 때 힙의 삽입과정 힙에 새로운 요소가 들어오면, 힙의 leaf노드에 삽입한다. 새 노드가 우선순위 규칙에 맞는지 확인한다. 부모 노드와 자리를 교체한다. 2번의 과정을 통해 우선순위가 맞게 되면 끝. 더이상 교환하지 않는다.코드// 배열로 구현.void insertMaxHeap(int heap[], int target) { int i = sizeof(heap) - 1; heap[i] = target; while(heap[i] &amp;gt; heap[i / 2]) { int tmp = heap[i]; heap[i] = heap[i / 2]; heap[i / 2] = tmp; }}힙의 삭제과정 항상 Root노드가 삭제.(최대 힙은 최대 값, 최소 힙은 최소 값) 삭제된 Root노드에 Leaf 노드를 가져온다. Root가 된 Leaf값을 자식과 비교해, 자식 중 우선순위에 더 가까운 것과 swap 물론, 모든 노드의 순서가 우선순위를 만족하지 않게 될 수도 있음. 그런데, 문제가 되지 않는 이유는 항상 맨 앞의 값 으로만 접근하기 때문 모든 노드에 알고리즘을 사용하지는 않아도 되기 때문에 O(N)의 성능을 내기도 한다고 함. 코드// root가 1이라고 가정void deleteMaxHeap(int heap[]) { heap[1] = heap[sizeof(heap) - 1]; heap[sizeof(heap) - 1] = 0; int lChild = 2, rChild = 3; int me = 1; int size = sizeof(heap); while(lChild &amp;lt; size &amp;amp;&amp;amp; rChild &amp;lt; size) { if(heap[lChild] &amp;gt; heap[me]) { // 왼쪽 자식 swap(heap, lChild, me); me = lChild; } else if(heap[rChild] &amp;gt; heap[me]) { // 오른쪽 자식 swap(heap, rChild, me); me = rChild; } else break; lChild = me * 2; rChild = me * 2 + 1; }}Reference)https://gmlwjd9405.github.io/2018/05/10/algorithm-heap-sort.html" }, { "title": "POJO(Plain Old Java Object)", "url": "/posts/POJO/", "categories": "Study, Spring boot", "tags": "spring, spring boot, 스프링, 스프링부트", "date": "2021-05-23 00:00:00 +0900", "snippet": ": 오래된 방식의 자바 객체. 자바 언어가 갖는 객체지향적 설계와 개발의 장점을 잃지 않고 특정 기술이나 프레임워크 등 외부 환경에 종속되지 않는 것.e.g) 특정 Spring 프레임워크를 의존하게 되면 해당 객체는 POJO가 아니게 되는 것. 우리는 사람들이 자기네 시스템에 보통의 객체를 사용하는 것을 왜 그렇게 반대하는지 궁금하였는데, 간단한 객체는 폼 나는 명칭이 없기 때문에 그랬던 것이라고 결론지었다. 그래서 적당한 이름을 하나 만들어 붙였더니, 아 글쎄, 다들 좋아하더라고. - 마틴 파울러정의: 어떠한 제한, 환경, 사양에 종속되지 않는 java object. 일반적으로 다음의 세가지를 하지 않고 객체지향적 원칙에 충실한 것이라고 한다. extends를 통해 클래스를 확장한 것 implements를 통해 어떠한 인터페이스를 구현한 구현체 annotation을 포함하는 것스프링 프레임워크는 POJO방식의 프레임워크: 개발자들이 객체를 구성할 때 객체지향에만 집중해 구성한다. IoC와 DI, AOP 등은 Spring에서 모두 해주니 이런식으로 구성 가능하다.장점 이를 통해 코드는 simple해진다. 개발자는 이용하고자 하는 기술의 low level을 깊이 알기보다 비즈니스, 서비스 로직에 집중할 수 있다. 특정 환경에 종속되지 않기 때문에 테스트에 용이하다. 객체지향적 설계에 집중해서 객체지향적 이점을 가져갈 수 있다.code level POJO 예시POJO를 적용한 예public class User { private String userId; public User() { // .. } public String getUserId() { return this.userId; }}POJO를 적용하지 않은 예@AllArgsConstructor@Getterpublic class User { private String userId;}트레이드 오프: 위의 예시처럼 Lombok 라이브러리를 사용해 POJO에 정의해놓았던 boilerplate를 제거하니 POJO는 아니지만 훨씬 간결해졌다. pojo를 지향하는 것은 좋아보이지만 어떤 경우에도 pojo를 사용한다고 생각하기보다 트레이드 오프를 따져가며 선택한다면 상황에 따라 더 좋은 코드를 만들어 낼 수 있을 것 같다.Reference)https://ko.wikipedia.org/wiki/Plain_Old_Java_Objecthttps://happyer16.tistory.com/entry/POJOplain-old-java-object%EB%9E%80https://siyoon210.tistory.com/120https://m.blog.naver.com/writer0713/220700687650https://limmmee.tistory.com/8http://asuraiv.blogspot.com/2017/07/spring-pojo.html" }, { "title": "합병 정렬(Merge sort)", "url": "/posts/%ED%95%A9%EB%B3%91_%EC%A0%95%EB%A0%AC/", "categories": "Study, Algorithm", "tags": "algorithm, sort", "date": "2021-05-23 00:00:00 +0900", "snippet": ": 배열의 크기를 더이상 나눠지지 않은 형태까지 분할하고(Divide), 전부다 합쳐질 때 까지 정렬하며 합친다(Conquer) 어떠한 경우에도 O(n logn) 시간 복잡도를 갖는다.(복잡도가 안정적) Divide and Conquer 방식 문제를 작은 단위의 문제로 분할하고 각각을 해결(정복)한다음 결합해서 문제를 해결 따라서 합병 단계에서 실제 정렬이 이루어진다. 합병단계에서 추가적인 리스트를 필요로한다.(Array를 통한 구현의 경우) 보통 재귀를 이용 안정성 있는 정렬 안정성 있게 하려면, 같은 값이 나왔을 때 첫번째 배열의 원소를 먼저 넣는 방식으로 해야 해결 될 듯 장단점 장점 연결 리스트로 구현하면 링크 인덱스만 변경하면 되므로 데이터의 이동은 아주 작아진다. 제자리 정렬로 구현할 수 있다. 모든 정렬 중 가장 효율적일 수 있다고 함. 이 경우 퀵 정렬보다 유리할 수 있다. 단점 Array로 구현하면 임시 배열이 필요하다(제자리 정렬이 아니다) 레코드 크기가 크면 이동횟수가 많아져 시간낭비가 커진다. 지역성이 떨어진다: 캐시의 Page가 계속 변경된다. 따라서, 퀵 소트에 비해 지역성이 떨어진다. 그러나, 힙 소트에 비해서는 나쁘지 않다고 한다. 시간복잡도 분할 단계 - 비교연산, 이동연산 수행 안하고 그냥 분할. 병합 단계 호출의 깊이 = O(log N) 비교 연산 갯수 = 각 층에서 최대 O(n) 따라서 O(N logN) 이동횟수 = 2n log n 임시 배열에 복사 -&amp;gt; 다시 가져오기 == 2n 순환 호출 == log n 소팅 과정과정 요약 일단 다 나눈다(재귀를 통해 더이상 못 나눌 때까지) 두 리스트들의 값들을 앞부터 하나씩 비교해, 우선순위를 새로운 리스트로 옮긴다 둘 중 하나 먼저 끝나면 나머지 리스트 남은 부분 전체를 비교 없이 그냥 다 넣어준다. 코드void merge(int data[], int left, int mid, int right) { int lo = left; int hi = mid + 1; int sortedData[MAX] = {0, }; int idx = lo; while(lo &amp;lt;= mid &amp;amp;&amp;amp; hi &amp;lt;= right) sortedData[idx++] = (data[lo] &amp;lt;= data[hi]) ? data[lo++] : data[hi++]; while(lo &amp;gt; mid) sortedData[idx++] = data[hi++]; while(hi &amp;gt; right) sortedData[idx++] = data[lo++]; while(left &amp;lt;= right) // 원래 리스트에 복사 (다음 sorting을 위해) data[left] = sortedData[left++];}void mergeSort(int data[], int left, int right) { if(left == right) // atomic 원소 return; int mid = left + (right - left) / 2; mergeSort(data, left, mid); // 분할을 위한 과정 mergeSort(data, mid + 1, right); merge(data, left, mid, right); // 합병을 위한 과정}Reference)https://ko.wikipedia.org/wiki/%ED%95%A9%EB%B3%91_%EC%A0%95%EB%A0%AChttps://gmlwjd9405.github.io/2018/05/08/algorithm-merge-sort.html" }, { "title": "퀵 정렬(Quick sort)", "url": "/posts/%ED%80%B5_%EC%A0%95%EB%A0%AC/", "categories": "Study, Algorithm", "tags": "algorithm, sort", "date": "2021-05-23 00:00:00 +0900", "snippet": ": pivot(보통 가운데 값)을 기준으로 좌우 구간으로 나눠 정복(분할, 정복). e.g. 오름차순의 경우, pivot 왼쪽엔 pivot보다 작은 값을, 오른쪽엔 큰 값을 위치하도록 partition. 또 이렇게 나뉜 좌 우 배열을 다시 quick sort 수행(분할). 이 때 pivot 값은 해당 부분 배열에서 이미 본인의 위치를 찾은 것이기 때문에(정복) 재귀에 포함하지 말 것. 기본적으로 재귀를 사용하기 때문에 Stack 자료구조의 개념이 사용된다고 보면 됨 안정적인 정렬이 아니다. 중복 값이 있다고 가정했을 때 pivot과 같은 값인 경우 pivot의 위치가 해당 element 위치를 역전 가능 시간복잡도 평균적으로 O(Nlog(N)) 이지만, 최악의 경우 O(N^2)가 된다. n log n == n(n개의 element에 대해 비교연산) * log n(비교의 깊이) 최악의 경우: pivot에 해당하는 값이 항상 부분 배열내에서 가장 작거나 가장 커서 원소 n개에 대해서 각 호출을 n번, n-1번, n-2번 … 계속 수행해야한다. 따라서 이 경우 O(N^2) 방지하는 방법 ? 특정 위치의 원소를 정하지 말고 가운데의 값을 갖는 pivot을 지정하면 된다. 그런데 어떻게? - 물리적 가운데 값이 데이터의 중간이라고 보장할 수는 없을 것 같은데 대부분의 실 데이터들은 가운데값이면 가운데에 분포되어있다.(한쪽으로 편향된 경우는 거의 없다) 퀵 소트의 지역성(locality): 가까운 공간의 데이터에 반복적으로 접근한다는 성질. merge sort와 같은 시간복잡도를 가지지만, 일반적으로 지역성의 특징때문에 퀵 소트가 성능이 좋다고 한다. 가상 메모리의 관점에서, 참조의 지역성이라는 성질을 효율좋게 이용하기 위해 자주 사용되는 페이지와 인접하게 있는 페이지(메모리)는 캐싱된다. 이는 물리 메모리까지 접근하지 않아도 되기 때문에 이득이다. 처음부터 끝까지, 심지어 새로운 배열을 할당해야하는 merge sort와 달리, quick sort는 제자리 정렬 알고리즘이며, pivot을 기준으로 인접한 주소의 메모리를 참조해 swap하는 방식이다. 따라서 quick sort가 이러한 특성을 잘 이용한 알고리즘이다.소팅 과정 초기 pivot: 5(맨 앞)을 기준으로 수행. 해당 pivot 제외 가장 좌측 low, 가장 우측 high로 접근 high에서 왼쪽으로 가면서 pivot보다 작은 것 있으면 stop, low에서 오른쪽으로 가면서 pivot보다 큰 값 있으면 stop 둘다 stop한 상황에서 둘이 교체하고, 다시 진행 high &amp;lt; low 가 되었을 때 high와 pivot을 교체(pivot이 왼 쪽에 있는 경우였기 때문에) pivot을 기준으로 좌, 우 서브 배열로 나눠 2번의 과정을 각각 진행한다.(재귀적으로)int quickSort(int* data, int start, int end) { if(start == end) // size of data is 1. return; int pivot = start; int low = start + 1, high = end; while(1) { while(start &amp;lt; high &amp;amp;&amp;amp; data[pivot] &amp;lt; data[high]) high--; while(low &amp;lt;= end &amp;amp;&amp;amp; data[low] &amp;lt; data[pivot]) low++; if(high &amp;lt; low) break; int tmp = data[high]; data[high] = data[low]; data[low] = tmp; } int tmp = data[high]; data[high] = data[pivot]; data[pivot] = tmp; quickSort(data, start, high - 1); quickSort(data, high + 1, end);}Reference)https://ko.wikipedia.org/wiki/%ED%80%B5_%EC%A0%95%EB%A0%AChttps://github.com/JaeYeopHan/Interview_Question_for_Beginner/tree/master/Algorithmhttps://gmlwjd9405.github.io/2018/05/10/algorithm-quick-sort.html" }, { "title": "OWT Stream publish, subscribe 코드 분석 및 시나리오", "url": "/posts/OWT_pub_sub_%EC%8B%9C%EB%82%98%EB%A6%AC%EC%98%A4_%EB%B6%84%EC%84%9D/", "categories": "Study, WebRTC", "tags": "webrtc", "date": "2021-05-22 00:00:00 +0900", "snippet": ": 아래의 과정으로 코드 분석해보기Publish 과정 Client(엔드포인트에서 사용하는 사용자) 유효성검사 RTCRtp인코딩 파라미터, 오디오, 비디오 인코딩 파라미터 validation audio, video가 MediaStream에 존재하는 트랙들과 일관된지 options의 audio, video가 있는지 audio,video boolean이나 array인지, 올바른 파라미터 들어와있는지 +기타 유효성 검사 peerConnection 생성 signaling Message 보냄(publish로) V11Client on(&#39;publish&#39;) if(!that.inRoom) -&amp;gt; 방에 join하지 않았다면 여기서 에러 streamID (난수)생성 Validation 이후 Portal의 publish call clientId == participantId, stream_id, req == pubInfo Portal portal/rpcRequest에 RPC call(publish) participants[participantId].controller (여기선 conference Agent), participantId, streamId, pubInfo Conference Agent에게 요청됨(that.publish) Conference Agent - 여기서 Participants[participantId] 등록(addParticipant) 유효성 검사 해당 시점 accessController, roomController 객체의 존재여부 Portal로부터 전달된 participants[participantId] (== 해당 Client가 Join 했는지) auth, input 수, Stream 이미 존재, audio or video 금지여부 등 sip or analytics 타입의 경우 stream 추가하고 끝 initiateStream을 통해 streams 배열에 stream객체 새롭게 저장 Pub할 때 streams[streamId] init, Sub할 때 Subscriptions[subscriptionId] init 생성 시점: addStream 여기서 streamId, subscriptionId는 v11Client에서 생성한 Random Number streams[stream]에는 info가 있음( info : { owner: participantId, type: pubInfo.type } ) format_preference의 video, audio를 pubInfo의 video,audio로 set webrtc worker node를 얻기 위해 accessController에게 initiate 요청 accessController Session 배열에 session 객체 새롭게 저장 Pub / Sub에 관계 없이 전부 sessions[sessionId]에 추가.(이 때 conflict 방지 해야 함) getWorkernode를 통해 workerAgent.Id, workerNode 얻음 -&amp;gt; cluster_name, sessionOptions.type == pubInfo.type(webrtc), {in_ room, sessionId}, origin == participants[participantId].getOrigin() clusterManager에게 scheduling 요청 -&amp;gt; scheduler가 workerAgent 전해주고 -&amp;gt; workerAgent에 해당하는 node를 node manager에게 요청 -&amp;gt; 준비된 node 할당 workerAgent.id, workerNode 반환 worker, workers[worker].info 이 결과를 locality 변수에 저장, 해당 세션ID에 이 worker 정보 저장 initiate를 통해 worker node, session id 및 정보들 conference/rpcRequest의 RPC call conference/rpcRequest에서는 목적노드의 publish call -&amp;gt; worker node에게로 sessionId (=connectionId), sessionType (=connectionType), options Worker node(access node) (webrtc/index) 중복 연결 방지 validation (connectionType == sessionType이 webrtc일 때) createdWebRTCConnection WrtcConnection 생성 로직 생성되면서 내부 변수들 세팅, wrtc 변수를 새로운 Connection으로 만들어주고, addmediaStream 진행 됨 initWebRtcConnection -&amp;gt; wrtc 객체에 status_event 라는 event Handler 등록 이후 이벤트 발생시 이벤트로 전해지는 결과(evt) 타입이 answer, candidate, ready, rid, firstrid에 따라 결과 나뉨 상황에 따라 콜백으로 on_status or on_mediaUpdate 발생 addConnection 중복 connection 객체 생성 방지, 새로 생성해 배열에 저장, return ‘ok’ accessController까지 내려가, sessions[sessionId].state를 connecting으로 변경 후 return ‘ok’ conference에서도 result 전달, -&amp;gt; portal -&amp;gt; v11Client -&amp;gt; Client webRTC connection complete wrtc 객체 event 발생(status_event) 정상일 때 ready 상태이므로 on_status({type: &#39;ready&#39;, audio: ~~, video: ~~, simulcast: ~~}) 발생 workder node (webrtc/index)에서 콜백으로 notifyStatus. options.controller에게 onSessionProgress remote 요청 Conference Agent의 onSessionProgress에서 accessController.onSessionStatus(sessionId, sessionStatus) onSessionStatus에서 ready -&amp;gt; onReady audio, video 세팅 후 on_session_established (콜백)하면, Conference Agent에서 accessController 만들 때 콜백으로 등록해 놓은 onSessionEstablished 실행 worker Agent, worker Node 정보가 등록되어있는 sessionInfo, session을 전달하며 addStream 참가자(participantId == client)에게 “progress” 메시지, sessionId와 status : ready를 함께 전송 Subscribe 과정 Client send signaling message(subscribe) V11Client Subscripbe Id 생성, validation, portal에게 subscribe 요청 Portal rpcRequest subscribe 요청(portal/rpcReq) Conference Agent가 받음 Conference Agent 여러 유효성체크, subs 정보 저장 initiateSubscription -&amp;gt; subsc배열에 subs 객체 추가 accessController.initiate Access Controller Session 배열에 session 객체 저장 getWorkernode를 통해 worker node 얻고, locality 변수에 저장 이후 worker node, session에 대한 정보들 conference/rpcRequest의 RPC call(initiate) conference/rpcReq 에서 direction === out이므로 목적노드의 subscribe 요청 Worker node(webrtc/index) webRTC connection 생성 (createdWebRTCConnection) 위의 메서드 내부에서 WrtcConnection 객체 생성, 이 때 pub을 위한 addMediaStream 또한 진행됨(미디어 스트림 생성) Wrtc 객체 생성하면서 Webrtc connection Ready되고, 여기서 Conference node에게 connection ready status를 알려야 함.( onSessionProgress 호출) accessController에서 onReady 상태가 되면, 미리 세팅해두었던 conference의 onSessionEstablished를 호출 Conference addSubscription 호출, media.video, audio 설정 후 roomController -&amp;gt; subscribe getAudioStream mixed Stream이라면 mixedStream을 생성하고 AudioStream을 얻음 getVideoStream mixed Stream이고, 매치되는 mixed stream이 없다면 해당하는 Stream을 생성 후 얻음 Reference)Client - https://github.com/open-webrtc-toolkit/owt-client-javascript/blob/8fae8a8e1714109d0851391f8fd20ffe3775cb65/src/sdk/conference/channel.js#L146Server - https://github.com/open-webrtc-toolkit/owt-server" }, { "title": "프로세스(Process)", "url": "/posts/%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4(Process)/", "categories": "Study, OS", "tags": "os, 운영체제", "date": "2021-05-22 00:00:00 +0900", "snippet": ": 실행중인 프로그램. 디스크로부터 메모리에 적재되어 CPU의 할당을 받고, OS로부터 주소 공간, 메모리 등을 할당받는 것Memory Section Data(BSS + DATA) 전역 변수(초기화 되지 않은 전역변수는 BSS영역에, 나머지는 DATA영역), static 변수 저장 프로세스 생성 시점에 위의 변수들을 이 곳에 저장 Stack 로컬 변수, 함수의 매개변수, 복귀 주소 등 임시자료 저장. 초기화 시점에는 메모리만 할당 보통 높은 주소에서 낮은 주소로 할당(보통 Descending stack) Heap과 반대로 Heap 동적 할당을 위한 메모리 영역. 초기화 시점에는 메모리만 할당 보통 낮은 주소에서 높은 주소로 할당(Stack과 반대로) Code 프로그램 실행 파일 내의 명령어들(소스코드) 저장 Stack과 Heap 메모리 영역 각각은 서로의 반대 방향으로 크기가 커진다. Stack overflow는 stack이 heap 영역을 침범, Heap overflow는 heap이 stack 영역을 침범해 발생하는 overflow 같은 타입, 이름이라도 동적할당하냐 안하냐의 차이가 있다. 객체 인스턴스의 경우 동적으로 할당된 것이고, 할당 해제 or GC에 의해 언제든 없어진다. 항상 힙 영역으로 선언된다. ```c// c언어 기준int foo[100]; // -&amp;gt; 정적으로 할당해서 stack에 저장 int* foo = malloc(sizeof(int) * 100);// 동적할당된 배열은 heap에 저장// 해당 배열을 가리키는 포인터 foo는 stack에 저장 int* a; // stack에 포인터 저장 PCB(프로세스 제어 블록): 프로세스에 대한 중요한 정보들을 저장 하고있는 운영체제의 자료구조 프로세스 생성과 동시에 고유한 PCB 생성 프로세스 Context switch 발생 시 진행하던 작업을 PCB에 저장하고 switch. 다시 CPU 할당받으면 PCB로부터 저장되어있던 내용 불러와 작업 수행. PCB 내부 저장되는 것 PID (a.k.a. Process ID) : 프로세스마다의 고유한 아이디 프로세스 상태(new, ready, blocked, running, terminated) 프로그램 카운터 : 다음으로 실행할 명령어 주소 CPU 레지스터 : running 상태에서의 실행을 저장하기 위해 사용된다. PC 레지스터, AC 레지스터, IR 등등 존재 CPU 스케줄링 정보 : 프로세스 우선순위, 스케줄 큐에 대한 포인터 멀티 프로세스: 두개 이상의 CPU가 task 병렬적 처리. 한 프로그램을 실행한다 하더라도 n개의 프로세스가 실행될 수 있다. 메모리를 독립적으로 가지지만, 공유 메모리를 갖도록 할 수도 있다.(IPC)IPC: 프로세스간 통신. 메시지 큐, RPC, 소켓, 공유 메모리 사용, 파이프, 세마포어 등등 다양한 방식이 있다.장점 한 프로세스 장애 발생해도 다른 프로세스에 영향이 없음(안정성 높음) 임계영역에 대한 고민을 할 필요 없음단점 자원 공유가 되지 않아 메모리 낭비 context switch(CPU scheduling)시에 속도 저하Reference)https://github.com/JaeYeopHan/Interview_Question_for_Beginner/tree/master/OShttps://blockdmask.tistory.com/22https://velog.io/@hoo00nn/%EB%A9%80%ED%8B%B0-%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4%EC%99%80-%EB%A9%80%ED%8B%B0-%EC%8A%A4%EB%A0%88%EB%93%9Chttps://wooody92.github.io/os/%EB%A9%80%ED%8B%B0-%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4%EC%99%80-%EB%A9%80%ED%8B%B0-%EC%8A%A4%EB%A0%88%EB%93%9C/http://tcpschool.com/c/c_memory_structure" }, { "title": "선택 정렬(Select sort)", "url": "/posts/%EC%84%A0%ED%83%9D_%EC%A0%95%EB%A0%AC/", "categories": "Study, Algorithm", "tags": "algorithm, sort", "date": "2021-05-22 00:00:00 +0900", "snippet": ": 제자리 정렬 알고리즘. 가장 작은원소를 찾아 첫번째 자리에, 그 다음을 찾아 두번째 자리에 .... 이러한 방식으로 진행 기본적으로 O(n^2) 의 시간복잡도를 갖는다. 장점: 자료 이동 횟수가 미리 결정됨 단점: 값이 같은 레코드가 있는 경우에 상대적인 위치가 변경될 수 있다. 정렬 안정성을 만족하지 않는다. -&amp;gt; 안정성 있게 구현도 가능할 것 같다. 교환(이동) 횟수: 3(n - 1) (SWAP함수 작업)제자리 정렬(in-place): 배열 내에서 정렬하기 때문에 따로 메모리 공간이 필요 없다.정렬에서의 안정성: 키 값이 같은 원소들끼리 “정렬되기 전의 순서”와 “정렬되고 나서의 순서”가 유지되는가 되지 않는가?코드void selectSort(int data[], int size) { for(int i = 0; i &amp;lt; size; i++) { int idx = i; for(int j = i + 1; j &amp;lt; size; j++) { if(data[idx] &amp;gt; data[j]) { idx = j; } } int tmp = data[i]; data[i] = data[idx]; data[idx] = tmp; }}Reference)https://ko.wikipedia.org/wiki/%EC%84%A0%ED%83%9D_%EC%A0%95%EB%A0%AChttps://gmlwjd9405.github.io/2018/05/06/algorithm-selection-sort.html" }, { "title": "버블 정렬(Bubble sort)", "url": "/posts/%EB%B2%84%EB%B8%94_%EC%A0%95%EB%A0%AC/", "categories": "Study, Algorithm", "tags": "algorithm, sort", "date": "2021-05-22 00:00:00 +0900", "snippet": ": 인접한 두 원소끼리 비교해, 크기가 순서대로 되어있지 않으면 두개를 바꾼다. 기본적으로 O(n^2) 시간복잡도를 갖는다. 그냥 무조건 for문 두번 돌기 때문에 최악, 평균 이런거 없이 다 O(N^2) 선택정렬과 기본 개념이 유사 장점: 간단하다 단점: 특정 요소가 최종 정렬 위치에 있어도 교환하는 일이 일어날 수 있다. 소팅 과정: 예시로 보는 것이 직관적. 오름차순의 경우를 예시 1회전(1번 루프) [6 4 9 7 2 5] -&amp;gt; [4 6 9 7 2 5] -&amp;gt; [4 6 9 7 2 5] -&amp;gt; [4 6 7 9 2 5] -&amp;gt; [4 6 7 2 9 5] -&amp;gt; 최종 [4 6 7 2 5 9] 2회전 [4 6 7 2 5 9] -&amp;gt; [4 6 7 2 5 9] -&amp;gt; [4 6 7 2 5 9] -&amp;gt; [4 6 2 7 5 9] -&amp;gt; 최종 [4 6 2 5 7 9] 3회전 [4 6 2 5 7 9] -&amp;gt; [4 6 2 5 7 9] -&amp;gt; [4 2 6 5 7 9] -&amp;gt; 최종 [4 2 5 6 7 9] 4회전 [4 2 5 6 7 9] -&amp;gt; [2 4 5 6 7 9] -&amp;gt; 최종 [2 4 5 6 7 9] 5회전 [2 4 5 6 7 9] -&amp;gt; 최종 [2 4 5 6 7 9]코드void bubbleSort(int data[], int size) { for(int i = size - 1; i &amp;gt; 0; i--) { for(int j = 0; j &amp;lt; i; j++) { if(data[j] &amp;lt; data[j + 1]) { int tmp = data[j]; data[j] = data[j + 1]; data[j + 1] = tmp; } } }}Reference)https://gmlwjd9405.github.io/2018/05/06/algorithm-bubble-sort.html" }, { "title": "JPA 연관관계", "url": "/posts/JPA_%EC%97%B0%EA%B4%80%EA%B4%80%EA%B3%84/", "categories": "Study, JPA", "tags": "jpa, spring boot jpa", "date": "2021-05-21 00:00:00 +0900", "snippet": "연관관계객체 연관관계와 DB 연관관계를 어떻게 매핑할지를 고민 이를 통해 객체지향과 DB사이의 패러다임 불일치 해결필요한 이유? 객체지향적으로 설계하기 위해 테이블에 맞춰 데이터중심으로 모델링하는 경우 객체 관점, DB 관점 존재 DB관점에서는 외래키 하나로 양쪽 테이블을 조인한다. 따라서 나눌 필요 X DB관점은 방향성이 없고 객체 관점은 방향성이 있다. 단방향 연관관계 한 객체만 참조용 field를 갖는다. 객체와 테이블의 연관관계 참조를 사용하는 객체 연관관계는 단방향 FK를 사용하는 테이블 연관관계는 양방향 @ManyToOne : N : 1 관계라는 매핑 정보. 다대일 관계에서 항상 “다” 쪽이 외래키를 가진다. @JoinColumn : 외래 키 매핑할 때 사용 이 annotation을 통해 연관관계 맵핑 양방향 연관관계 두 객체 모두 참조용 field를 갖는다. 단, 테이블에서는 한쪽 테이블만(다대일에서 다) FK 하나만 가진다. 단순히 단방향보다 조회를 편하게 하기 위한 용도 어차피 조회할 수 있는 기능만 있다.(주인 개념때문에) 주인: 연관 관계에서의 FK를 관리하는 주체(주인만이 FK 변경 가능) 비즈니스(도메인)적으로 중요하지 않다. 주인은 테이블 등록, 수정, 삭제 등 제어의 권한 있음 주인이 아니면 read only(DB관점) 객체 관점에서는 수정같은게 있을 때 둘다 수정해 데이터 동기화를 해줘야 한다. 외래 키가 있는 곳을 주인으로 설정 다대일 관계에서 다가 갖고있는 일의 외래키부분이 연관관계 주인. 이렇게 해야 성능 이슈가 없다. 주인이 아닌쪽은 읽기만 가능 ​ e.g. 1) Member에 Team값을 업데이트 하면 mappedBy로 매핑된 Team의 members로 업데이트 된 DB의 멤버들을 읽을 수 있다는 이야기이다. ​ e.g. 2)Member에 Team 정보 update 했는데, Team에서 getMembers로 가져왔는데 반영 안됐네? -&amp;gt; 연관관계 설정 안했구나.. 라고 바로 알 수 있다. 출처: https://ict-nroo.tistory.com/122 [개발자의 기록습관] 이걸 많이쓰면 복잡해질 수 있음 객체 관점에서는 양쪽 객체 모두에게 참조를 설정해줘야 한다. 여기서 실수가 나면 양방향이 깨지는 관계가 존재하게 됨. 모두 양방향으로 설정하게 되면 User같은 엔티티는 아주 많은 테이블과 연관 관계를 맺게 됨. @OneToMany(mappedBy = &quot; &quot;) 를 통해 연관관계 매핑 주인은 mappedBy 속성 사용 x @JoinColumn 사용 주인이 아니면 mappedBy로 주인(필드) 지정 좋은 것은 일단 단방향 매핑으로 하고 나중에 역방향 객체 탐색이 꼭 필요할 때 추가해주기다대다 연관관계 n:m 테이블 보다는 연결 테이블을 설정해 관리해야함 RDBMS에서는 정규화된 테이블 2개로 다대다 관계를 표현할 수 없기 때문 한계: 개발 과정에서 추가 데이터가 필요할 수 있으나, 맵핑 정보 외에 추가 정보를 넣는 것이 불가능 연결 테이블을 Entity로 승격 양 테이블의 FK를 묶어서 PK로 사용 할 수 있음 실제로는 독립적인 연결 엔티티만의 id를 사용하는 것이 권장. ID가 두 테이블에 종속되지 않을 수 있음. Reference)https://ict-nroo.tistory.com/127https://velog.io/@conatuseus/%EC%97%B0%EA%B4%80%EA%B4%80%EA%B3%84-%EB%A7%A4%ED%95%91-%EA%B8%B0%EC%B4%88-1-i3k0xuve9ihttps://jeong-pro.tistory.com/231https://ict-nroo.tistory.com/122" }, { "title": "삽입 정렬(Insert sort)", "url": "/posts/%EC%82%BD%EC%9E%85_%EC%A0%95%EB%A0%AC/", "categories": "Study, Algorithm", "tags": "algorithm, sort", "date": "2021-05-21 00:00:00 +0900", "snippet": ": 두번째 element부터 시작해 본인의 앞 element들과 비교하면서(계속 swap하면서) 본인의 위치를 찾아감. 최선의 경우 : 이동 없이 1번의 비교만 이루어지는 경우(이미 정렬되어 있는 경우) O(N) 시간복잡도를 갖는다. 최악의 경우 : 완전 역순으로 되어있을 때 O(n^2) 시간복잡도를 갖는다. 이때는 이동 횟수도 O(N^2) 장점 안정적인 정렬방법 (같은 값에 대해선 change 하지 않고 다음 원소의 정렬로 넘어감) 이미 거의 정렬되어있는 경우에 매우 효율적일 수 있다. n 값이 작은 경우에도 효율적이다(n &amp;lt; 16을 기준으로 선택한다고 한다) 참조 지역성의 효과를 매우 잘 얻을 수 있다. 단점 많은 이동을 포함 바로 앞의 것과 비교해 옮길만 하면 그냥 바꿔버림 레코드 수가 많고 레코드 크기가 클경우 부적합 코드void insertSort(int data[], int size) { for(int i = 1; i &amp;lt; size; i++) { for(int j = i; j &amp;gt; 0; j--) { if(data[j - 1] &amp;gt;= data[j]) break; int tmp = data[j - 1]; data[j - 1] = data[j]; data[j] = tmp; } }}Reference)https://ko.wikipedia.org/wiki/%EC%82%BD%EC%9E%85_%EC%A0%95%EB%A0%AChttps://gmlwjd9405.github.io/2018/05/06/algorithm-insertion-sort.html" }, { "title": "MST(최소 스패닝 트리)와 Kruskal, Prim", "url": "/posts/MST_%ED%81%AC%EB%A3%A8%EC%8A%A4%EC%B9%BC_%ED%94%84%EB%A6%BC/", "categories": "Study, Algorithm", "tags": "algorithm, mst, kruskal, prim", "date": "2021-05-20 00:00:00 +0900", "snippet": ": 최소한의 연결을 가지면서 모든 정점을 포함하고, 가중치도 최소인 것특징 스패닝 트리 중 간선 가중치 합이 최소 스패닝 트리이므로 n-1개의 간선 간선의 weight(가중치) 합이 최소여야 한다. Cycle이 없어야 한다.스패닝 트리? 최소한의 연결로 모든 정점을 포함하는 트리 n개의 정점을 가지는 그래프의 간선의 수는 n-1개 전체 그래프에서 일부 간선을 선택해 만든 트리 사용 사례: 통신망, 도로망, 유통망에서 길이, 구축 비용, 전송 시간 등을 최소로 하는 곳 도로 건설: 최소 도로 길이로 도시들을 모두 연결 전기 회로: 최소 전선 길이로 단자들을 모두 연결 통신: 최소 전화선으로 케이블 망 구성크루스칼: 전체에서 가중치가 작은 간선부터 연결 (그리디 알고리즘)해 MST를 만드는 알고리즘 각 단계에서 Cycle을 이루지 않는 최소 비용 간선 선택 부모노드 병합하고, 사이클 확인하는 과정에서 보통 union-find 사용과정 가중치를 기준으로 간선을 오름차순 정렬 가중치 낮은 것부터, 사이클을 만들지 않는 간선을 선택해 MST 집합에 추가프림: 하나의 시작점을 잡고 연결된 정점들 중 가중치 낮고, 사이클을 만들지 않는 간선 선택 크루스칼과는 다르게 정점을 기준으로 선택 이전 단계에서 만들어 놓은 MST를 확장하는 방법으로 사용되기도 함과정 시작 정점 선택 - 이 정점을 포함한 집합은 MST가 된다. 앞 단계에서 만들어진 MST에 인접한 정점 중 낮은 가중치로 연결된 정점 이 때 사이클을 만들지 않도록 n-1 간선을 가질 때까지 반복Reference)https://www.crocus.co.kr/733https://github.com/WeareSoft/tech-interview/blob/master/contents/algorithm.md" }, { "title": "JPA + Kotlin에서 고려할 것들", "url": "/posts/JPA_+_Kotlin%EC%97%90%EC%84%9C_%EA%B3%A0%EB%A0%A4%ED%95%A0_%EA%B2%83%EB%93%A4/", "categories": "Study, JPA", "tags": "jpa, spring boot jpa, kotlin", "date": "2021-05-16 00:00:00 +0900", "snippet": " Entity는 public, protected의 매개변수가 없는 “기본 생성자(No-argument 생성자)”를 가지고 있어야 한다. 클래스 상태를 초기화 할 때 기본 생성자를 이용하기 때문. 코틀린에서는 @Entity / @Embeddable / @MappedSuperClass annotation이 붙어있을 때 자동으로 no-arg 생성자를 생성해준다. Entity 클래스 뿐 아니라 클래스 내부 모든 메서드, persist되는 프로퍼티는 final로 지정 불가 open class로 만들어주어 상속이 가능하도록 해야함 Lazy loading 이라는 특성 때문. 런타임에 proxy 객체를 통해 entity를 상속하고 이를 통해 참조해야함. Entity의 상태는 JavaBean style에 부합하는 인스턴스 변수로 표현. 인스턴스 변수는 Entity 자기 자신에 의해서만 접근 되어야 함. 따라서 Kotlin에서는 프로퍼티에 protected set 과 같은 키워드로 제한 이전에 설정해놓은 open이 프로퍼티에도 적용되어, private set으로 할 경우 에러가 발생 따라서 set을 해야하는 경우 protected set, set이 필요 없는경우 val로 지정 update logic을 수행해야 할 때는 entity 내부의 메서드를 이용 Reference)https://blog.junu.dev/37" }, { "title": "HTTP 1.0, HTTP 1.1, HTTP 2.0", "url": "/posts/HTTP1.1_vs_HTTP2.0/", "categories": "Study, HTTP", "tags": "http, http 1.0, http 1.1, http 2.0", "date": "2021-05-15 00:00:00 +0900", "snippet": "HTTP/1.0 처음으로 널리 쓰인 HTTP 버전 1연결당 1Req,1Res를 처리 keep-alive 헤더로 connection 유지 가능 브라우저에서 요청에 대한 성공과 실패를 바로 알 수 있게 됨. 이전(0.9)에는 GET만 사용했고, 여기서 POST 추가됨HTTP/1.1 가장 많이 사용되고 있는 프로토콜 개발자도구에서 protocol에 http/1.1 로 표현됨 파이프라이닝 도입 이전 요청 다 수행하기 전에 다음 요청 보냄. 지속 커넥션: 1연결당 여러 건의 요청 처리. 일정 시간 내 연결 정보를 기억해 연결 재사용 동시전송문제, 다수의 리소스 처리 시 성능 이슈 단점 HOLB(Head Of Line Blocking) - 특정 응답 지연 Pipelining을 통해 1연결 1req,res - &amp;gt; 1연결 N req,res 기법으로 해결하는 과정에서 발생 문제점: 파이프라인의 앞선작업 하나의 res가 지연되면 다른 res도 지연됨 RTT(Round Trip Time) 증가 디폴트가 지속커넥션이지만 성능 저하를 방지하기 위해 connection을 끊어주긴 해야한다. 클라이언트 입장에선 과부하 방지를 위해 넉넉잡아 두개의 커넥션 유지 connection마다 TCP 연결마다 3-way handshake or 4-way handshake -&amp;gt; 오버헤드 heavy header header의 많은 중복된 값이 전송됨. 이 중 cookie가 가장 문제라고 함 cookie는 매번 전송되기 때문에. 크기도 꽤 큼.(토큰이 더큼) HTTP/2.0 HTTP 1.1과 동일한 API면서 성능 향상에 초점 개발자도구에서 protocol에 h2 로 표현됨 Multiplexed Streams(다중화된 요청): 한 요청에 여러개의 스트림을 보낸다는 이 성질이 가장 큰 특징 서버가 Stream으로 요청받으면, 그 요청과 같은 Stream으로 응답한다. 스트림은 31비트의 고유한 식별자를 갖기 때문에, 순서가 섞여도 상관없고 따라서 그냥 보내는데에만 신경쓴다. Stream Prioritization : 스트림 간 우선순위를 갖는다. 만약 대역폭이 충분하지 않을 때 중요한 스트림부터 요청 할 수 있다.(서버쪽 처리는 의무사항이 아니기 때문에 우선 처리는 보장 안된다.) Server Push : 클라이언트가 요청하지 않은 리소스(필요하게 될 리소스)를 마음대로 보내준다. HTTP/1.1에서는 요청한 html 문서를 해석하면서 필요한 리소스를 재요청하지만 HTTP/2에서는 이러한 것들을 push해주어 클라이언트의 요청 최소화한다. Header Compression : HPACK 압축방식을 통해 Header 정보 압축 한번 사용한 스트림은 한 커넥션에서 다시 사용하지 않는다. 만약 식별자 고갈이 되는경우라면 그냥 다시 커넥션을 맺으면 된다.이 링크의 애니메이션을 통해 정확하게 이해하기https://freecontent.manning.com/animation-http-1-1-vs-http-2-vs-http-2-with-push/이해를 돕는 그림Reference)HTTP 완벽가이드https://chacha95.github.io/2020-06-15-gRPC1/https://velog.io/@taesunny/HTTP2HTTP-2.0-%EC%A0%95%EB%A6%AChttps://developers.google.com/web/fundamentals/performance/http2?hl=kohttps://developer.mozilla.org/ko/docs/Web/HTTP/Overview#http_%EA%B8%B0%EB%B0%98%EC%8B%9C%EC%8A%A4%ED%85%9C%EC%9D%98%EA%B5%AC%EC%84%B1%EC%9A%94%EC%86%8C" }, { "title": "JPA와 관련해 겪은 이슈들, 간단한 메모", "url": "/posts/JPA_Issues/", "categories": "Study, JPA", "tags": "jpa, spring boot jpa", "date": "2021-05-14 00:00:00 +0900", "snippet": "210514JPA repository 사용시 Optional 이슈 기본적으로 자바에 맞춰져 있으므로 Optinal로 묶여있음 Kotlin의 장점을 잘 살리려면 Nullable을 바로 체크할 수 있어야 함. Extension 사용 함수를 재정의하기 이미 잘 구현되어있는 built-in extension 사용 e.g) findById() -&amp;gt; findByIdOrNull() 성능 이슈가 있다고 하지만, 무시할 수 있을정도의 미미한 성능차 @JoinColumn 어노테이션의 옵션 name은 해당 엔티티 테이블에 어떤 컬럼명으로 저장할지를 지정 실제로 FK가 맵핑되는 컬럼은 해당 타입(엔티티)의 PK이니까 자동으로 알아서 맵핑해줌. findAllBy~~ vs findBy~~~ 둘은 이름만 다르지, 같은 쿼리를 만들어 냄. 복수형을 만들어내는 곳에선 All, 아닌 곳에선 findBy를 사용해 코드의 가독성을 높이면 됨210525MongoDB 도입해 개발 도중 발생 에러If you have database settings to be loaded from a particular profile you may need to activate it mongodb application.properties 이 곳에서 datasource 명시 안했어서? -&amp;gt; 외부 속성 문제 X JPA + MongoDB 의존성으로 인한 문제. JPA 제거(MongoDB에서도 원래 사용하던 API 그대로 사용)" }, { "title": "Dirty checking", "url": "/posts/Dirty_checking/", "categories": "Study, JPA", "tags": "jpa, spring boot jpa, dirty checking", "date": "2021-05-13 00:00:00 +0900", "snippet": ": Transaction을 commit하는 시점에 알아서 데이터베이스에 반영해주는 것 단건의 수정에 대한 쿼리를 JPA에서는 지원하지 않는데, 해당 엔티티를 변경하고, 별도로 save하지 않아도, 변경사항이 반영됨더티체킹 과정 일단 엔티티의 최초 상태(스냅샷)를 영속성 컨텍스트에 보관해 놓는다. 트랜젝션 커밋 시 em 내부에서 flush 호출되고, 이 때 변경된 엔티티와 스냅샷을 비교한다. 변경된 엔티티가 있다면 수정 쿼리를 쓰기 지연 sql 저장소에 보내고, 이 sql은 DB에 날라가고, 트랜잭션은 커밋 완료된다.위의 과정을 통하기 때문에 벌크 연산을 이용한 수정과는 과정이 다름.만약 @Transactional을 사용하지 않았다면 위의 과정은 발생하지 않고, 원하는 시점에 save 나 saveAndFlush를 사용해야 함.Reference)https://cheese10yun.github.io/jpa-bulk/https://devhyogeon.tistory.com/4https://jojoldu.tistory.com/415https://interconnection.tistory.com/121" }, { "title": "Plugin", "url": "/posts/Plugin/", "categories": "Study, Kotlin", "tags": "kotlin", "date": "2021-05-10 00:00:00 +0900", "snippet": "all-open 플러그인 Kotlin은 기본적으로 final class 따라서 상속 불가 안정성 상승 effective java “상속에 대한 좋은 설계와 문서화를 할 자신이 없다면 상속을 허용하지 말 것.” 그러나 java에 익숙하다면 이것이 불편할 수 있음 all-open 플러그인 buildscript { dependencies { classpath &quot;org.jetbrains.kotlin:kotlin-allopen:$kotlin_version&quot; }} apply plugin: &quot;kotlin-allopen&quot; plugins { id &quot;org.jetbrains.kotlin.plugin.allopen&quot; version &quot;1.4.32&quot;} allOpen { annotation(&quot;com.my.Annotation&quot;) // annotations(&quot;com.another.Annotation&quot;, &quot;com.third.Annotation&quot;)} 이처럼 annotation을 설정하면 해당 annotation을 갖는 클래스는 모두 all-open이 된다. 상속이 불필요한 곳은 막을 수 있음. 기본적으로 @Configuration, @Componenet, @Async 등 특정 어노테이션을 갖는 클래스들은 이미 open 되어있다(어노테이션에 의해서) - 상세는 공식문서에 Reference)https://cchcc.github.io/blog/Kotlin-%EB%94%94%ED%8F%B4%ED%8A%B8%EA%B0%80-final%EC%9D%B8-%EC%9D%B4%EC%9C%A0/https://kotlinlang.org/docs/all-open-plugin.html#gradle" }, { "title": "for-loop vs forEach vs map", "url": "/posts/for-loop_forEach_map/", "categories": "Study, Kotlin", "tags": "kotlin", "date": "2021-05-04 00:00:00 +0900", "snippet": "Map vs forEach forEach 값 반환 X 각 요소에 대한 콜백을 수행. (현재 배열을 변경해서 반환). map보다 빠르다. JS에서는 for-loop가 더 빠르고, kotlin에서는 forEach(Collection의 경우)가 더 빠르다. 원래의 배열을 바꿀 염려 있음. 주로 DB 저장과 같은 일에 사용됨 map 값 반환 O 각 요소에서 함수를 호출하고, 결과로 새로운 배열을 만들어냄. 원래의 배열에 영향을 주지 않기 때문에 함수형 프로그래밍에 더 적합. for vs forEach break, continue등을 사용하며 중간에 빠져나올 일이 있을때는 for, 한바퀴 전체를 돌기 위한 목적이라면 forEach 가 적절 성능 일반적 반복문: for문이 더 좋음 Collection 반복문: forEach가 더 좋음 list, map, set과 같은 클래스들은 Collection을 상속받는데, 해당 클래스 몇몇 함수들은 inline을 제공받음 따라서 더 빠름. inline함수 (c언어에서의 매크로 함수) inline 함수가 더 빠른 이유 함수 호출 시 해당 위치로 컴파일러가 이동해, 해당 함수를 실행 inline함수를 사용하면 함수 호출부분이 해당 inline 함수의 내용으로 치환(대체)됨. 함수 호출 시 처리해야 할 작업을 줄일 수 있다. -&amp;gt; 1. 함수 종료 후 반한할 현재 명령어의 주소 저장, 2. 해당 함수로 점프시키는 일, 3. 다시 돌아오는 일 등 단점: 호출부가 많아진다면, 컴파일된 코드 양이 많아질 수 있다는 점 asSequence: lazy collection의 한 종류임. 체인 형식(filter, map 등)으로 컬렉션 호출 시 list는 값을 저장하기 위해 tmp collection을 따로 만든 후 값을 저장하는 형를 띄우는데, 이는 오버헤드가 되며 퍼포먼스 저하.(java 8에서는 stream에 대응되는 lazy collection이 제공되면서 이를 해결했다고 함) Reference)https://hwan-shell.tistory.com/245https://medium.com/mobile-app-development-publication/kotlin-for-loop-vs-foreach-7eb594960333https://coding-factory.tistory.com/694https://codechacha.com/ko/kotlin-inline-functions/https://boycoding.tistory.com/220" }, { "title": "WebRTC &amp; OWT", "url": "/posts/webRTC_OWT/", "categories": "Study, WebRTC", "tags": "webrtc", "date": "2021-05-02 00:00:00 +0900", "snippet": ": web real-time communication. 웹 애플리케이션과 사이트가 중간자 없이 실시간으로 데이터를 교환, 영상이나 오디오를 스트림해주는 기술 P2P 통신: Third party software(서버와 같은 중간자) 없이 P2P(Pear to Pear) 데이터 통신을 통해 빠르게 전송해, 실시간 화상회의 등 가능하게 함. 서버를 거치지 않아 빠른 속도 (210820) P2P 통신은 중간자가 없다는 것이 아니라, 멀티캐스트 없이 1:1로 통신한다는 의미라고 함 기본적으로 udp 통신은 멀티캐스트를 지원하고, webRTC는 udp 통신을 하는데 멀티캐스트가 아닌 p2p 통신을 하는 것. STUN 서버에 의해 peer의 public IP주소와 Port를 알 수 있고, P2P 통신이 가능해진다. 그러나, 아래와 같은 문제가 있을 때 TURN을 사용 Symmetric NAT의 경우 문제: 패킷을 보내는 외부 서버마다 NAT 맵핑을 다르게 가져가는 것 두 Peer가 같은 NAT 환경에 있을 경우 동작 불가 HTTPS가 강제되는 요쇼이기 때문에 보안 또한 보장 TURN 서버(릴레이 서버) : STUN의 역할을 수행하지만, Peer간 직접 통신이 실패할 경우 TURN이 peer 사이에서 데이터 Relay 수행 직접 통신하지 않고 TURN이라는 중개서버를 통해 relay하는 방식. -&amp;gt; 엄격하게 말하면 P2P 통신을 포기하게 되는 것. 불가피하게 오버헤드가 발생한다. -&amp;gt; 최후의 수단으로 사용해야 한다. OWT-server Name Definition Portal The MCU component listening at the Socket.io server port, accepting signaling connections initiated by Clients, receive/send signaling messages from/to Clients. Client The program running on end-user’s device which interacts with MCU Server by messages defined in this documentation. Signaling Connection The signaling channel between Client and Portal established by Client to send, receive and fetch signaling messages. Room The logical entity of a conference in which all conference members (participants) exchange their video/audio streams, and where mixed streams are generated. Every room must be assigned with a unique identification (RoomID) in the MCU scope. User The service account defined in the third-party integration application. The user ID and user role must be specified when asking for a token. Participant The logical entity of a user when participating in a conference with a valid token. Every participant must be assigned with a unique identification (ParticipantID) in the room scope, and must be assigned a set of operation permissions according to its role. Token The credential when a particular participant requests to join a particular room. It must contain a unique identification, the hostname of the target portal which can be used to connect, and the checksum to verify its validity. Stream The object represents an audio and/or video media source which can be consumed (say, be subscribed, recorded, pushed to a live stream server) within a room. A stream can be either a participant published one which is called a Forward Stream, or a room generated one which is called a Mixed Stream. A stream object must be assigned with a unique identification (StreamID) in the room scope, Participants can select a particular stream to subscribe according to StreamID. A stream must also contain the audio information of the codec, sample rate, channel number, and video information about codec for Forward Stream or about codec, resolution, frame rate, key frame interval, quality level for Mixed Stream. Participants can determine whether the stream fulfill their expectation based on such information. Subscription The activity a participant consuming a stream, such as receiving a stream via a WebRTC PeerConnection, recording a stream to a MCU storage, pushing a stream to a live stream server. A unique identification (SubscriptionID) in the room scope must be assigned to the subscription once its request is accepted by MCU. Participants will use the identification to update/cancel/stop a specific subscription. Session The entity in which a real-time audio/video communication takes place. Typically, participants establish WebRTC sessions between a WebRTC client and MCU (accurately, the webrtc-agent) to publish or subscribe streams. Since a stream ID will be assigned when publishing a stream into a room and a subscription ID will be assigned when subscribing a stream (or a pair of stream if audio and video come from different source), the stream ID and subscription ID in these two cases are re-used to identify the corresponding session, and MCU must guarantee that the stream IDs and subscription IDs will not conflict within a room. Socket.io signalingFormatSignaling message : 서로 다른 네트워크에 있는 2개의 디바이스를 위치시키기 위해서는 각 디바이스의 위치를 발견하는 방법, 미디어 포맷 협의 필요. 이 프로세스를 Signaling이라고 함. Client -&amp;gt; Portal Client가 Portal과 연결되어 send/recv 할 준비가 되면, Client는 socket객체의 emit() 을 통해 Portal에게 모든 signaling message를 보내야 한다. Portal -&amp;gt; Client Portal에 Client가 연결되어 socket 객체가 send/recv 할 준비가 되면, Portal은 emit()을 통해 Client에게 모든 signaling mesage를 보내야 한다. Connection Maintenance Client Connects Portal은 Client의 연결을 받기 위해 각각의 socket.io 서버 포트를 listen할 수 있어야 한다. Secure socket.io 서버가 가능해지면, SSL certificate과 PK store path가 올바르게 정해져야한다. (portal.toml 의 config를 통해) Client Keeps Alive (refreshReconnectionTicket) Socket.io 서버는 keep-alive 메커니즘을 갖고있기 때문에 app level의 heart-beat는 불필요. 그러나, 서버가 죽는 경우를 대비해서 Client는 현재의 티켓이 만료되기 전에 주기적으로 reconnection 티켓을 refresh해야한다. Client Disconnects 서버 사이드에서의 연결된 socket.io 객체는 disconnect event를 받는다. 다음의 조건들이 만족된다면, disconnect event 이후에 reconnecting 타이머(Timer100)가 시작된다. Participant leaving 가 발생하지 않았을 때(의도적으로 나간게 아닐 때) Conenction이 mobile client로부터 초기화되었을 때 Client Reconnects RequestName : “relogin” RequestData : ReconnectionTicket 객체 ResponseData : base64-encoded ReconnectionTicket 객체(ResponseStatus가 “ok” 일 때) Reference)https://github.com/duan-xiande/owt-server/blob/master/doc/Client-Portal%20Protocol.mdhttps://wormwlrm.github.io/2021/01/24/Introducing-WebRTC.htmlhttps://developer.mozilla.org/ko/docs/Web/API/WebRTC_APIhttps://jomuljomul.tistory.com/category/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D%20%EA%B3%B5%EB%B6%80/WebRTChttps://github.com/duan-xiande/owt-server/blob/master/doc/Client-Portal%20Protocol.md" }, { "title": "CORS(Cross-Origin Resource Sharing)", "url": "/posts/CORS/", "categories": "Study, Network", "tags": "network, cors", "date": "2021-05-02 00:00:00 +0900", "snippet": "CORS란?: HTTP 헤더를 사용해 애플리케이션이 다른 origin 리소스에 접근할 수 있게, 다른 origin이 나의 resource에 함부로 접근하지 못하게 하기 위해 사용하는 메커니즘 정확하게는 CORS란, SOP(Same origin policy, 동일 출처 정책)에 의해 원래는 허용이 안되는 Cross origin 접근을 허용해주는 정책 javascript로 만든 크로스 오리진 요청에는 기본적으로 쿠키나 HTTP 인증같은 자격 증명(Credential)이 함께 전송되지 않는다. credential과 함께 전송되는 요청은 영향력이 강하기 때문에, javascript로 민감한 정보에 접근할 수 있기 때문 처음 전송되는(받는) Origin에 대한 요청은 cross-origin HTTP에 의해 처리됨. 필요 이유: 보안상의 이유 서비스하고 있지 않은 브라우저에서 세션을 요청해 획득한다면 악의적인 행동을 할 수 있음 Preflight ? 사전 전달 메시지, 이걸 통해 “허가”를 받게 되면 그때부터 실제 정보 요청 OPTIONS 메서드를 통해 브라우저에서는 Request가 허용된 도메인으로만 보내게 할 의무가 있다. server to server에선 cors가 필요 없다. 서버에서 요청을 보낼 때 http 헤더에 origin을 명시할 의무도 없다.SOP(Same Origin Policy): 동일 출처 원칙: 모르는 출처의 스크립트에서 사용자가 서버로 요청할 경우, 어떤 스크립트가 실행될지 모른다(XSS). 따라서, 동일한 출처의 브라우저에 대해서만 요청을 허가한다. 따라서, 브라우저에서는 Request가 허용된 도메인으로만 요청을 보내도록 할 의무가 있다.Origin과 domain의 차이 domain: 도메인(naver.com) origin:스킴, 도메인, 포트 e.g) https://naver.com:8080 정확한 문법 Origin: &amp;lt;scheme&amp;gt; &quot;://&quot; &amp;lt;hostname&amp;gt; [ &quot;:&quot; &amp;lt;port&amp;gt; ] 동작 방식 브라우저(크롬이)가 리소스 요청 시 헤더에 추가 정보를 담아 보냄 내 origin은 무엇이고, 어떤 메소드를 사용해서 요청을 할 것이고, 어떤 헤더들을 포함할 것인지 서버는 서버가 응답할 수 있는 origin들을 헤더에 담아서 브라우저에게 보냄 브라우저가 헤더를 보고 해당 origin에서 요청할 수 있다면 리소스 전송을 허용하고 만약 불가능하다면 에러를 발생 Simple request 일부 요청은 Preflight를 트리거하지 않는다. 다음의 조건들을 모두 만족하는 Simple Request 여야 한다. GET, HEAD, POST (데이터 변화시킬 위험 없는 안전한 메서드) POST의 경우 Origin 헤더를 포함해야 한다. GET, HEAD는 포함시킬 필요 없다. User Agent가 자동으로 설정한 헤더 + CORS-safelisted request 헤더 Content-type 헤더는 아래의 세개만 가능 application/x-www-form-urlencoded, multipart/form-data , text/plain e.g) preflight 트리거한 예제 main 요청은 Cross-Origin 요청이기 때문에 Origin: 이 붙는다. Post 메서드 요청 Content-type 이 application/xml 그런데, 사용자 정의 헤더이기 때문에 preflighted 처리.헤더 목록위의 예시 or MDN 자세한 예시 참고Request(서버에게) Origin : foo.com (나의 origin) Access-Control-Request-Method(preflight 과정에서) : 실제 요청에서 어떤 메서드를 사용할 것인지 Access-Control-Request-Headers(preflight 과정에서) : 실제 요청에서 어떤 header를 사용할 것인지Response(서버에서) Access-Control-Allow-Origin : foo.com (내가 허용한 origin) 브라우저가 해당 origin이 자원에 접근할 수 있도록 허용 혹은 *은 credentials이 없는 요청에 한해서 모든 origin에서 접근이 가능하도록 허용 Access-Control-Allow-Methods preflight요청에 대한 대한 응답으로 허용되는 메서드들을 나타냄 Access-Control-Allow-Headers preflight요청에 대한 대한 응답으로 실제 요청 시 사용할 수 있는 HTTP 헤더를 나타냄 Access-Control-Max-Age 또다른 preflight request를 보내지 않고, 얼마나 오랫동안 preflight요청이 캐싱 될 수 있는지 Access-Control-Expose-Headers 브라우저가 액세스할 수있는 서버 화이트리스트 헤더를 허용 Access-Control-Allow-Credentials Credentials가 true 일 때 요청에 대한 응답이 노출될 수 있는지를 나타냄 preflight요청에 대한 응답의 일부로 사용되는 경우 실제 요청을 수행 할 수 있는지를 나타냅니다. 간단한 GET 요청은 preflight되지 않으므로 자격 증명이 있는 리소스를 요청하면 헤더가 리소스와 함께 반환되지 않으면 브라우저에서 응답을 무시하고 웹 콘텐츠로 반환하지 않음 COR의 역사 한 사이트의 스크립트에서 다른 사이트에 있는 콘텐츠에 접근할 수 없다는 제약이 있었다. 따라서 hacker.com에서 gmail.com에 접근할 수 없었다. - 해커의 접근 방지 제약을 피하는 트릭: 제약 때문에 웹 페이지는 자유롭지 못했고, 웹 개발자들이 강력한 기능을 원하면서 트릭을 만들어 냄.트릭 Form 사용 : &amp;lt;form&amp;gt; 태그에 &amp;lt;iframe&amp;gt; 를 넣어 전송해 네트워크(GET, POST) 요청 그러나, 다른 사이트에서 &amp;lt;iframe&amp;gt; 의 콘텐츠를 읽는 것이 금지되었어서, 응답을 읽는 것 불가능했음 Script 사용 : &amp;lt;script&amp;gt; 태그에 src 속성값을 이용해 보내는 것 // 1. 날씨 데이터를 처리하는데 사용되는 함수를 선언function gotWeather({ temperature, humidity }) { alert(`temperature: ${temperature}, humidity: ${humidity}`);} // 2. 다음과 같은 script 태그를 만듦. 스크립트는 동적으로 생성let script = document.createElement(&#39;script&#39;);script.src = `http://another.com/weather.json?callback=gotWeather`;document.body.append(script); // 실행 결과gotWeather({ temperature: 25, humidity: 78 }); 리모트 서버에서 받아온 스크립트가 실행되면 gotWeather 함수가 호출됨. 이 함수는 현재 페이지에서 만들었기도 하고, 리모트 서버(weather.com)에서 받은 데이터도 있기 때문에 원하는 결과를 얻음. 위의 과정들을 거쳐, 명시적으로 cross origin 요청 허가를 알려주는 cors가 생겨나게 됨 Reference)모던 Javascript 튜토리얼 - https://ko.javascript.info/fetch-crossoriginhttps://developer.mozilla.org/ko/docs/Web/HTTP/CORShttps://hannut91.github.io/blogs/infra/corshttps://velog.io/@josworks27/CORS-%EA%B8%B0%EC%B4%88-%EA%B0%9C%EB%85%90https://zzossig.io/posts/web/what_is_cors/https://medium.com/@woody_dev/cors-cross-origin-resource-sharing-cea401fb79b6" }, { "title": "REST API resource 표현방식", "url": "/posts/Resource_%ED%91%9C%ED%98%84_%EB%B0%A9%EC%8B%9D/", "categories": "Study, REST API", "tags": "rest, rest api", "date": "2021-05-01 00:00:00 +0900", "snippet": "1. document 1개의 인스턴스 나타냄 /users/{id} 객체 인스턴스, DB의 record와 유사한 개념 일반적으로 id를 통해(유일한 것) GET, PUT, DELETE, PATCH에 사용2. collection resource의 묶음 일반적으로 POST, GET(collection)에 사용 truncate 해야하는 경우 DELETE도 사용될 것 같음 /users 3. store client 입장에서의 resource 저장소. 참조 블로그에선 “장바구니” 라고 표현 API로 client가 resouce를 생성, 삭제를 자유롭게 약간 hash(key - value)처럼 생각 /users/{id}/my-users 4. controller Client 입장에서 Server의 메서드를 실행하는 느낌 CRUD 로 구분이 안될만한 것들에 수행하면 될 듯 RPC call 대신에 이걸 사용하면 rest의 단점을 보완가능, RPC 커버 가능? REST 특성상 명사를 사용하도록 권장하지만, 여기서는 function을 실행하는 느낌이기 때문에 동사를 사용해도 될 것 같다고 함 /users/{id}/doSomething Reference)https://sabarada.tistory.com/28http://storyg.co/rest-api-explain" }, { "title": "Rabbitmq와 kafka 간단 비교", "url": "/posts/RabbitMQ_kafka/", "categories": "Study, RabbitMQ", "tags": "rabbitmq, message queue", "date": "2021-04-30 00:00:00 +0900", "snippet": "공통점 메시지 큐잉 시스템. 따라서 메시지 큐의 장점을 가진다. 로그 시스템을 구축하기 위한 좋다고 한다. API 송수신과 비동기처리를 할 수 있다. 분산 처리 가능메시지 큐의 장점 비동기 처리로 Application과 분리되어 동작한다. 일부 실패하더라도 전체에 영향이 없고, 회복이 가능하다. 작업 처리 확인 가능하다. RabbitMQ의 경우 대시보드도 잘 지원된다. 처리율: 다수 process에 대한 메시지 처리 가능하다.RabbitMQ 구성이 쉽고 편하다. 비동기 가능하며 처리율이 높다. 성숙도: 오래되어 레퍼런스가 많고 편리한 도구가 많다. 분산이 필요한 Traffic을 처리할 것 아니라면 Kafka말고 간단하게 이걸 써도 좋다.Kafka Subscription, 비동기식 pulling 방식으로 고성능 분산처리에 효율적kafka vs rabbitMQ rabbitMQ : broker가 consumer에 메시지를 push kafka : consumer가 broker로부터 메시지를 pull하는 방식 메시지를 disk에 저장하기 때문에 이러한 방식이 가능하다. " }, { "title": "정규표현식(pattern matching)", "url": "/posts/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(pattern_matching)/", "categories": "Study, Develop", "tags": "regex", "date": "2021-04-30 00:00:00 +0900", "snippet": ": 문자열 검색, 치환 or 회원가입, 이력서 양식 등에 validation을 위해 이용표준 문법 .: 임의의 한 문자.(아무거나) [] : 문자클래스 [ 와 ] 사이의 문자 중 하나를 선택 [^ ] : 문자클래스 내부를 제외한 나머지. ​ e.g. [^a-z] : a~z를 제외한 모든 것 ^ : 처음 (행의 처음) $ : 끝 () : 하위식. 여러 식을 묶을 수 있음 ​ &quot;abc|adc&quot; 와 &quot;a(b|d)c&quot; 는 같은 의미를 가짐 \\n : 일치하는 n번째 패턴 (1 &amp;lt;= n &amp;lt;= 9) * : 0회 이상. ​ &quot;a*b&quot; == b, ab, aab, aaab, … + : 1회 이상 {m, n} : m회 이상 n회 이하 ? : 앞 문자가 0 or 1 예시1) 모든 숫자 : ^[0-9]*$2) 모든 영문자 : ^[a-zA-Z]*$3) 모든 한글 : ^[가-힣]*$4) 모든 영어와 숫자 : ^[a-zA-Z0-9]*$Regex test: https://regexr.com/ 를 통해 테스트Reference)https://ko.wikipedia.org/wiki/%EC%A0%95%EA%B7%9C_%ED%91%9C%ED%98%84%EC%8B%9Dhttps://highcode.tistory.com/6https://uznam8x.tistory.com/62" }, { "title": "DTO(data transfer object)에 관해서", "url": "/posts/DTO%EC%97%90_%EA%B4%80%ED%95%B4/", "categories": "Study, Spring boot", "tags": "spring, spring boot, 스프링, 스프링부트", "date": "2021-04-27 00:00:00 +0900", "snippet": ": DTO란, 비즈니스에 종속되어있고, Layer간 데이터 전송이 목적인 일종의 자료구조 역할을 수행하는 객체DTO가 필요한 이유 일단 필요 정도는 프로젝트 규모에 따라 다를 것 같다. 큰 프로젝트일수록 DTO가 잘 분리되어 있다면 복잡도를 줄일 수 있고 변화에 용이할 것 같다. DTO와 엔티티를 분리하는 이유: 비즈니스의 변경에 따라 Entity와 독립적으로 변경될 가능성이 항상 있기 때문이다.DTO 사용과 위치: 일단 표준은 없어서 명확히 DTO 위치에 정해진 것도 없고 상황에 따라 다양하게 사용될 수 있다.사용되는 경우 컨트롤러와 서비스가 DTO를 주고받고 서비스에서 Entity화 (repository는 DTO가 아닌 Entity에 의존적이기 때문) e.g) fooEntity = FooDto.toEntity(); 서비스가 Entity를 DTO로 변환시켜 컨트롤러로 반환하기 e.g) return FooDto.of(fooEntity); DTO는 일반적으로 원시 타입을 사용한다. 어차피 JSON형태로 앞단에 전달하니까 원시 타입을 사용한다. Entity에는 nullable을 표현 할 수 있는 래퍼타입을 권장한다.Reference)https://xlffm3.github.io/spring%20&amp;amp;%20spring%20boot/DTOLayer/https://dbbymoon.tistory.com/4https://github.com/HomoEfficio/dev-tips/blob/master/DTO-DomainObject-Converter.md" }, { "title": "Domain, entity, VO", "url": "/posts/Domain_Entity_VO/", "categories": "Study, Spring boot", "tags": "spring, spring boot, 스프링, 스프링부트", "date": "2021-04-23 00:00:00 +0900", "snippet": "Domain 내가 개발하고자하는 관심 영역 일반적으로 Entity, Repository(interface) 도메인 로직 등이 있을 수 있다.Entity 식별자를 갖는다. DB 말고도 객체지향적인 개념으로도 쓰인다. 객체지향에서의 메시지를 생각해보면, 엔티티에 관련된 로직을 포함할 수 있다.VO(value object) 값 자체가 의미가 있다..? == 어느 상황에도 동일하게 취급 되는 것이 핵심 e. g. 1) 서비스에서 사용하는 색상클래스 RED가 new Color(255,0,0); 이고, 이 서비스 내부에서 red 색상을 사용하고자 할 때 Color.RED 를 사용하면 되는 것과 같은? e. g. 2) 돈으로 따지면 100원은 어딜가도 100원. 관련 value와 관련된 로직을 가질 수 있다. 값 자체이기 때문에 read only로 가져가는 것이 보통이다. DTO는 전달 자체에 초점을 두는 것과 VO에서는 차이가 있다.Reference)https://multifrontgarden.tistory.com/186https://velog.io/@gillog/Entity-DTO-VO-%EB%B0%94%EB%A1%9C-%EC%95%8C%EA%B8%B0" }, { "title": "세션 유지 방법 - 토큰 기반 JWT(Json Web Token)", "url": "/posts/%EC%BF%A0%ED%82%A4_%EC%84%B8%EC%85%98_3_%ED%86%A0%ED%81%B0/", "categories": "Study, Network", "tags": "network, 쿠키와 세션", "date": "2021-04-23 00:00:00 +0900", "snippet": "특징 브라우저에 저장하기 때문에 서버 리소스에 부담 없다. 서버 확장성(Scalability): Scaling시에도, 서버는 Stateless하기 때문에 토큰 Verification만 수행하면 된다. 보안성: Verification을 수행하는데 Server의 비밀키가 사용된다. 확장성(Extensibility): 로그인 분야가 사용되는 영역의 확장을 의미한다. OAuth같은 경우 Google, Facebook과 같은 소셜 계정을 이용해 다른 곳에 로그인 가능하다. CORS 단일 도메인에서만 처리할 수 있도록 했던 세션에서는 CORS문제가 있다. 서비스 규모가 커지면 다른 디바이스나 도메인과 호환을 하게 된다. 이 때 토큰을 사용하게 되면 다른 도메인에서도 토큰의 유효성 검사를 진행한 후에 토큰만 유효하다면 정상처리하면 된다. 이런 구조를 통해 assets 파일(Image, html, css, js 등)은 모두 CDN에서 제공하고, 서버 측에서는 API만 다루도록 설계할 수 있다고 한다(?) 클라이언트가 상태를 들고있다는 점은 쿠키와 같지만, 토큰의 시그니처가 서버의 secret key로 암호화가 되어있다는 점이 다르다.고려하고 있어야 할 점 저장할 필드에 따라 Token이 커질 수 있다. - 일반적으로 세션ID보다 길다고 함 XSS 공격으로 토큰이 탈취 당할 수 있어 민감한 정보 포함시키지 않아야 한다. 클라이언트 컴퓨터가 탈취(해킹)당할 경우 문제 액세스 토큰과 리프레시 토큰으로 해결 JWT : 서버측에 token blacklist 를 관리하게 될 경우 서버쪽 메모리를 사용할 가능성이 있다.Access Token, Refresh Token: 클라이언트 컴퓨터가 탈취당할 경우를 대비 유효기간이 짧은 액세스 토큰에서 유효기간이 다 되면 유저에게 ID/PW를 물어보는게 아니고 refresh token을 통해 서버에게 액세스 토큰을 재발행 받는다. 만약 액세스 토큰 유효기간이 다되고, refresh로 재발행 받으려 할 때 client가 탈취당한걸 서버가 알고있을 경우, 해당 id로는 액세스 토큰을 발급받지 못하도록 막음 이 방식의 단점 액세스 토큰 재발행 시 매번 서버에 접속 -&amp;gt; 부하 액세스 토큰 유효기간 끝날때까지는 여전히 무방비 과정 유저 로그인 시 Signed token(액세스 토큰)을 생성 후 암호화 할 secret key를 통해 암호화, 클라이언트에게 발급 클라이언트는 Token을 브라우저의 쿠키나 웹 스토리지에 저장한다. HTTP 요청 시 헤더에 토큰을 넣어 보낸다. 서버는 전달받은 요청메시지 헤더의 토큰의 시그니처를 서버가 들고 있는 secret key를 통해 Verification (복호화 후 조작 여부나 expired 확인) 한 뒤, 유저에게 권한 인가해줌.구조 Header 헤더 토큰 타입(JWT)과 해싱 알고리즘(SHA256 or RSA)을 지정. Payload 정보 토큰에 담을 정보(클레임)가 들어있음 Signature 서명(Verification에 사용) 헤더의 인코딩 값과 페이로드의 인코딩 값을 합친 후 서버의 비밀 키로 해쉬 Reference)https://velopert.com/2350https://developer88.tistory.com/325https://jins-dev.tistory.com/entry/Session-%EA%B8%B0%EB%B0%98-%EC%9D%B8%EC%A6%9D%EA%B3%BC-Token-%EA%B8%B0%EB%B0%98-%EC%9D%B8%EC%A6%9D" }, { "title": "디자인 패턴 - 퍼사드 패턴", "url": "/posts/%EB%94%94%EC%9E%90%EC%9D%B8_%ED%8C%A8%ED%84%B4_%ED%8D%BC%EC%82%AC%EB%93%9C%ED%8C%A8%ED%84%B4/", "categories": "Study, Software Engineering", "tags": "software enginerring, 소프트웨어 공학, 디자인 패턴", "date": "2021-04-22 00:00:00 +0900", "snippet": "Facade pattern (퍼사드 패턴): 스프링 부트 프로젝트에서 서비스간 결합도를 줄이고, 퍼사드 계층에서 모든 것들을 호출한다. 이렇게 처리함으로써 view layer과 서비스를 더 분리할 수 있고, 두 레이어를 연결하는 인터페이스를 퍼사드 계층이 수행한다. 복잡한 여러개의 서비스로직을 한군데(퍼사드)에 묶어 하나의 흐름으로 처리 트랜잭션 처리 관점에서, 영속성 컨텍스트는 이 레이어까지 라이프사이클을 갖게 된다. 이 곳에서 적절히 진짜 객체를 만들어 view 계층에 전달하면 된다.트레이드 오프: 레이어가 하나 더 늘어 오히려 복잡해질 수 있다. 필요한 적절한 때를 고려하는 것이 좋을 것 같다." }, { "title": "코드 깔끔하게 작성하기", "url": "/posts/%EC%BD%94%EB%93%9C_%EA%B9%94%EB%81%94%ED%95%98%EA%B2%8C_%EC%9E%91%EC%84%B1%ED%95%98%EA%B8%B0/", "categories": "Study, Develop", "tags": "develop, code", "date": "2021-04-20 00:00:00 +0900", "snippet": "소프트웨어 개발 원칙 세가지1. DRY (Don’t Repeat yourself) &amp;lt;-&amp;gt; WET(Write Every Time, Write Everything twice, Waste Everyone’s Time) 반복되는 것을 피하자 반복된 코드에서 로직의 변경사항이 발생할 때 모든 곳을 변경해야 하고, 한군데를 빠트리면 더 문제상황 로직, 지식, 의도, 비즈니스 로직 이 모든것이 중복되지 않도록(광범위한 범위)2. KISS(Keep It Simple, Stupid): 심플하게 만들었을 때 최고로 잘 동작함(불필요한 복잡성을 피하자) 가독성 있는 심플한 코드 메소드 네임, 변수를 가독성있게, 하나의 기능만을 하나의 책임만 담당하는 클래스 UI에서는 비즈니스 로직을 빼고 하나의 서비스에서는 하나의 기능을 담당하는 개별적인 서비스3. YAGNI (You Ain’t Gonna Need It) 지양할 것: 필요하지 않는 기능, 지금 당장 사용되지 않는 기능, 지나치게 미래지향적인 기능 지향: 클린하게, 변경 쉽게, 유지보수 잘할수있도록Reference)https://youtu.be/jafa3cqoAVM (드림코딩 엘리)" }, { "title": "세션 유지 방법 - 세션(Session)", "url": "/posts/%EC%BF%A0%ED%82%A4_%EC%84%B8%EC%85%98_2_%EC%84%B8%EC%85%98%EA%B3%BC_%EC%BF%A0%ED%82%A4_%EC%B0%A8%EC%9D%B4/", "categories": "Study, Network", "tags": "network, 쿠키와 세션", "date": "2021-04-14 00:00:00 +0900", "snippet": ": 일정기간동안 한 사용자의 상태를 유지시키는 것(클라이언트를 구분하는 수단).특징 쿠키는 브라우저나 하드에 저장하는데, 세션은 서버에 저장한다. Session Id(유일한 값인 세션 키값. 개발자 도구에서 JSESSIONID)를 쿠키에 저장하고, 필요할 때마다 서버에 저장된 데이터를 이 키로 받아온다. 세션: HTTP 프로토콜에서 요청, 응답이 오고가면 연결이 끊어져 다음 요청이 어떤 사용자가 보낸지 모른다. 이 때 정보 유지를 위해 이 세션이라는 것이 필요하다.JWT: 세션은 서버 처리를 필요로 하기 때문에 최근 JWT라는 토큰 기반 인증 방식을 많이 사용한다.세션의 절차 클라이언트가 서버에 리소스 요청하면 HTTP 헤더의 쿠키에서 Session Id를 확인한다. Session Id가 없으면 Set-Cookie를 통해 새로 발행한 Session Id를 보낸다. 클라이언트는 세션 Id를 브라우저의 쿠키에 저장하고, 다시 리소스 요청 시 HTTP request 헤더에 Session Id를 포함하여 원하는 리소스를 요청한다. 서버는 클라이언트마다 구분이 되는 이 Session Id를 통해 세션을 찾아 클라이언트의 상태 정보를 파악하고 적절한 응답을 보내준다.쿠키와 비교했을 때 세션의 장단점장점 보안: 실제 세션정보는 서버에 저장하기 때문에 보안에 유리하다. 하나의 쿠키 당 4KB(=4096byte) 저장할 수 있는데, 세션을 사용하면 그냥 session Id만 부여해주고 세션 유지에 필요한 정보는 서버 리소스이기 때문에 제한은 없다.단점 서버에 별도 저장 공간 필요하다. 서버 성능 저하의 요인이 될 수 있다. 세션 서버: LB 상황에서도 처리하기 어려운데, 이 때는 하나의 서버에 저장해 Sticky session 방식으로 통신하도록 구성하거나 세션서버로 Redis 같은 별도 서버를 둔다. CORS: 세션 관리 시 단일 도메인 및 서브 도메인에서만 작동하도록 되어있어, 여러 도메인에서 관리하는 것은 번거롭다고 한다. 클라이언트에 저장할 때 처럼 쿠키를 전부 보내진 않지만, 여전히 보안상 문제 있다.보안상 문제: 하이재킹의 경우: HTTP요청을 가로채, 사용자의 session id를 알아내면, 해커는 여전히 해당 session id로 session을 얻을 수 있음. 해결 방법 1. HTTPS를 사용해 요청 자체를 탈취해도 안의 정보를 얻기 어렵도록 하기 2. 세션에 유효기간을 주는 방법Reference)https://tansfil.tistory.com/58https://velog.io/@junhok82/%EB%A1%9C%EA%B7%B8%EC%9D%B8%EC%9D%80-%EC%96%B4%EB%96%BB%EA%B2%8C-%EC%9D%B4%EB%A3%A8%EC%96%B4%EC%A7%88%EA%B9%8CCookie-Sessionhttps://hahahoho5915.tistory.com/32https://interconnection.tistory.com/74https://nesoy.github.io/articles/2017-03/Session-Cookiehttps://tristan91.tistory.com/521" }, { "title": "HTTP 기초", "url": "/posts/HTTP%EA%B8%B0%EC%B4%88/", "categories": "Study, HTTP", "tags": "http", "date": "2021-04-14 00:00:00 +0900", "snippet": "HTTP란? 웹에서 쓰이는 통신 프로토콜(상호간에 정의된 규칙) HTTP 트랜잭션(요청 응답) 속에서 URI, 요청 리소스, 메소드, 메시지 상태코드, MIME타입(text/html) 등을 규정하는 프로토콜 TCP / IP 프로토콜의 Application 레이어에서 동작 네트워크 통신에서 대중적이고 신뢰성 있는 핵심적 세부사항은 TCP가 맡아서 함 Stateless 프로토콜(상태가 없음) 데이터 요청이 독립적으로 관리(이전 데이터 요청과 다음 요청은 관련이 없음) 하기 때문에, 쇼핑 장바구니 기능처럼 한 사용자가 일관된 방식으로 요청을 할 때 문제가 될 수 있음. 이걸 하기 위해 HTTP쿠키가 상태가 있는 세션을 만들어준다. 헤더 확장성을 사용해, 각각의 요청들에 대한 세션을 만들도록 HTTP 쿠키가 추가 됨. 서버에서 사용자의 웹 브라우저에 쿠키(데이터 조각)를 전달하고, 브라우저는 그 데이터를 브라우저에 저장. 추후 재 요청시 해당 데이터를 함께 전송. 로그인 시 Token 정보를 이거로 활용 가능 Client-Server 구조 포트 80을 디폴트로 사용 기본적으로 신뢰성 있는 TCP 표준에 의존 클라이언트, 서버 통신 전에 TCP 연결을 해야함. 3 way, 4 way handshake 여러 요청을 보내야 할 때 각 요청마다 연결을 열면 비효율 그러나, 계속 연결을 유지하는 것은 그것대로 또 리소스 낭비 HTTP/1.1에서는 지속적인 연결을 도입 HTTP/2.0에서는 단일 연결 상에서 다중 전송 할 수 있도록 함. Simple HTTP 메시지들은 사람이 읽고 이해하기 편함 GET / HTTP/1.1Host: developer.mozilla.orgAccept-Language: fr HTTP 기반 시스템의 구성요소 클라이언트 요청은 사용자 에이전트(대부분 브라우저)에 의해 전송됨. 서버는 이에 따른 응답을 보냄 요청과 응답 사이에는 다양한 개체들 Proxy : 게이트웨이 or 캐시 역할 수행 클라이언트: 사용자 에이전트 사용자를 대신해 HTTP 요청을 만들어준다. -주로 브라우저에 의해 수행됨 하는 일(여러 종류의 에이전트가 존재) 페이지의 html 문서 요청 페이지 내 리소스들을 표시하기 위한 css에 해당하는 추가 요청 받은 리소스 혼합 웹 페이지란? 하이퍼텍스트 문서 사용자가 사용자 에이전트를 제어하고, 새로운 웹 페이지를 가져오기 위한 실행(마우스 클릭) 될 수 있는 링크 이러한 지시사항을 변환하고 http응답을 해석해 사용자에게 명확한 응답 제공 웹 서버 통신채널 반대편에 클라이언트 요청에 대한 문서(정적)를 제공하는 서버 LB 혹은 캐시, DB 등의 정보를 얻고, 문서를 생성하는 소프트웨어의 복잡한 부분을 공유하는 서버의 집합을 웹 서버라고 하기에 단일 기계라고 말 함. 프록시(Proxy) 웹 브라우저와 웹 서버 사이에 존재, 어플리케이션 레벨에서 동작 많은 곳에서 캐싱 기능을 장점으로 말함. LB, 필터링, 인증, 로깅과 같은 다양한 기능 또한 제공 forward, reverse(보안을 위해) 프록시라는 것 존재 리버스 프록시에선 실제 서버를 내부망으로 가려놓고, 프록시를 통해 통신. 프록시 문제발생 혹은 해킹을 당해도 실제 서버는 문제 없음. 캐시 자주 요청하는 것의 사본을 저장해두고, 클라이언트가 재요청하면 멀리 떨어진 웹 서버 말고 여기서 문서를 받는다. 따라서, 캐시는 프록시의 일종게이트웨이: 다른 애플리케이션과 연결된 특별한 웹 서버 다른 서버들의 중개자 HTTP 트래픽을 다른 프로토콜로 변환 스스로가 리소스를 갖고 있는 진짜 서버인 것 처럼 요청을 다룸 - 따라서 클라이언트 입장에선 게이트웨이와 통신하는걸 알아채지 못함 e.g) HTTP/FTP 게이트웨이는 FTP URI에 대한 HTTP 요청을 받아들인 뒤 FTP 프로토콜을 이용해 문서를 가져옴터널 데이터를 열어보지 않고 그대로 전달해주는 HTTP 애플리케이션 e.g) 암호화된 SSL 트래픽을 HTTP 커넥션으로 전송해, 웹 트래픽만 허용하는 사내 방화벽을 통과시키는 것Reference)HTTP 완벽 가이드https://developer.mozilla.org/ko/docs/Web/HTTP/Overview#http_%EA%B8%B0%EB%B0%98%EC%8B%9C%EC%8A%A4%ED%85%9C%EC%9D%98%EA%B5%AC%EC%84%B1%EC%9A%94%EC%86%8C" }, { "title": "Shell과 Kernel", "url": "/posts/Shell_Kernel/", "categories": "Study, Linux", "tags": "linux, 리눅스", "date": "2021-04-11 00:00:00 +0900", "snippet": ": 터미널(Shell)에 CLi를 입력하면 쉘은 Kernel에게, Kernel은 하드웨어에게 전달 사람이 받는(보는) 것은 위의 과정과 역순으로 전달커널: 하드웨어와 가장 가까이 있는 프로그램 “커널을 통해 하드웨어 제어” HW : CPU, 메모리(RAM), Disk 따라서, 함부로 건드리면 안됨쉘: 사용자가 선호하는 쉘을 선택해 사용하고 커널을 제어할 수 있게 됨 echo $0 을 통해 해당 터미널이 어떤 쉘을 사용하는 지 알 수 있음. bash, zsh 등의 명령어 해석기 둘은 부모가 같고 비슷함. /bin (root디렉토리 하위의 bin 디렉토리)에 존재 쉘 스크립트란?: 순차적으로 실행되어야 할 명령의 순서(각본) 해당 명령어 셋을 재사용 할 수 있음 .sh 파일 우리가 쉘에서 사용하는 많은 명령어들이 실제로는 쉘 스크립트처럼 동작함 스크립트 파일은 #!/bin/bash 로 시작 이 밑의 line들은 bash에 의해 해석되어야 한다 라는 의미. 쉘 스타트업 스크립트 alias l = &#39;ls -al&#39; : ls -al의 별명을 l로 만들어 준 것 bash에 무엇을 실행할지 코드가 있음.Reference)https://opentutorials.org/course/2598/14203https://reakwon.tistory.com/135" }, { "title": "리눅스 Permission", "url": "/posts/Permission/", "categories": "Study, Linux", "tags": "linux, 리눅스", "date": "2021-04-11 00:00:00 +0900", "snippet": ": 어떠한 사용자가 파일, 디렉토리에 대해 Read, Write, Execute를 할 수 있게 / 없게 하는 것Access mode$ ls -al-rw-rw-r-- 1 joowon joowon 0 Jul 12 12:34 example.txtrw-rw-r-- rw- : owner의 권한 rw- : group의 권한 r-- : other의 권한(운영체제의 다른 모든 사용자들)r(read), w(write), x(exec) 세 가지 권한Change Mode: chmod 777 과 같은 CLI로 권한 변경 가능 4: read 2: write 1: execute 0: 아무것도 없음 e.g ) chmod 777 example.txt 혹은 u-r / o+w 와 같은 옵션을 주어서 e.g) chmod o+r example.txt e.g 2) chmod u-w example.txt e.g 3) chmod -R o+w example-dir (디렉토리에 대해 recursive하게) 디렉토리 실행권한: cd 명령어로 들어갈 수 있는가? 쓰기권한: 해당 디렉토리 내부 내용을 바꿀 수 있는가?Reference)https://opentutorials.org/course/2598/14190" }, { "title": "Class diagram", "url": "/posts/%ED%81%B4%EB%9E%98%EC%8A%A4_%EB%8B%A4%EC%9D%B4%EC%96%B4%EA%B7%B8%EB%9E%A8/", "categories": "Study, Software Engineering", "tags": "software enginerring, 소프트웨어 공학", "date": "2021-04-10 00:00:00 +0900", "snippet": " Generalization 상속 관계 A -&amp;gt; B : A가 B를 상속 Realization Interface에 정의된 메서드를 오버라이딩해 구현한 것 이라고 생각하면 됨 A -&amp;gt; B : A는 B를 실체화 혹은 구현한것 Dependency A객체가 B 객체를 가지고 있을 때 A가 B에 의존관계를 가지게 됨 A -&amp;gt; B public class A { public String foo(B b) { ... };} Association 다른 객체의 참조를 가짐. 방향성이 없다 -&amp;gt; 누가 누구를 참조할지 명시를 하지 않는 것 모든 가능성에 대해 생각 할 것 public class A { private List&amp;lt;B&amp;gt; b;} Dependency와 Association의 차이 Dependency 클래스 A가 클래스 B의 메서드를 가지고 있음 클래스 B를 메서드의 인자로 받음 Association 클래스 A가 클래스 B를 멤버 “변수”로 가짐 Diredted Association 방향성을 가짐 바로 위의 예시에서 A -&amp;gt; B &amp;lt;&amp;lt;List&amp;gt;&amp;gt; 혹은 * , 혹은 속성을 같이 명시하면 좋음 Aggregation 보다 특수한 Association. 코드 level에서는 큰 차이가 보이지 않음 “집합”이라는 개념이 추가되었으나 공식문서에서도 명확한 정의 없음 따라서 많은 곳에서 웬만하면 지양해야 한다고 함 Composition Aggregation과 비슷한데 좀더 강한 집합. whole이 part의 생명주기를 책임진다. Reference)https://en.wikipedia.org/wiki/Class_diagramhttps://www.nextree.co.kr/p6753/https://morm.tistory.com/88" }, { "title": "Port (포트)와 포트포워딩", "url": "/posts/%ED%8F%AC%ED%8A%B8_%ED%8F%AC%ED%8A%B8%ED%8F%AC%EC%9B%8C%EB%94%A9/", "categories": "Study, Linux", "tags": "linux, 리눅스", "date": "2021-04-10 00:00:00 +0900", "snippet": " naver 도메인에 포트 언급 없이 혹은 80 / 443 포트로 접근하면 자연스럽게 접근이 되지만 8000과 같은 포트로 접근하면 되지 않는다. CLI 기준 -p 뒤에 오는 숫자 : ssh -p 22 ubuntu@192.168.156.147 서버에는 0~65536 port 존재 0~1024는 well known port(표준처럼 사용 - 특별히 명시하지 않아도 가능) 웹은 80으로, ssh는 22로 기본 포트가 정해져있다.(각 서버는 해당 포트에서 대기하고 있다) 따라서, 그냥 따로 포트번호를 적지 않으면 정해진 포트로 접속 /etc/ssh/ssh/sshd_config에서 ssh 기본 포트 변경 가능 포트 포워딩: 특정 포트로 접속이 들어오면 그 접속을 특정한 IP(컴퓨터)로 전달한다.필요한 이유?: 외부에서 공유 아이피를 통해 공유기에 접근은 가능하지만, 그 내부의 컴퓨터는 사설 아이피를 사용하므로, 해당 서버에 IP로 접근을 할 수 없기 때문내부에서 공유기 IP에 접근하기: 내부에서만 통용되는 Default gateway에 접근하면 됨 나의 IP: ip addr, ifconfig 를 통해 디폴트 게이트웨이: ip route (네트워크 설정에서 “기본 라우팅”) 접근할 수 있는 경우에만 가능.(회사, 학교 같은 곳에선 일반적으로 불가능) Reference)https://opentutorials.org/course/2598/14470" }, { "title": "유닉스 디렉토리의 구조", "url": "/posts/%EC%9C%A0%EB%8B%89%EC%8A%A4_%EB%94%94%EB%A0%89%ED%86%A0%EB%A6%AC%EA%B5%AC%EC%A1%B0/", "categories": "Study, Linux", "tags": "linux, 리눅스", "date": "2021-04-10 00:00:00 +0900", "snippet": ": 프로그램 성격에 따라 정해져있는 이름의 디렉토리에 위치하는 규칙root 디렉토리 (/$): 홈에서 / 디렉토리로 들어가면 나오는, 유닉스 계열 시스템의 디렉토리들의 Rootbin: 사용자들이 사용하는 명령들 위치 이 디렉토리에 bash, nano, pwd, ps, ls, cd, 등 사용자들이 사용하는 것들이 위치 bin == binary(이진수) 줄임말 실행 가능한 프로그램을 주로 바이너리 라고 부른다. sbin: 시스템 바이너리 프로그램들 reboot, shutdown, halt 등 컴퓨터를 끄거나, 재부탱하거나 등 시스템을 관리하기 위한 목적 Root 사용자. (일반 사용자의 명령들은 bin에) etc: Configuration file들. 운영체제, 이미 설치된 프로그램의 설정에 관한 설정파일들이 여기 있음var: 변할 수 있는 파일들 log 파일과 같이 내용이 고정되어있지 않고, 증가되거나 바뀔 수 있는 파일들이 위치 bin, sbin, etc라는 디렉토리들은 바뀌지 않음(직접 설정하기 전까진) tmp:임시 파일들. 컴퓨터 리부트 시 자동으로 삭제가 됨home: 현재 사용자의 디렉토리 ~ 디렉토리와 같다. 어디서든 home으로 가고싶을 때 cd ~opt: 경우에따라 디렉터리를 지정해야 할 때. 대충 애매할 때usr: 유저 프로그램들이 저장 되었었음. /bin과 /usr/bin 가 구분 - 약간 레거시의 느낌. 설치하는 프로그램들은 /usr/bin에, 기본적으로 unix 계열의 형태로 제공 되는 것은 /bin에 현재의 유저 프로그램들은 /home/에 위치하게 되면서 위의 두가지 이유로 더이상 무의미해졌다고 함Reference)https://opentutorials.org/course/2598" }, { "title": "Daemon, Service", "url": "/posts/Daemon_Service/", "categories": "Study, Linux", "tags": "linux, 리눅스", "date": "2021-04-10 00:00:00 +0900", "snippet": ": 항상 켜져있어야 하는 것 웹 브라우저에 무언가를 쳤을 때 응답을 웹 서버에서 줄 수 있어야 한다. 언제 브라우저 요청이 올 줄 모른다. 따라서 웹 서버는 항상 켜져있어야 하는 데몬 or 서비스 /etc/init.d 디렉토리에 데몬 프로그램 위치한다. 일반적으로 프로그램을 켜는 것과는 다르다. sudo service apache2(예) start / stop 위의 CLI로 실행한 서비스는 ps aux를 통해 확인 가능.이전에 redis와 rabbitMQ가 계속 커져있던 이유는 당시의 그것들이 데몬으로 켜져있었어서 CLI 환경 기준 /etc/rc3.d로 가서 ls -l 을 해보면, 최근에 지웠던 redis와 rabbitmq 확인 가능 GUI기준 rc5.d라고 함 각 서비스에 대해 링크들이 걸려있음을 확인 가능 (-&amp;gt;)Reference)https://opentutorials.org/course/2598" }, { "title": "CLI를 사용하는 이유", "url": "/posts/CLI%EB%A5%BC_%EC%82%AC%EC%9A%A9%ED%95%98%EB%8A%94_%EC%9D%B4%EC%9C%A0/", "categories": "Study, Linux", "tags": "linux, 리눅스", "date": "2021-04-10 00:00:00 +0900", "snippet": "CLI 사용 이유? 일단 GUI보다 비용을 적게 쓴다. GUI방식은 사용성 증대를 위해 에너지를 사용하기 때문 순차적 실행이 가능해진다. “A 하고 B 하고 C 해라” Pipelining이 가능해진다. A(라는 명령, 프로그램, 프로세스)의 결과를 B의 입력으로, B의 결과를 C의 입력으로 순차 실행 (;) 순차적으로 처리할 명령어(행위)들을 한번에 정의해 시킬 수 있다. ​ -&amp;gt; A를 수행하고, B를 수행하고, C를 수행해라 e.g) mkdir my-dir; cd my-dir; ls 만약 이 예시가 아주 오래 걸리는 일이었다면? GUI방식이라면 사람이 직접 여러 태스크를 수행해야 할 것. CLI방식이라면 중간과정에서 사용자가 이걸 모니터링하고 있지 않아도 된다. Pipelining 순차적으로 처리하면서, 그 결과로 무언가를 또 수행할 때 |를 통해 파이프를 구분 e.g) ls --help | grep sort ls로 받은 결과를 파이프로 연결해, grep을 수행(sort 포함 행만을 뽑아냄) e.g) ls --help | grep sort | grep file 위의 결과 중에서 file도 포함하는 것을 뽑아냄 netstat -nap | grep LISTEN Reference)https://opentutorials.org/course/2598/14190" }, { "title": "리눅스와 프로세스", "url": "/posts/%EB%A6%AC%EB%88%85%EC%8A%A4_%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4/", "categories": "Study, Linux", "tags": "linux, 리눅스", "date": "2021-04-09 00:00:00 +0900", "snippet": "하드웨어 관점 프로세스 Disk(스토리지), RAM(메모리), CPU(프로세서) 디스크: 가격 낮고, 용량 높고, 속도 느림 메모리: 가격 비싸고, 용량 낮고, 속도 빠름 CPU는 아주 빠르기 때문에 느린 디스크를 이용하기보다 빠른 메모리에 필요한 만큼 적재해서 사용 e.g) 커맨드 mkdir과 같은 것을 날리면, /bin과 같은 곳에 프로그램 형태로(디스크에) 저장되어있는 해당 명령어를 메모리에 적재하고, CPU(프로세서)에 의해 실행된다. 이 상태를 프로세스라고 한다. 프로세스 모니터링(htop) ps , ps aux , htop 등으로 모니터링 가능 htop CPU, MEM(물리) 등으로 정렬해서 볼 수 있음 코어의 갯수와 점유율, load average 등 볼 수 있음 모니터링하는 방법에 대해 추가적으로 알아보기 Reference)https://opentutorials.org/course/2598" }, { "title": "리눅스와 웹 서버", "url": "/posts/%EB%A6%AC%EB%88%85%EC%8A%A4_%EC%9B%B9%EC%84%9C%EB%B2%84/", "categories": "Study, Linux", "tags": "linux, 리눅스", "date": "2021-04-09 00:00:00 +0900", "snippet": " 웹 서버: 아파치, Nginx, IIS 등 domain name, IP addr를 통해 웹 브라우저가 접속할 수 있도록. 웹 브라우저: firefox, chrome …리눅스에 아파치 실행 sudo로 설치(update 후) 서비스 실행 htop 확인 - 웹 서버는 많은접속이 들어올 수 있기 때문에 많은 접속 상황에서 분산 처리하기 위해 많은 프로세스가 실행 됨 elinks 도구 이용해 google.com 들어가고 실제 인터넷처럼 쉘에서 사용 이번엔 ip addr로 알아낸 ip -&amp;gt; curl이나 elinks http://192.168.156.147/ 로 접속해보기 (혹은 elinks 127.0.0.1) 혹은 localhost:80(혹은 127.0.0.1:80)으로 apache port 접속하면 apache 화면 나옴 웹 브라우저 입장에선 웹 서버가 같은 컴퓨터이기 때문에 localhost라는 도메인 네임으로 접속 가능한 것 127.0.0.1: 자기 자신을 가리키는 특수한 IP. -&amp;gt; 도메인 네임: localhost 192.168.156.147/index.html을 어디서 읽어오는 것일까?: /etc/apache2/apache2.conf설정파일을 참고해서 사용자의 접속이 들어왔을 때 사용자의 어떤 storage의 어디에서 찾을 건지 웹 페이지를 찾는 최상위 디렉토리 : document root 현재는 document root가 /var/www/html/index.html로 되어있다 확인하는 방법 : /etc/apache2/sites-enabled에 document root가 저 경로로 되어있음 대부분의 서버는 /etc/{자신의 이름}으로 존재로그를 확인하는 방법 var/log/apache2 밑에 로그가 존재(access.log, error.log) 실시간 확인하려면 tail -f /var/log/apache2/access.log 찾으려면 : whereis *.log Reference)https://opentutorials.org/course/2598/14446" }, { "title": "리눅스 관점에서의 네트워크, 인터넷, 서버", "url": "/posts/%EB%A6%AC%EB%88%85%EC%8A%A4_%EA%B4%80%EC%A0%90_%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC_%EC%9D%B8%ED%84%B0%EB%84%B7/", "categories": "Study, Linux", "tags": "linux, 리눅스", "date": "2021-04-09 00:00:00 +0900", "snippet": ": Request와 Response가 계속 왔다갔다하는 컴퓨터간 통신기본적인 과정: google.com을 웹 브라우저에 치면(req), google에서 응답을(res) 주는 과정 여기서 google.com : 도메인 &amp;lt;–&amp;gt; IP address 리눅스 터미널에서 ping google.com 를 입력하면 google의 IP를 받음(172.217.175.46) 실제로는 IP로 해당 주소를 찾아감. 그에 해당하는 alias같은 것이 domain. -&amp;gt; 사람이 기억하기 쉽도록 사람은 도메인으로 기억하면 됨 DNS 서버 : 이세상의 모든 도메인이 어떤 IP인지 알고 있는 거대한 전화번호부내가 서버를 제공할 때 내 컴퓨터를 서버로 사용하려면 나의 IP를 알아야 한다. 나의 IP 나의 실제 아이피 확인: ip addr을 입력하고 inet에 해당하는 addr을 확인 (192.168.156.147) 나에게 접속한 결과적인 IP(외부에서 본): 혹은 https://ipinfo.io/ip에 접속 혹은 curl을 날려, ip 확인 (210.90.149.16) 두 개의 IP가 다른 이유 위의 그림처럼 각각의 IP를 뚫어 계약을 맺으면 되나, 일단 가격이 비싸다. 위와 같이 router를 두는 것으로 해결 통신사가 제공한 211.46.24.37(공인 아이피)은 Router가 갖게 됨.(회사 대표번호) 각각의 컴퓨터의 주소(IP)는 Router 네트워크끼리 사용하는 사설 아이피(Private IP)로 해결 == 회사 내 내선번호와 같은 느낌 curl ipinfo.io/ip를 통해 알아내는 것 -&amp;gt; 외부의 공용 아이피를 볼 수 있음 ip addr을 통해 알아내는 것 -&amp;gt; 이 컴퓨터의 실질적 아이피가 무엇인지(사설 아이피) 사설 아이피를 사용하는 경우로 어떻게 서버로 사용 일단 Router로 묶여있는 내부 컴퓨터(내부망)끼리는 통신 가능 혹은 Router에 추가적인 별도 설정을 통해서?Reference)https://opentutorials.org/course/2598/14427" }, { "title": "세션 유지 방법 - 쿠키(Cookie)", "url": "/posts/%EC%BF%A0%ED%82%A4_%EC%84%B8%EC%85%98_1_%EC%BF%A0%ED%82%A4/", "categories": "Study, Network", "tags": "network, 쿠키와 세션", "date": "2021-04-08 00:00:00 +0900", "snippet": "쿠키: 인터넷 사용자가 웹 사이트를 방문하면(요청을 보내면) 그 사이트의 서버에서 인터넷 사용자의 해당 브라우저에 저장하는 작은 기록 정보. GET /me와 같은 요청을 보내면 서버 입장에서는 내가 누군지 알 수가 없는데, 이 때 HTTP request 쿠키에 나에 대한 정보를 담아 보내, 서버에서 파악하도록 한다.// github의 set-cookie 응답 헤더set-cookie: has_recent_activity=1; path=/; expires=Tue, 15 Feb 2022 14:54:36 GMT; secure; HttpOnly; SameSite=Lax// github에서의 cookie 요청 헤더cookie: user_session=avhAggsHduFqr2CJV-llWc6fX-I4iAO2oadXFJ1x46_if_iX; __Host-user_session_same_site=avhAggsHduFqr2CJV-llWc6fX-I4iAO2oadXFJ1x46_if_iX; logged_in=yes; dotcom_user=hungryjayy; _device_id=9201e5493cfb21d6e366550217400b15; _octo=GH1.1.177507419.1640739867; color_mode={&quot;color_mode&quot;:&quot;light&quot;,&quot;light_theme&quot;:{&quot;name&quot;:&quot;light&quot;,&quot;color_mode&quot;:&quot;light&quot;},&quot;dark_theme&quot;:{&quot;name&quot;:&quot;dark&quot;,&quot;color_mode&quot;:&quot;dark&quot;}}; tz=Asia/Tokyo; has_recent_activity=1; _gh_sess= ~~~... 이하 생략특징 Key-value 쌍을 이루는 4KB의 작은 정보. 성능 저하의 원인: 동일한 서버에 재 요청시 매 요청마다 서버로 쿠키를 함께 전송하기 때문에, 크면 오버헤드일 수 있음 Expires: 유효기간 존재 유효기간이 존재하는 쿠키는 대부분 브라우저에 저장한다. Stateless인 HTTP 프로토콜에서 stateful하게 만들어주는 역할을 하고 다양한 용도로 사용된다. 세션 관리: 로그인 정보, 장바구니 개인화: 사용자 선호, 테마 세팅 등 트래킹: 사용자 행동 분석 취약점 보안: 위 실제 요청을 참고해보면, 쿠키는 암호화하지 않고 클라이언트 정보를 그냥 저장한다. JWT 토큰은 서버의 비밀키를 통해 토큰값 자체를 암호화해서 클라이언트 브라우저에 저장하도록 한다는 점에서 보안의 차이가 있다. Persistent 쿠키(지속 쿠키): 세션 쿠키와 Expires 옵션에서 차이가 있다. 지속 쿠키는 하드에 저장한다. 공용 PC에서 하드에 저장된 cookie 정보를 쉽게 얻어낼 수 있다. XSS 공격(크로스 사이트 스크립팅): 네트워크를 통해 전송되는 쿠키를 암호화하지 않으면 네트워크 스니핑 공격(데이터 도청)(=세션 하이재킹 같은 것)을 통해 쿠키를 탈취 가능하다. 스니핑을 막기 위해 위의 예시처럼 HttpOnly 옵션을 사용한다. 이걸 통해 브라우저 코드(스크립트)로 해당 쿠키로 접근 불가능하게 한다. Secure cookie HTTPS를 통해 쿠키 또한 암호화 될 수 있다. 개발자의 실수로 HTTP를 전송하는 경우가 있을 수 있는데, Set-Cookie 헤더에 secure 옵션을 주면 HTTPS가 아닌 통신에서 쿠키를 전송하지 않도록 막을 수 있다.Reference)https://it-eldorado.tistory.com/90https://tristan91.tistory.com/521https://nsinc.tistory.com/121https://blog.naver.com/PostView.nhn?blogId=dlaxodud2388&amp;amp;logNo=221917137726https://junwoo45.github.io/2019-05-17-%EB%A1%9C%EC%BB%AC_%EC%84%B8%EC%85%98%EC%8A%A4%ED%86%A0%EB%A6%AC%EC%A7%80_%EC%BF%A0%ED%82%A4/" }, { "title": "도메인과 DNS", "url": "/posts/%EB%8F%84%EB%A9%94%EC%9D%B8_DNS/", "categories": "Study, Linux", "tags": "linux, 리눅스", "date": "2021-04-08 00:00:00 +0900", "snippet": " google.com에 접속할 때 IP 주소로 변환되어 접속이 이루어진다. 애초에 모든 IP를 알고 있을 수는 없다. 따라서 사람은 DNS 주소로 접근 DNS(도메인 네임 시스템) 서버를 통해 IP를 알게 되고 그 IP를 통해 접근 hosts file(보안에 신경써야 함): 네트워크 내의 host들의 도메인 이름이 각각 어떤 IP를 갖는가? DNS가 있기 전, hosts file이 있었고, 여기에 적혀있는 도메인의 IP를 보고 해당 IP에 접근을 했었음. 도메인 네임과 IP의 맵핑을 마음대로 변조할 수 있음 sudo nano /etc/hosts - 접근하고싶은 IP에 대한 (로컬에서 사용할)도메인을 여기에 등록해놓을 수 있음 만약 여기에 접속하고자하는 도메인의 IP가 존재한다면, DNS 서버에 접속하지 않고 여기껄 그대로 쓴다. 그러나 네트워크가 커지면서, 전 세계 네트워크의 호스트를 관리하기가 불가능 어떠한 경우에 사용? 어떠한 특정한 도메인의 IP를 나만 변조해서 사용하고자 할 때 hosts file을 이용한 해커의 공격 google.com에 해당하는 hosts file의 내용을 바꾸어 놓고 google과 똑같은 사이트의 이미지를 제공한다. 이 때 로그인 정보 등 개인정보를 얻음DNS Server: 예전에는 네트워크가 크지 않았고 호스트가 많지 않았기 때문에 호스트 파일로 관리가 가능했었음. 네트워크가 커지면서, 전 지구적인 규모의 이름을 기억하기 위해 만들어짐 /etc/resolv.conf의 nameserver에 해당하는 것이 DNS 서버의 IP 해당 DNS 서버에게 나의 DNS가 IP에 해당한다는 것을 알려주려면 도메인을 구입해야함. 순서: 1. 도메인 가능한지 조회 2. 마음에 드는 것 구매 공짜 ~ 10만원정도로 다양한데 거의 한달에 22000 서브 도메인: myDomain.com 도메인을 샀다고 할 때, blog.myDomain.com / admin.myDomain.com 과 같이 서브 도메인을 이용하면, 하나의 도메인을 구입해 여러 사이트를 운영할 수 있는 장점DNS 서버 찾기 과정: 루트 도메인 (뒷쪽) -&amp;gt; 서브 도메인 순으로 IP를 찾는다.e. g) google.com. root dns 서버 : 루트 도메인인 .com을 관리하는 dns 서버가 누구인지를 물어본다. .com의 dns 서버 : 서브 도메인인 google.com을 관리하는 dns 서버가 누구인지를 물어본다. google.com의 dns 서버: 이 도메인의 IP가 무엇인지 물어본다.Reference)https://opentutorials.org/course/2598/14471" }, { "title": "다중 사용자", "url": "/posts/%EB%8B%A4%EC%A4%91_%EC%82%AC%EC%9A%A9%EC%9E%90/", "categories": "Study, Linux", "tags": "linux, 리눅스", "date": "2021-04-08 00:00:00 +0900", "snippet": ": 무언가 리소스에 대한 접근을 다중 사용자에게 허용. 권한이라는 개념. 유닉스 계열의 시스템 어떤 누군가가 해도 되는지 안되는지를 확인해야 함super(root) user sudo -i: superuser로 login하는 것. -&amp;gt; su와 같다. sudo apt-get update su : 유저를 바꾸거나 super user가 되기 e.g) su - root (root 유저 되기) su : switch user의 준말. default가 root유저임. 즉, su만 쳐도 root로 접근하게 되는 것 이 때 root에 대한 password를 unlock해야한다. sudo passwd -u root 이후에.(unlock) 터미널에서 $가 아니라 #로 커맨드가 보인다. user 사용자 추가하기 : sudo useradd -m aaa /home에서 ls를 보면 aaa 사용자가 추가된 것을 보게된다. 그러나 password 설정 안했기 때문에 로그인 불가 sudo passwd aaa로 패스워드 추가, su - aaa로 계정 변경 CLI id : 내 자신이 누구인지 who : 누가 현재 접속해있는지Reference)https://opentutorials.org/course/2598/14241" }, { "title": "TCP/IP vs UDP - UDP", "url": "/posts/TCP_UDP-UDP/", "categories": "Study, Network", "tags": "network, tcp/ip, udp", "date": "2021-04-07 00:00:00 +0900", "snippet": ": User Datagram Protocol특징 데이터그램 단위로 처리하는 비연결형 서비스 연결을 위해 할당되는 논리적 경로 없음 패킷은 각각 독립적 관계(독립적으로 처리) ACK와 같은 절차 없다. 신뢰성 낮다. 덕분에 빠르긴 하다. 메시지 크기도 TCP에 비해 엄청 작다. 송신 port, 수신 port, 패킷 length, checksum이 끝. 빠른 특징으로 인해 HTTP/3.0에서 채택되었다. 정확하게는 UDP 기반 QUIC 채택으로 신뢰성있는 빠른 통신을 할 수 있다고한다. 현재 curl 최신도 HTTP/3.0을 사용한다고한다. UDP 헤더의 checksum필드로 최소한의 오류만을 검출 패킷 순서에 맞게 조립, 흐름제어, 혼잡제어 다 하지 않음. 신뢰성 없고, 연속성이 중요한 서비스에 적합 e.g) 실시간 스트리밍 그러나 개발자가 개발 레벨에서 어느정도 신뢰성을 줄 수는 있다고 함 UDP 서버의 특징 연결 자체가 없고 서버소켓 클라이언트소켓 구분 X 소켓 대신 IP 기반 데이터 전송 1:1, 멀티캐스트**, **브로드캐스트 다 가능. 데이터그램 단위 전송 (65535 바이트 크기)Reference)HTTP 완벽 가이드https://github.com/WeareSoft/tech-interview/blob/master/contents/network.md#tcp%EC%9D%98-3-way-handshake%EC%99%80-4-way-handshakehttps://velog.io/@hidaehyunlee/%EB%8D%B0%EC%9D%B4%ED%84%B0%EA%B0%80-%EC%A0%84%EB%8B%AC%EB%90%98%EB%8A%94-%EC%9B%90%EB%A6%AC-OSI-7%EA%B3%84%EC%B8%B5-%EB%AA%A8%EB%8D%B8%EA%B3%BC-TCPIP-%EB%AA%A8%EB%8D%B8https://mangkyu.tistory.com/15https://engineer-mole.tistory.com/140https://velog.io/@hidaehyunlee/TCP-%EC%99%80-UDP-%EC%9D%98-%EC%B0%A8%EC%9D%B4" }, { "title": "Linux 기초", "url": "/posts/%EB%A6%AC%EB%88%85%EC%8A%A4_%EA%B8%B0%EC%B4%88/", "categories": "Study, Linux", "tags": "linux, 리눅스", "date": "2021-04-07 00:00:00 +0900", "snippet": ": 리눅스 커널에 기반을 둔 오픈소스 유닉스 계열 운영체제 리눅스 커널, 기타 구성요소가 오픈소스라는 점이 다른 OS와의 큰 차이점 Unix 계열(Mac도 Unix 계열) 따라서 리눅스와 맥은 공통의 조상을 가짐 패키지 관리자: apt, yum, portage 등 배포판 중에는 데비안, 페도라, 우분투 포함 가상 머신(virtualbox)을 통해서도 윈도우 위에 리눅스 설치 가능 다중 사용자가 사용 가상 머신에서도 Sudo: 다중 사용자가 사용하기 때문에 Root 권한 개념이 있어야 하고, permission이 있어야 한다. Ternimal: GUI 없이 명령어(CLI)를 통해 제어Sudo(Super User Do): 다중 사용자 시스템(리눅스)에서 root 권한을 갖는 슈퍼유저를 구별하기 위해 항상 super user이면 큰 실수를 초래할 수 있기 때문에 디폴트는 Root가 아님 필요할 때 sudo 사용 무언가 설치할 때 Package Manager: 필요한 패키지들을 다운받는 등 관리해주는 것 ls, mkdir같은 것들은 이미 내장되어있는 프로그램 별도의 프로그램(패키지)을 다운받기 위해서는 패키지 매니저를 통해 다운받아야 함. apt-get update : 내가 현재 설치할 수 있는 프로그램 목록을 최신 상태로 반영해주는 CLI api-get install : 패키지 다운(sudo 권한 필요)WGET: GUI 아닌 방식에서 다운로드 받는 방법 wget {다운받을 URL} 혹은 git clone가상 머신?: 소프트 웨어 상 가상의 하드웨어를 구현하고 그 위에서 운영체제가 작동하도록 하는 기술 독립된 작업공간 필요한 경우 보안 문제: 가상 머신에 설치하면 호스트 컴퓨터는 안전하게 유지 가능 하나의 머신에서 여러 명에게 운영 체제 환경을 제공 Docker: 스냅샷(이미지)를 그대로 컨테이너에 올림 Reference)https://opentutorials.org/course/2598https://ko.wikipedia.org/wiki/%EB%A6%AC%EB%88%85%EC%8A%A4" }, { "title": "TCP/IP vs UDP - TCP/IP", "url": "/posts/TCP_UDP-TCP/", "categories": "Study, Network", "tags": "network, tcp/ip, udp", "date": "2021-04-06 00:00:00 +0900", "snippet": ": Transfer Control Protocol / Internet Protocol프로토콜이란?: 장치(컴퓨터)간 통신 할 때 그냥 전기 신호가 전달되는 것이 아니라 표준화된 절차, 약속에 따라서 전달됨. 보내는 쪽에서는 데이터를 안전하고 정확하게 규격화하는 방법이 필요하고 받는 쪽에서는 정확하게 해석하는 방법이 필요하다. OSI 계층에서 전송 계층은 IP에 전달되는 패킷의 오류를 검사하고 재전송 요구 등의 제어를 담당하는데, 여기서 TCP, UDP 두 프로토콜이 있고 두 프로토콜에서 제공하는 서비스가 다르다. TCP와 UDP는 별도의 포트 주소 공간을 관리하기 때문에 같은 포트를 사용해도 다른 포트로 간주된다.   port description well-known 0~1023 IANA에서 정한 포트. 22, 53(dns), 80, 443, registered 1024~49151 IANA에 등록되어있는 포트. 3306, 8080 등 dynamic, private 49152~65535 클라이언트쪽의 어플리케이션에 자동적으로 할당되는 포트 번호 TCP 연결형 서비스: 3 way, 4 way handshake UDP보다 느리다. 신뢰성이 필요한 전송에 사용특징 흐름 제어: 데이터 송신하는 곳과 수신하는 곳의 데이터 처리 속도를 조절해 buffer overflow 방지 Stop and Wait: 전송 패킷에 대한 ack를 받으면 다음 패킷 전송. 슬라이딩 윈도우: 수신자가 설정한 window 크기만큼에 대해서는, ack를 받지 않아도 전송을 하도록 한다. window에 포함된 패킷들이 전송되고 ack를 받으면, 그 만큼 윈도우를 slide하는 방식 window크기는 동적으로 변화 가능하다. 혼잡 제어 : 네트워크 내의 패킷 수가 너무 증가하지 않도록 방지. 느린 시작: “혼잡 윈도우를 연다.” 처음에는 패킷 하나 전송, ack를 받으면 두개 전송, 네개 전송, … AIMD(Additive Increase, multiple decrease): 합 증가, 곱 감소 방식. ack를 받으면 윈도우 크기 1 증가하고, 전송이 실패했다고 판단하면 윈도우 크기 절반으로 줄인다. 신뢰성 보장 정상적인 상황이라면 ACK값이 연속적으로 전송되어야 함. Dupack-based retransmission : ACK 중복 시 패킷 재전송 요청 Timeout-based retransmission : ACK 수신 못할 시 재전송 요청 패킷들에는 순서가 있다. 이 순서를 조립해 완성하면 하나의 데이터가 되고, 이러한 방법으로 데이터를 정확하게 받을 수 있음 전이중(Full-Duplex) : 전송은 양방향으로 동시에 일어날 수 있다. 점대점(P2P) : 연결은 2개의 엔드포인트가 있다. 따라서 multicasting이나 broadcasting 지원 x TCP 서버의 특징 서버 소켓은 연결만을 담당 server client는 1:1 연결 스트림 전송으로 전송 데이터 크기가 무제한 패킷 응답 때문에 느리고, CPU소모가 크다 Streaming에 사용되지 않음 손실 시 재요청해 정확한 데이터를 주고받는 것보다 지연되지 않는 stream이 유리하기 때문 c f) 텔넷을 통한 원격 접속 방식에서의 TCP 커넥션 웹 서버는 원격으로 접속한 사용자를 웹 클라이언트로 취급하고 TCP 커넥션을 통해 돌려주는 데이터를 볼 수 있다. 1 % telnet www.joes-hardware.com 802 Trying 128.121.66.211...3 Connected to joes-hardware.com.4 Escape character is &#39;^]&#39;.5 GET /tools.html HTTP/1.16 Host: www.joes-hardward.com7 line 1: 텔넷은 호스트명을 찾아 80번 포트로 대기중인 joes-hardware 웹 서버에 연결 line 2~4: 커넥션 수립을 알리는 텔넷의 출력 line 5~7: 사용자가 직접 HTTP 요청 입력 후 Host 헤더로 전송하고, 한줄 더 띄우면 해당 웹 서버에서 리소스(/tools.html) 반환 Reference)HTTP 완벽 가이드https://github.com/WeareSoft/tech-interview/blob/master/contents/network.md#tcp%EC%9D%98-3-way-handshake%EC%99%80-4-way-handshakehttps://velog.io/@hidaehyunlee/%EB%8D%B0%EC%9D%B4%ED%84%B0%EA%B0%80-%EC%A0%84%EB%8B%AC%EB%90%98%EB%8A%94-%EC%9B%90%EB%A6%AC-OSI-7%EA%B3%84%EC%B8%B5-%EB%AA%A8%EB%8D%B8%EA%B3%BC-TCPIP-%EB%AA%A8%EB%8D%B8https://mangkyu.tistory.com/15https://velog.io/@hidaehyunlee/TCP-%EC%99%80-UDP-%EC%9D%98-%EC%B0%A8%EC%9D%B4" }, { "title": "논리연산자(&amp;&amp;, ||)와 단축평가", "url": "/posts/%EB%85%BC%EB%A6%AC%EC%97%B0%EC%82%B0%EC%9E%90_%EB%8B%A8%EC%B6%95%ED%8F%89%EA%B0%80/", "categories": "Study, JavaScript", "tags": "javascript, js", "date": "2021-04-02 00:00:00 +0900", "snippet": "단축평가? &amp;amp;&amp;amp;,   에서 왼쪽부터 오른쪽으로 가면서 결과 발생 시 더이상의 논리 평가를 하지 않음 e.g.) C++에서 if(!Q.empty() &amp;amp;&amp;amp; Q.front() &amp;gt; 1) 이 상황에서 Q가 비어있어도 Q.front()에서 segmentation fault 발생하지 않던 이유 논리합 || 왼쪽 피연산자 true 시 바로 왼쪽 것 그대로 반환 바꿔 말하면, 왼쪽 false 시 오른쪽 것 그대로 반환 예시 true || false : 왼쪽 것 true, 오른쪽 보지 않고 true 반환 req.body || newBody : req.body 있으면 req.body 반환, 없으면 newBody 반환 true || body : true 반환 body1 || body2 : body1 있을 시 body1 반환, 없으면 body2 반환 헷갈릴만한 것 : “??” 이것 또한   처럼 쓰임.   : falsy를 판단(0, “”, false, null, undefined 모두 해당) ??: null이나 undefined인지를 판단 논리곱 &amp;amp;&amp;amp; 왼쪽 피연산자 false 시 오른쪽 보지 않고 왼쪽 것 그대로 반환 바꿔말하면, 왼쪽 true 시 오른쪽 값 그대로 반환 예시 true &amp;amp;&amp;amp; false : 왼쪽 것 true, 오른쪽 반환 false req.body &amp;amp;&amp;amp; newBody : req.body 있으면 newBody 반환, 없으면 req.body 반환 true &amp;amp;&amp;amp; body : body 반환 body1 &amp;amp;&amp;amp; body2 : body1 있을 시 body2 반환, 없으면 body1 반환 단축평가 쓰임 예시 null, undefined 체크 const req = null;1. const foo = req.body; // TypeError 2. const foo = req &amp;amp;&amp;amp; req.body; // 에러 발생 x 출처: https://curryyou.tistory.com/193 [카레유] 매개변수 기본값 세팅(디폴트 값을 만들어줌) function getName(name){ const yourName = name || &quot;무명&quot;; return yourName;}; getName(&#39;정우성&#39;) // &quot;정우성&quot;getName(); // &quot;무명&quot; 출처: https://curryyou.tistory.com/193 [카레유] 변수 초기화(if vs 단축평가) let res = :&quot;&quot;;let cond = true; 1. if(cond) res = &#39;DD&#39;; 2. res = cond &amp;amp;&amp;amp; &#39;DD&#39;; 출처: https://curryyou.tistory.com/193 [카레유] Reference)https://curryyou.tistory.com/193" }, { "title": "Annotation", "url": "/posts/%EC%96%B4%EB%85%B8%ED%85%8C%EC%9D%B4%EC%85%98/", "categories": "Study, Spring boot", "tags": "spring, spring boot, 스프링, 스프링부트", "date": "2021-04-01 00:00:00 +0900", "snippet": "Bean으로 만들어주는 것 @Componenet : 클래스를 Bean으로 등록 @Repository : @Component + DAO 관련 장점 (unchecked 예외 처리) @Service : @Component + 서비스 레이어 명시 @Controller : @Componenet + 컨트롤러에서 사용할 어노테이션에러처리 @ControllerAdvice 에러를 한 곳에서 처리(각각의 Controller의 에러 처리 로직은 비슷비슷 할 것이기 때문) @Restcontrolleradvice = @ControllerAdvice + @ResponseBody @ExceptionHandler @Controller, @RestController의 Bean에서 발생한 예외를 잡아서 한 메서드에서 처리 인자로 캐치하고 싶은 예외 클래스 등록 여러개도 가능 e.g. ) @ExceptionHandler({ Exception1.class, Exception2.class }) @ResponseStatus Controller나 Exception의 return에 status 정보를 설정하여 리턴해줌. API call에서 @RequestParam Get mapping에서 url의 parameter를 받음 @RequestBody post mapping에서 Body로 받을 때 JPA 관련 @Id 직접 할당을 원한다면 @Id에 set 직접 할당 아니라면 자동 생성(@GeneratedValue), 전략 네 가지 중 하나 선택 @GeneratedValue Generate 방식에는 네가지 전략 존재 IDENTITY 기본 키 생성을 DB에 위임(DB에 의존적) DB에 값을 저장한 후 기본 키 값을 얻을 수 있다. SEQUENCE 시퀀스를 이용해 기본 키 할당(DB 의존) TABLE 키 생성 테이블을 사용하는 방법 - 모든 DB 적용 가능 테이블에 이름과 값으로 사용할 컬럼을 만드는 방법 AUTO DB에 따라 알아서 하나 선택해주는 방법 Reference)https://coding-start.tistory.com/71https://ithub.tistory.com/24" }, { "title": "3 way, 4 way handshake", "url": "/posts/3_way_4_way_handshake/", "categories": "Study, Network", "tags": "network, tcp/ip", "date": "2021-04-01 00:00:00 +0900", "snippet": ": 이 과정을 통해 TCP 프로토콜의 송 수신자 모두 준비가 되었다는 것을 보장한다. UDP와 다르게 TCP 통신에서는 장치 사이에서 연결을 보장하고 명확한 전송을 하기 위해 conn을 맺고 끊을 때 3-way, 4-way handshake를 한다.3 way handshake: TCP 연결을 초기화 할 때 사용 SYN(n): 클라이언트가 서버에게 SYN 를 보낸다. 이 때 시퀀스넘버라는 난수를 생성해 SYN에 붙여서 보낸다. 난수를 보내는 이유: 다른 SYN 요청과의 구분 보낸 후 client는 SYN_SENT 상태가 됨 flag: 000010 ACK(n+1) + SYN(m): 서버가 클라이언트에게 ACK(요청 수락)와 SYN를 보낸다. 마찬가지로 시퀀스 넘버를 붙여서 보낸다. 서버는 SYN_RECEIVED 상태가 됨 flag: 010000 ACK(m+1): 클라이언트가 ACK를 보내고 ESTABLISHED가 되고, 서버는 받고서 ESTABLISHED가 되며 이후로 데이터가 오간다.4 way handshake: TCP 연결을 종료하기 위해 수행하는 절차. Client -&amp;gt; Server 방향으로 요청하는 것으로 표현되어있지만, 일반적으로 요청을 보내는 쪽이 Client라고 이해하면 된다. 실제로 지속 커넥션이 아니라면, 웹서버 입장에서는 사용자의 요청 메시지에 대한 응답을 다 보내고나서 커넥션을 닫는다고 한다. FIN: 클라이언트가 연결 종료 메시지 FIN플래그를 보낸다. flag: 000001 ACK: 서버가 확인메시지를 보낸다. CLOSE-WAIT 상태 FIN: 서버가 통신 끝났다는 메시지인 클라이언트에게 FIN플래그를 보낸다. ACK: 클라이언트가 ACK를 보낸다. 클라이언트는 TIME_WAIT 상태가 되고, 2MSL동안 기다리게 된다. 지연으로 패킷이 FIN보다 늦어지는 상황 세션 종료 후 전송되는 패킷은 drop, 데이터 유실 됨. TIME-WAIT 상태: 이러한 상황에 대비해 client는 FIN을 수신하더라도 세션을 남겨놓고 패킷을 기다림. 이 때, 일반적으로 2 MSL(double maximum segment lifetime)동안 기다린다.MSL: TCP 세그먼트가 internetwork(네트워크들이 연결된 상태의 네트워크)에서 살아있을 수 있는 시간. // linux 체계에서 아래와같이 확인 가능 sysctl net.ipv4.tcp_fin_timeout cat /proc/sys/net/ipv4/tcp_fin_timeout RFC 명세에선 MSL값은 2분이 디폴트로 나온다. 리눅스 설정값을 보니 1분이 디폴트이다. 2 * MSL 기준으로 보통 2~4 분으로 많이 설정하는 것 같다. 두배인 이유는 패킷 손실 시 회복을 보내는 시간까지 고려. 예상치 못하게 네트워크 트래픽이 많은 경우 최악의 케이스로 MSL이 발생한다고 한다면 재요청 패킷 또한 MSL까지 발생할 수 있을것이라고 판단연결 끊는 상황에서 3 way 아닌 4 way로 구성하는 이유: Client 데이터 전송이 끝났어도 Server쪽에서 아직 보낼 데이터가 남아있을 수 있기 때문에이다. 따라서, 받은 FIN에 대한 ACK만 보내고, 보낼 것이 있으면 다 보내고 난 후 서버도 FIN을 보낸다.시퀀스넘버를 난수로 날리는 이유: Port를 통해 연결하고 데이터를 교환하고 다시 끊고 나서, 시간이 지나고서 같은 포트를 다시 또 사용한다. 따라서, 과거에 사용된 포트번호 쌍을 사용할 가능성이 존재하기 때문에, 과거의 SYN을 현재의 SYN으로 인식할 수 있다.(오해가 생길 수 있다) ACK의 난수는 해당 응답의 요청이었던(SYN) 시퀀스넘버의 +1Reference)코딩 인터뷰 완전분석http://www.tcpipguide.comhttps://mindnet.tistory.com/entry/%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-%EC%89%BD%EA%B2%8C-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0-22%ED%8E%B8-TCP-3-WayHandshake-4-WayHandshakehttps://github.com/WeareSoft/tech-interview/blob/master/contents/network.md#tcp%EC%9D%98-3-way-handshake%EC%99%80-4-way-handshake" }, { "title": "AMQP 라이브러리 Option", "url": "/posts/AMQP_%EC%98%B5%EC%85%98/", "categories": "Study, RabbitMQ", "tags": "rabbitmq, message queue", "date": "2021-03-31 00:00:00 +0900", "snippet": " ack, noAck RabbitMQ가 고객에게 메시지를 전달하면 바로 삭제 표시. 작업자가 죽으면 메시지 손실 durable, persistent durable - rabbitMQ가 예기치 않게 종료되어도 queue를 잃지(잊지) 않게 됨. prefetch prefetch count가 1로 설정되어있으면 소비자로부터 ack를 받지 못한 메시지가 1개라도 있을 때 해당 소비자에게는 메시지를 전달하지 않음. 즉, prefetch count는 소비자에게 동시에 전달되는 메시지의 양 vhost : vhost설정을 통해 각 사용자마다 격리된 환경을 제공 받을 수 있다. durable 옵션: exchange, queue의 durable 속성은 disk에 메시지를 저장할지 결정하는 boolean 형태의 option이다." }, { "title": "공인 아이피와 사설 아이피", "url": "/posts/%EA%B3%B5%EC%9D%B8%EC%82%AC%EC%84%A4_%EC%95%84%EC%9D%B4%ED%94%BC_VPC/", "categories": "Study, Network", "tags": "network", "date": "2021-03-30 00:00:00 +0900", "snippet": "공인 아이피 인터넷상 서로다른 PC끼리 통신을 위해 필요한 아이피 ISP가 할당(Internet Service Provider)한다. e.g ) 82.33.263.12 사설 아이피 내부망 전용 아이피: 내부끼리 통신할 경우 접근 가능하다. 외부에서 접근하려면 해당 망이 있는 VPC에 먼저 접근 한다음 해당 망 내부의 사설 아이피로 접근해야한다. 내부 어디에 연결해있는지를 알려면 Routing table을 확인한다. netstat -r e.g ) 192.168.156.147 클래스에 따른 세가지 사설 아이피 대역 Class A : 10.0.0.0 ~ 10.255.255.255(10/8 prefix) Class B : 172.16.0.0 ~ 172.31.255.255(182.16/12 prefix) Class C : 192.168.0.0 ~ 192.168.255.255(192.168/16 prefix) VPC AWS 예시: 위의 그림처럼 VPC별로 네트워크 구성되면 각각의 VPC는 독립적인 네크워크를 형성한다. 이 VPC 내부에 존재하는 더 작은 논리적 단위가 서브넷다른 PC docker container 접근하기 (우분투) A에서 B ssh로 접속하기: ufw는 기본적으로 아웃바운드 모두 허용, 인바운드 모두 비허용이다. B에 port 열어주기 ufw(ubuntu firewall) or iptables 명령어 sudo ufw enable (활성화) sudo ufw allow 22(ssh default) sudo ufw reload A에서 ssh root@${PC A ip} 연결 완료 후 A에서 B 컨테이너로 접근 : 목적 컨테이너 포트 열기, 도커 네트워크 설정Reference)https://medium.com/harrythegreat/aws-%EA%B0%80%EC%9E%A5%EC%89%BD%EA%B2%8C-vpc-%EA%B0%9C%EB%85%90%EC%9E%A1%EA%B8%B0-71eef95a7098https://velog.io/@hidaehyunlee/%EA%B3%B5%EC%9D%B8Public-%EC%82%AC%EC%84%A4Private-IP%EC%9D%98-%EC%B0%A8%EC%9D%B4%EC%A0%90https://jmoon.co.kr/183https://docs.aws.amazon.com/ko_kr/vpc/latest/userguide/how-it-works.html" }, { "title": "HTTPS와 SSL", "url": "/posts/HTTPS_SSL/", "categories": "Study, HTTP", "tags": "http, ssl, https", "date": "2021-03-23 00:00:00 +0900", "snippet": "HTTP의 문제점 암호화 하지 않음 - 평문(단순 텍스트)을 주고받음(Http 메시지) GET / HTTP/1.1Host: developer.mozilla.orgAccept-Language: fr 문제점 통신 상대 확인하지 않음 - Client, server 확신 불가(위장 가능성) 스니핑 후 데이터를 변조할 가능성 따라서, CA를 통해 받은 인증서를 이용해 검증된 신뢰성 있는 통신을 해야한다. -&amp;gt; HTTPS 스니핑 공격: 기본적으로 같은 네트워크 상에 있는 호스트들의 모든 트래픽을 볼 수 있다. 이는 성능 저하의 우려가 있기 때문에, 호스트의 네트워크 카드를 읽어 목적지 IP와 MAC 주소가 본인에 해당하지 않으면 해당 패킷을 무시해버리는데, 스니핑 공격은 해당 패킷을 읽어오는 것. HTTPS 프로토콜을 이용한다면 이러한 도청이 있더라도 암호화가 되어있기 때문에 안전하다.HTTPS: HTTP의 보안 취약점을 해결하기 위한 프로토콜. HTTPS는 기존 HTTP 통신을 SSL 프로토콜(443 Port)을 통해 평문을 암호화하고, 통신하는 것이라고 보면 된다.SSL: 응용(L5~L7), 전송계층(L4) 사이에 보안계층이라는 독립적인 계층을 만들어, HTTP + SSL (or TLS)로 보내는, (보안)통신 프로토콜CA(Certificate Autority) 로부터 인증서 받아오는 과정: 통신을 어떻게 할건지, CA에게 의뢰(?)를 통해 인증서 발급, 대칭키 발급, 암호화 알고리즘 결정, SSL / TLS 프로토콜 결정 과 같은 일을 하는 과정 SSL 인증서 : client, server 통신을 제3자가 보증해주는 것. 이 서버가 진짜임을 나타냄 Server -&amp;gt; CA: 서버가 서버의 공개 키와 서버 정보를 CA에게 보냄 CA -&amp;gt; Server: CA는 서버 정보, 서버 공개 키, 공개 키 암호화 방법을 담은 SSL 인증서를 만들고 CA의 개인 키를 통해 암호화해 서버에 전달SSL 핸드쉐이크 SSL은 443 port를 사용하는 TCP 프로토콜이기 때문에, 당연히 이 핸드셰이크 이전에 TCP 3-way 핸드셰이크 선행 Client -&amp;gt; Server: 브라우저 지원 가능한 암호화 방식(알고리즘) 제안, Random data 전달 Server -&amp;gt; Client: 암호화 방식 중 하나 선택하고, 인증서 전달, Random data 전달 이 인증서에 서버의 공개 키 포함되어 있음 Client는 CA의 공개 키를 통해 인증서를 복호화해 서버의 공개 키 얻고, 진짜 서버인 것을 확인. CA는 세계적으로 신뢰성있는 기업이라 이미 CA의 공개 키가 웬만한 브라우저에 저장 되어있음. Client -&amp;gt; Server(키교환): 미리 주고받은 random data를 이용해 암호화 시 사용할 대칭 키(비밀 키) 생성 후, 서버의 공개 키로 암호화 해, 서버에게 전달. 이후 서버에서는 전달 받은 것을 서버의 개인 키로 복호화하고, 여기서 대칭 키를 얻음 Finished: 서로 finished 메시지 보내고, 이 후 클라이언트한테 받은 이 클라이언트의 대칭 키(비밀 키)를 통해 암호화해 통신 HTTPS라도, 안전하지 않은 사이트와 같은 경우 자체 인증 발급인 경우일 수 있고, 무조건 안전한 것은 아님키 종류공개 키 모두에게 공개하는 키(해커가 알아도 되는 키) 공개키 암호화: 공개키로 암호화하고, 개인키로 복호화개인 키 나만 가지고 있는 키 공인인증서의 문제: 이 개인키를 컴퓨터에 그냥 일반 파일로 저장하도록 함 개인키 암호화: 개인키로 암호화, 공개키로 복호화대칭 키 암호화, 복호화에 동일한 하나의 키를 사용Reference)https://aws-hyoh.tistory.com/entry/HTTPS-%ED%86%B5%EC%8B%A0%EA%B3%BC%EC%A0%95-%EC%89%BD%EA%B2%8C-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0-2Key%EA%B0%80-%EC%9E%88%EC%96%B4%EC%95%BC-%EB%AC%B8%EC%9D%84-%EC%97%B4-%EC%88%98-%EC%9E%88%EB%8B%A4?category=768734https://opentutorials.org/course/1334/4894https://blog.naver.com/skinfosec2000/222135874222https://velog.io/@okstring/http-vs-httpshttps://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Network/HTTP%20%26%20HTTPS.md" }, { "title": "SpringBoot 용어 및 기본 개념", "url": "/posts/Spring_Boot_%EC%9A%A9%EC%96%B4_%EB%B0%8F_%EA%B8%B0%EB%B3%B8_%EA%B0%9C%EB%85%90/", "categories": "Study, Spring boot", "tags": "spring, spring boot, 스프링, 스프링부트", "date": "2021-03-22 00:00:00 +0900", "snippet": "용어 Controller : 비즈니스 로직 처리, 세분화가 필요할 경우 적절한 service에 전달 Service: DAO로 데이터베이스에 접근, DTO로 전달 DAO : Data Access Object DTO : Data Transfer Objectspring boot vs spring 추상화: Spring Boot는 Spring을 잘 사용하기 위해 한번 더 추상화해 나온 것. starter로 디펜던시 편하게 관리. 빈에 대한 자동설정이 적용되어 생성된다. 스프링은 직접 빈 등록해야한다.DB 연계Spring boot JPA 실무에서 많이 사용한다. JPA를 추상화 -&amp;gt; 그냥 인터페이스에 사용할 API 정의만 해주면 된다. 엔티티 매니저 등은 구현체에서 관리해준다.Spring Data JDBC Spring boot JPA는 성능과 편의를 위해 많은 것이 추상화 되어있는데 그렇다보니 전체를 이해하기에 공부가 많이 필요하다. JDBC는 이러한 부분을 덜어내고 simplify하는 것에 초점을 두었다고 한다.Bean? POJO(plain old java object) IoC: 빈 컨테이너에 의해 인스턴스 관리(DI)되고 thread safety도 보장된다. 스프링에서는 XML파일로 관리되었다.Reference)https://gmlwjd9405.github.io/2018/11/10/spring-beans.htmlhttps://velog.io/@yhh1056/%EC%8A%A4%ED%94%84%EB%A7%81-Bean-Configuration-Singleton" }, { "title": "데드락(Deadlock)", "url": "/posts/%EB%8D%B0%EB%93%9C%EB%9D%BD(Deadlock)/", "categories": "Study, OS", "tags": "os, 운영체제", "date": "2021-03-22 00:00:00 +0900", "snippet": ": 둘 이상의 프로세스가 서로 각자 필요로하는 자원을 갖고 있고, 서로의 것을 원할 때 무한정 기다리는 현상데드락 발생 조건 상호 배제: 자원은 한번에 한 프로세스만 사용 할 수 있음 점유 후 대기: 최소한 하나의 자원을 점유하고 있는 상태에서 다른 프로세스의 자원을 추가 점유하려는 프로세스가 존재 비선점: 다른 프로세스의 자원은 강제로 뺏을 수 없음 순환 대기: 순환형태의 자원 대기가 있음데드락 해결 방법데드락 예방 : 데드락 발생조건 하나를 제거해 해결 상호 배제 제거: 여러 프로세스가 공유 자원 사용하도록 점유 후 대기 제거 : 프로세스 실행전에 미리 필요한 모든 자원 할당을 마쳐 추가 점유를 제거. 문제: 자원 과다 사용으로 인한 효율성, starvation, 무한 대기 등 문제가 있다. 비선점 제거 : 선점 가능한 프로토콜을 만들어줌 문제: 기존에 사용중이던 프로세스는 작업 내용을 잃을 수도 있다. 순환대기 제거 : 자원에 고유번호 할당 후 오름차순으로 자원 요구하도록데드락 회피 : 데드락 발생할 것 같으면 피해가기 은행원 알고리즘 어떠한 프로세스가 자원 요구 시, 시스템은 자원 할당 후에도 안정 상태로 남아있게 되는지 사전에 검사해서 안정이면 할당, 아니면 자원 해지까지 대기 최소 한 사람이 최대로 요구할 수 있는 자원을 알고, 미리 그것보다 많은 자원을 갖고 있어야 한다. 데드락 탐지 : 자원 할당 그래프를 통해 데드락 감지. 자원 요청 때마다 탐지 알고리즘을 실행, 그에 대한 오버헤드 존재 순환이 발생하면 데드락 발생하는 것이라고 결정. Union find DFS를 통해 visit했는지 탐지 토끼와 거북이(runner 매커니즘) 데드락 회복 : 데드락 발생한 1. 프로세스 종료하거나 2. 할당된 자원 해제를 통해 회복 종료방법 데드락 프로세스 모두 중지 or 데드락 해결때 까지 하나씩 중지 자원 선점(해제)방법 데드락 프로세스의 자원을 다른 프로세스에게 할당 우선순위가 낮은 프로세스나 수행횟수 적은 것 부터 식사하는 철학자와 기아(Starvation) 데드락 발생조건의 네가지를 전부 만족하는 시나리오. 발생조건 중 하나를 제거하면 해결과정 왼쪽 젓가락부터 집어든다. 다른 철학자가 이미 왼쪽 젓가락을 쓰고 있다면 그가 내려놓을 때까지 생각하며 대기한다. 왼쪽을 들었으면 오른쪽 젓가락을 든다. 들 수 없다면 들 수 있을 때까지 생각하며 대기한다. 두 젓가락을 모두 들었다면 일정 시간동안 식사를 한다. 식사를 마쳤으면 오른쪽 젓가락을 내려놓고, 그 다음 왼쪽 젓가락을 내려놓는다. 다시 생각하다가 배고프면 1번으로 돌아간다.Reference)https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Operating%20System/DeadLock.mdhttps://github.com/JaeYeopHan/Interview_Question_for_Beginner/tree/master/OS#%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4-%EB%8F%99%EA%B8%B0%ED%99%94https://gameproyyj.tistory.com/157?category=875111https://m.blog.naver.com/hirit808/221788147057" }, { "title": "웹 통신의 큰 흐름 - www.google.com을 치면 일어나는 일", "url": "/posts/%EC%9B%B9_%ED%86%B5%EC%8B%A0%EC%9D%98_%ED%9D%90%EB%A6%84/", "categories": "Study, Network", "tags": "network", "date": "2021-03-22 00:00:00 +0900", "snippet": "브라우저 DNS Lookup: 사용자가 브라우저에 도메인네임 입력하면 DNS 서버에서 IP주소를 얻기 위해 DNS lookup을 수행한다. 프로토콜 스택의 가장 윗층 7 layer인 Application Layer에 해당한다. 크롬에서는 브라우저 -&amp;gt; hosts 파일(파일 시스템) -&amp;gt; DNS cache 순으로 찾는다. 루트 도메인서버에서부터 서브 도메인서버 순으로 IP를 찾는다. IP주소를 이용해 HTTP request message를 만들어 OS에 전송 요청한다.프로토콜 스택(OS에 내장된 네트워크 제어용 SW): OSI 계층(or TCP 계층)을 내려가면서 패킷 등 붙이는 것 브라우저로 부터 받은 메시지를 패킷속에 저장하고, 이 패킷을 LAN 어댑터에 넘김 LAN 어댑터는 이걸 전기신호로 변환시켜 송출한다.네트워크: 패킷은 스위칭 허브 -&amp;gt; 인터넷 접속용 라우터 -&amp;gt; 통신사 인터넷 순으로 전달된다.방화벽(목적지 앞 단): 인터넷 핵심부를 통과해 웹 서버 측 LAN에 도착하고, 방화벽에서 패킷 검사 이후, 캐시서버에서 얻을 수 있는거면 캐시서버에, 아니면 웹 서버로 가게 된다.웹 서버 웹 서버의 프로토콜 스택(OS의 네트워크 제어용 sw)은 패킷 추출, 메시지 복원해 웹 어플리케이션에 요청받은 데이터를 응답 메시지에 넣어 클라이언트에 회송.(왔던 과정 그대로)Reference)HTTP 완벽 가이드https://github.com/WooVictory/Ready-For-Tech-Interview/blob/master/Network/%EC%A3%BC%EC%86%8C%EC%B0%BD%EC%97%90%20naver.com%EC%9D%84%20%EC%B9%98%EB%A9%B4%20%EC%9D%BC%EC%96%B4%EB%82%98%EB%8A%94%20%EC%9D%BC.mdhttps://github.com/ksundong/backend-interview-questionhttps://github.com/JaeYeopHan/Interview_Question_for_Beginner/tree/master/Network" }, { "title": "라인에서 Kafka를 사용하는 법", "url": "/posts/%EB%9D%BC%EC%9D%B8%EC%97%90%EC%84%9C_kafka%EB%A5%BC_%EC%82%AC%EC%9A%A9%ED%95%98%EB%8A%94_%EB%B0%A9%EB%B2%95/", "categories": "Study, Kafka", "tags": "kafka, infra", "date": "2021-03-21 00:00:00 +0900", "snippet": " 분산 queue system resource를 많이 사용해야하는 업무 발생시 내부 처리X. 다른 프로세스에서 작동중인 백그라운드에 위임 데이터 hub 데이터 업데이트 발생 시 해당 데이터를 사용하는 다른 서비스들에게 전파 e.g ) A 사용자가 B 사용자를 친구로 추가했을 때 해당 업데이트를 Kafka의 topic에 이벤트로 입력. 이 이벤트는 통계 시스템이나 타임라인 등 서비스로 전파 데이터가 하나의 클러스터에 집중. 데이터를 사용하는 서비스가 해당 데이터를 쉽게 찾을 수 있음 reference)https://engineering.linecorp.com/ko/blog/how-to-use-kafka-in-line-1/" }, { "title": "동치연산자 &#39;==&#39; vs &#39;===&#39;", "url": "/posts/%EB%8F%99%EC%B9%98%EC%97%B0%EC%82%B0%EC%9E%90/", "categories": "Study, JavaScript", "tags": "javascript, js", "date": "2021-03-16 00:00:00 +0900", "snippet": "’==’ : Equality 피연산자가 다른 타입이면 강제 형변환을 통해 비교. (값 비교) 예시 0 == &#39;&#39; // true0 == &#39;0&#39; // true1 == true // truefalse == &#39;0&#39; // truenull == undefined // truefalse == null // falsefalse == undefined // false2 == true // false&#39;true&#39; == true // false ’===’ : Identity 형변환을 하지 않고 엄격한 비교 (값 &amp;amp; 자료형) 가능한 이 것을 사용할 것을 권장(자료형을 직접 변환해 비교함으로써 가독성 높이도록) 예시 0 == &#39;&#39; // false0 == false // false1 == true // false&#39;abc&#39; == new String(&#39;abc&#39;) // falseNaN == NaN // false. (NaN은 어떤 것과도 같지 않음)null == undefined // false. (typeof null == &quot;object&quot; /typeof undefined == &quot;undefined&quot;) Reference)https://hyunseob.github.io/2015/07/30/diffrence-between-equality-and-identity-in-javascript/http://guswnsxodlf.github.io/javascript-equal-operatorhttps://velog.io/@filoscoder/-%EC%99%80-%EC%9D%98-%EC%B0%A8%EC%9D%B4-oak1091tes" }, { "title": "스레드(Thread)", "url": "/posts/%EC%8A%A4%EB%A0%88%EB%93%9C(Thread)/", "categories": "Study, OS", "tags": "os, 운영체제", "date": "2021-03-15 00:00:00 +0900", "snippet": ": 프로세스의 실행 단위. 프로세스 내 주소 공간이나 자원 공유. 스레드 ID, 프로그램 카운터, 레지스터 집합, 스택으로 구성 다른 스레드와 stack, PC register 제외 나머지 영역 공유해 상호간 통신 프로세스와 비교했을 때 context switch 시간이 짧음(캐시를 비우지 않아도 됨) 스레드 크기는 1MB. 프로세스에 할당되는 한 어플리케이션 메모리 최대한도가 일반적으로 2GB이므로약 2천개가 최대? 따라서, 스레드 생성 불가라는 에러는 메모리 문제 멀티 스레드: 프로세스 내에 다수의 스레드가 존재해, 자원을 공유해 수행 능력을 향상 시키는 것.스레드마다 독립적으로 할당받는 것 스택 영역 로컬 변수, 되돌아갈 함수 주소, 매개변수 인자 등 함수 내에서 사용하는 것들을 저장하는 공간이므로 독립적으로 함수를 호출하기 위해. 따라서 스레드마다 독립적인 실행 흐름을 갖게 됨. PC 레지스터 스레드가 명령어 어디까지 수행했는지를 저장. PCB에서 CPU 레지스터 중 하나. 독립적인 흐름 내에서 각 스레드가 어디까지 수행했는지를 알기 위해 이 부분을 독립적 할당 멀티 스레드에서 스레드간 통신방법: 스레드간 통신이 필요한 경우 별도 자원을 사용하진 않고, data영역과 heap영역, code영역을 공유. 프로세스간 통신 방법에 비해 간단함. 프로세스간 통신(IPC)에는 공유 메모리 사용, 메시지 큐, 소켓 등 다른 기법들이 존재 context switch시 캐시 메모리를 비울 필요 없음. -&amp;gt; context switch 빠름멀티 스레드 문제점 데이터, 힙을 공유하기 때문에 공유 자원(임계영역)에서 의도하지 않은 값을 불러오는 경우가 발생할 수 있음 동기화 작업이 필요(스핀 Lock, Mutex, Semaphore 등) =&amp;gt; 과도할 경우 성능 저하멀티 스레드 vs 멀티 프로세스 멀티 스레드 하나의 프로세스 내부에서 여러 스레드 동시 수행 동기화 문제: 스레드 하나 종료시 전체 스레드 종료 멀티 프로세스 멀티 쓰레드처럼 여러 개의 CPU 사용해 동시 수행. 동기화 문제: 하나의 프로세스 종료 시 다른 프로세스에 영향 없음. 그러나, 많은 메모리, CPU 시간 차지 차이점을 이해하고, 시스템에서 적절한 것을 선택해야 함병렬성과 동시성 병렬성: 실제로 동시에 병렬적으로 처리하는 Task 수는 CPU의 코어 수이다. 2 코어라고 한다면, 두 task에서 수행되는 쓰레드들은 병렬적이라고 볼 수 있다. 동시성: 한 코어 내에서 아주 빠른 context switch를 발생시키며 동시에 처리하는 것처럼 보이는(엄밀히 말하면 아니다) 멀티스레드의 환경은 동시성의 특징을 갖는다.Reference)https://github.com/JaeYeopHan/Interview_Question_for_Beginner/tree/master/OS#cpu-%EC%8A%A4%EC%BC%80%EC%A4%84%EB%9F%AChttps://goodgid.github.io/What-is-Thread/" }, { "title": "Http 통신과 Socket 통신", "url": "/posts/Http_%ED%86%B5%EC%8B%A0%EA%B3%BC_socket_%ED%86%B5%EC%8B%A0/", "categories": "Study, Web socket", "tags": "웹소켓, web socket", "date": "2021-03-12 00:00:00 +0900", "snippet": ": Client, server간 데이터를 주고받기 위한 통신Socket OSI에서의 L4계층(TCP 또는 UDP를 이용하기 위한 수단. 일종의 창구 역할) Transport layer 전통적인 통신 방식. 통신의 end point 바이트 스트림으로 통신 client-server 통신 과정을 직접 구현해야함. 주거나 받은 데이터를 개발자들이 알아서 formatting(parsing)해야함. TCP 소켓 - 연결이 되어있는 상태에서 통신을 주고 받음. 따라서 양방향 통신이라고 함 실시간 통신에 적합 e.g) 채팅서버, 게임, 전화 실시간 streaming 서비스를 Http로 구현한다면? 계속해서 연결을 요청하기 때문에 오버헤드 &amp;lt;-&amp;gt; HTTP 통신은 Client가 필요한 경우에 요청을 보내는 점에서 다름 (HTTP의 비연결성) UDP 소켓 - 비연결형 소켓 통신. 데이터가 유실되어도 알 방법이 없다. 그냥 상대방 주소로 보내놓고 보냈다고 믿기 Http Rest, RPC, gRPC, … TCP계층에서 Application 계층에 속함 어플리케이션 개발에 주로 사용 Client의 Request가 있을 때 Server에서 Response 전달 Server가 Client에게 요청을 보낼수는 없음 비연결성 - 응답 받고서는 바로 연결 종료, 이러한 점에서 단방향 통신 e.g. ) F5 누르면 해당 페이지 다시 요청하는 것.(결과는 300대 status로 리다이렉션) c.f) DDOS 공격: F5를 계속 누르듯, 대량의 요청을 계속 보내 서버를 다운 실시간이 아니고 필요한 경우에만(부하를 줄이기 위해) HTTP통신에 적합한 것을 Socket통신을 통해 구현하면 연결을 게속 유지해 오버헤드 Reference)https://velog.io/@bmh8993/REST%EC%99%80-RPCgRPC%EA%B0%80-%EB%93%B1%EC%9E%A5%ED%95%98%EA%B8%B0%EA%B9%8C%EC%A7%80https://m.blog.naver.com/jevida/140189691025https://mangkyu.tistory.com/48https://hwanine.github.io/network/Socket-Http/https://juyoung-1008.tistory.com/13" }, { "title": "임계영역(Critical section)", "url": "/posts/%EC%9E%84%EA%B3%84%EC%98%81%EC%97%AD(Critical_section)/", "categories": "Study, OS", "tags": "os, 운영체제", "date": "2021-03-12 00:00:00 +0900", "snippet": ": 멀티 스레드 환경에서 고려해봐야 할 영역. 동일한 자원에 접근할 때 해당 영역을 임계영역이라고 함.임계영역 문제 다른 스레드에서 사용할 공유자원을 변경해 의도치 않은 사이드이펙트를 얻게 되는 경우 임계영역을 공유해 효율을 올리며(동시성), 부작용을 막아 적절히 함께 사용할 수 있도록 프로토콜 설계임계영역문제를 해결하기 위한 조건 Mutual Exclusion(상호 배제) 한 프로세스가 임계영역 사용중이라면 다른 프로세스는 들어올 수 없음 Dead lock을 발생시키는 조건 중 하나 Progress(진행) 임계영역에서 실행중인 프로세스가 없을 때 별도의 동작 없는 프로세스들이 진입 후보로 참여될 수 있음 Bounded waiting(한정적 대기) 대기에는 한정이 있어야 함. 프로세스가 해당 임계영역에 들어갈 수 있는 횟수 제한(limit)을 두어, Starvation 방지 임계영역문제 해결책 - Spin Lock, Mutex, SemaphoreLocking 메커니즘: 임계영역에 들어가는 프로세스는 Lock을 획득, 나올 때 Lock 방출Spin Lock(스핀 락): “조금만 기다리면 바로 쓸 수 있는데 굳이 context switch 해야하나??” 할 때 사용 Locking 메커니즘 사용 Busy waiting : 진입 전까지 계속 루프를 돌면서 확인. polling 방식과 유사 context switch 하지않음 : 짧은 시간 안에 진입할 수 있는 경우 context switch 비용이 절감되지만, 반대로 말하면 다른 스레드를 실행 불가(동시성 저하) 하드웨어 기반으로 해결. 소프트웨어 알고리즘은 느려서 사용하지 않는다고 함. 피터슨 알고리즘 : flag(누가 임계영역 들어갈지), turn(누가 임계영역 들어갈 차례인지)이라는 변수를 사용. 인터럽트를 disable -&amp;gt; enable하는 방법 void func0() { flag[0] = true; turn = 1; while (flag[1] == true &amp;amp;&amp;amp; turn == 1) {} // busy waiting flag[0] = false;} void func1() { flag[1] = true; turn = 0; while (flag[0] == true &amp;amp;&amp;amp; turn == 0) {} // busy waiting flag[1] = false;} Mutex(상호 배제) Locking 메커니즘 사용 스핀 락과의 비교 공통점: 임계영역에 하나의 스레드만 접근 가능(Lock을 하나의 스레드만 가질 수 있음) 차이점: Busy waiting이 아니라 sleep 상태로 들어가 context switch하고 다른 태스크를 수행하다가 wakeup 되는 방식 0, 1만을 가진 이진(binary) 세마포어와 유사 Lock을 가진 스레드가 반드시 나갈 때 그 락을 해제해야 함. -&amp;gt; 이진 세마포어와의 차이점. Semaphore Counting Semaphore 매커니즘. 임계영역(자원)에 접근할 수 있는 스레드 개수를 정해놓음. 방출 시 세마포 증가, 진입 시 감소 이진 세마포어와 뮤텍스의 차이점: 뮤텍스는 나갈 때 나가는 스레드가 lock을 해제해야 하는데, 세마포어에서는 lock을 걸지 않은 스레드가 signal()을 이용해 lock 해제 가능. 단점이 발생하는 경우 busy waiting: 초기의 세마포는 임계영역에 진입해야 하는 프로세스는 진입 코드를 계속 반복 수행해 CPU 시간 낭비했었음 이러한 단점 해결을 위해 진입 실패한 스레드 block시킨 후, 임계영역 진입이 가능할 때 깨워주는 형태 DeadLock: 각 스레드들이 서로가 점유하고 있는 자원들을 얻어야 하는 상황일 때 무한정 기다리게 되는 문제Reference)https://brownbears.tistory.com/45https://github.com/JaeYeopHan/Interview_Question_for_Beginner/tree/master/OS#%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4-%EB%8F%99%EA%B8%B0%ED%99%94https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Operating%20System/DeadLock.mdhttps://gameproyyj.tistory.com/153https://thinkpro.tistory.com/124https://www.crocus.co.kr/1371" }, { "title": "Hoisting", "url": "/posts/Hoisting/", "categories": "Study, JavaScript", "tags": "javascript, js", "date": "2021-03-12 00:00:00 +0900", "snippet": ": 사전적 의미로 “끌어올리기”. 선언되는 모든 변수는 호이스트된다.(끌어올려진다)특징 ECMA2015(ES6). 2015년도 이후로 나왔다.(let, const, 화살표함수, 디스트럭쳐링과 더불어) 물리적으로 코드가 옮겨지는 것이 아니고, 컴파일 단계에서 변수 및 함수 선언이 메모리에 저장되는 것foo(&quot;abc&quot;);function foo(text) { console.log(&quot;print: &quot; + text);}// 결과- print: abc선언과 할당 변수의 정의가 그 범위에 따라 선언과 할당으로 분리된다. 선언은 호이스팅, 할당은 호이스팅 X 따라서, 함수 선언이 함수를 실행하는 부분보다 뒤에 있어도 JS엔진은 실행되기 전에 함수 선언을 끌어올리기 때문에 가능한 것. console.log(foo); // undefined var foo = 2; console.log(foo); // 2 함수의 경우도 마찬가지. 그러나, 선언문과 표현식에서 차이가 있다. 함수 선언문: 자바스크립트 엔진은 스크립트 실행 전, 초기화 단계에서 전역에 선언된 함수 선언문을 찾고, 해당 함수를 생성. 함수 표현식: 실행 흐름이 let foo = function...의 우측 표현식에 도달했을 때 함수가 생성된다. 이 방식대로 한다면, 함수가 할당된 변수가 존재하는 컨택스트라면 해당 함수를 사용 가능하다는 특징 함수를 값처럼 할당, 복사 var foo2; // 변수값 선언 foo(); // hello foo2(); // Error: foo2 is not a function. function foo() { // 함수 선언식 console.log(&quot;hello&quot;); } foo2 = function() { // 함수 표현식 (호이스팅 x). 실제로 도달했을 때 함수 선언. console.log(&quot;hello2&quot;); } 함수 스코프 내 호이스팅 - 함수 내에서만 호이스팅 된다. function foo() { for(var j = 0; j &amp;lt; 10; j++) { alert(j); }}foo(); (function () { // IIFE for(var i = 0; i &amp;lt; 10; i++) { alert(i); }})() console.log(i); // Error: i is not definedconsole.log(j); // 실행도 안되고, 되어도 Error: j is not defined Reference)https://developer.mozilla.org/ko/docs/Glossary/Hoistinghttps://gmlwjd9405.github.io/2019/04/22/javascript-hoisting.html" }, { "title": "OSI(Open System Interconnection) 7계층", "url": "/posts/OSI_7%EA%B3%84%EC%B8%B5/", "categories": "Study, Network", "tags": "network, osi", "date": "2021-03-03 00:00:00 +0900", "snippet": ": 각 계층별 기능과 통신의 과정을 표준화해 네트워크를 편리하게 이해하기 위한 목적으로, 실무적으로, 교육의 목적으로 이용될 수 있도록 만든 모델캡슐화 아랫층으로 데이터를 넘길 때 각각의 레이어에서 붙일 수 있는 헤더를 붙이는 과정 윗 층(어플리케이션) HTTP 개발자는 아랫층 소프트웨어에 헤더가 붙는 과정을 보지 못한다. 2층에서는 오류제어를 위해 헤더가 아닌 데이터의 뒷부분에도 일부 데이터가 추가됨 PDU(프로토콜 데이터 유닛) 전송하려는 데이터 SDU(Service Data Unit) 와 제어 정보 PCI(Protocol Control Information)로 구성되어 있다. PCI에는 송신자와 수신자 주소, 오류 검출 코드, 프로토콜 제어 정보 등이 있다. 비캡슐화 전달받은 데이터가 윗쪽 계층으로 전해지면서 헤더가 벗겨지는 과정계층 별 역할1계층: 물리 계층(Physical Layer): 프레임을 전기신호(비트)로 변환해 케이블로 전송하는 계층 통신 단위 : 비트 (0 or 1) 단순히 데이터 전달만의 역할 1계층 장비 : 케이블, 리피터, 허브2계층: 데이터 링크 계층(Data Link Layer): 물리 계층을 통해 송수신되는 정보의 오류와 흐름을 관리해 안전한 정보의 수행을 도움. 통신 단위 : 프레임 물리적인 연결을 통하여 인접한 두 장치의 신뢰성 있는 정보 전송 물리 계층의 오류 수정 Mac(부 계층) 주소를 가지고 통신 Mac주소(Media Access Control) : 기기(컴퓨터)간 데이터를 전송하기 위해 사용되는 컴퓨터의 주소 (흔히들 IP주소라고 생각하지만, 정확하게는 IP주소를 Mac주소로 바꿔 물리적 위치를 찾아내는 것) MAC 테이블(ARP table)을 확인해서 있으면 그 주소로 보내고, 없으면 Network 상의 모든 곳으로 Broadcast 후 MAC 주소를 받아와서 저장한다. 2계층 장비 : 브릿지, 스위치.3계층: 네트워크 계층(Network Layer): 데이터를 목적지까지 안전하고 빠르게 전달하는 기능 통신 단위 : 패킷 (패킷을 통해 목적지 설정) L4의 TCP 세그먼트에 IP 패킷을 담아 보냄 라우터 기능 대부분이 여기 존재 A에서 B까지 어떻게 보낼지 방법은 무수히 많은데, 이 계층의 라우터가 이걸 효율적으로 처리 IP(직접 주소) 주소 사용, 라우팅(어떤 목적지로 전달할지 - 다익스트라), 흐름 제어, 오류 검사 데이터를 연결하는 다른 네트워크를 통해 전달 - &amp;gt; 인터넷이 가능하게 만드는 계층 3계층 장비 : 라우터, L3 스위치 netstat -r : r 옵션을 통해 routing table 확인 가능 4계층: 전송 계층(Transport Layer): 통신을 활성화하기 위한 계층 통신 단위 : 세그먼트 종단 간(End-to-End)에 신뢰성있는 데이터를 전송 상위 계층이 유효성이나 효율성 생각하지 않아도 됨. 송 수신자 연결 지원, 신뢰성, 흐름제어, 다중화 Port를 열어 응용 프로그램을 전송 (목적지의 어떤 포트로 전달할지) TCP 프로토콜, UDP 프로토콜 4계층 장비 : L4 스위치(3계층 트래픽 분석, 서비스 종류 구분)5계층: 세션 계층(Session Layer): 응용 프로그램 간 논리적 연결 지원, 응용 프로세스가 통신을 관리하기 위한 방법 정의 통신 단위 : Data(Message) 토큰이라는 특수 메시지 TCP/IP 연결(세션)을 관리. 연결이 손실되면 복구를 시도하거나, 오랫동안 연결되지 않으면 연결을 종료하고 재개한다. NetBIOS(세션 내 연결관리, 에러감지, 복구), SSH, Appletalk 등등6계층: 표현 계층(Presentation Layer): 데이터의 변환 작업. 응용 계층의 데이터 형식을 맞춰줌. 통신 단위 : Data(Message) 응용프로그램 형식과 네트워크 형식을 변환시켜준다. MIME 타입을 인코딩하거나 ASCII, JPEG, MPEG 등등 번역 전송하는 데이터의 인코딩, 디코딩, 암호화, 복호화7계층: 응용 계층(Application Layer): UI를 제공 통신 단위 : Data(Message) 인터페이스 역할: 사용자에게 보이며, 사용자와 가장 밀접. 개발자들이 실제로 비즈니스 로직을 작성하는 등 신경써야할 많은 부분이 이 계층에 속하게 된다. 크롬, 파이어폭스, 사파리, 이메일 등 Application HTTP, FTP, SMTP, Telnet등 프로토콜Reference)HTTP 완벽가이드https://ko.wikipedia.org/wiki/OSI_%EB%AA%A8%ED%98%95https://en.wikipedia.org/wiki/OSI_modelhttps://devowen.com/344https://ryusae.tistory.com/4https://velog.io/@inyong_pang/OSI-7-%EA%B3%84%EC%B8%B5%EA%B3%BC-TCPIP-%EA%B3%84%EC%B8%B5https://github.com/WeareSoft/tech-interview/blob/master/contents/images/data-encapsulation.png" }, { "title": "CLI", "url": "/posts/CLI/", "categories": "Study, Linux", "tags": "linux, 리눅스", "date": "2021-03-03 00:00:00 +0900", "snippet": "기초 / : Root 디렉토리 pwd : 현재 디렉토리 .... --help echo ~~~ : ~~~를 화면에 표준 출력(stdout) 디렉토리 삭제할 때 -r(recursively) touch aaa.txt : aaa.txt 만들기 grep : 내가 원하는 키워드가 포함되어있는 행을 찾아주는 명령어 tail -f aaa.log : aaa.log를 계속 감시하고 있다가 바뀔때마다 리프레시해서 보여줌 실시간 로그 볼때 편함 -f 5와 같이 보여줄 라인을 설정 가능 -u : –unlockgrep 사용하기 AND : cat a.log | grep 2021-09-14 | grep error| : 파이프라인을 이용해서 grep 두 조건에 만족하는 문장만 OR: cat a.log | grep -e 2021-09-14 -e error : 둘중 하나만 혹은 cat a.log | grep -E &quot;2021-09-14 | error&quot; NOT: cat a.log | grep -v error : 해당 조건 포함 안하는 경우만 cat a.log | grep -A 10 error : 해당 줄 아래 10줄까지 보여줄 것 cat a.log | grep -B 10 error : 해당 줄 위로 10줄 보여줄 것권한 ls - l로 권한 확인 가능 chmod : 파일의 권한(readable, writable, executable)을 바꿔줄 수 있음 change mode 약자 chmod o-r example.txt : other에게 read 권한 뺏음(소유자는 u, 그룹은 g) 파일 찾기 locate : 디렉토리를 돌면서 찾는 것이 아니고 mlocate라는 DB 를 뒤져서 위치를 찾는 것 e.g) locate *.log : log 파일 모두 찾기 find find [찾기 시작할 경로] [어떻게 찾을건지] [무엇을] e.g) find / -name *.log whereis: 실행파일이 어디에 있는지? whereis ls : ls 명령어가 어디에있는지? $PATH와 연관 : echo $PATH 명령어를 수행하면 bin 밑의 ls를 찾기 위해 PATH에 있는 경로를 전부 찾아다님. 따라서, 어떤 경로에서 ls를 수행하던, 우리가 원하는 ls를 수행 할 수 있는 것 FG(fore ground) fg : 백그라운드에 있던 프로그램을 포그라운드로 jobs: 현재 back ground로 실행되고 있는 것 무엇이 있는지 nano 작성 중 Ctrl + Z 누르면 back ground로, jobs로 확인 가능 help와 man(manual) help: 간단한 사용법 man: man ls 처럼 man + CLI. 더 상세할 수 있음 SSH 서버(리눅스) 컴퓨터에 접속해 서버를 제어하고자 할 때 리눅스가 서버 시장에서 많은 부분을 차지하기 때문에 SSH의 사용이 유용 ec2 로그인하기 : ssh -i &quot;key파일&quot; ubuntu@도메인 ssh -p 8080 ubuntu@도메인다중 사용자 id : 내 자신이 누구인지 who : 누가 현재 접속해있는지 sudo useradd -m aaa /home에서 ls를 보면 aaa 사용자가 추가된 것을 보게된다. su : switch user sudo -i : super user로 login하기 (== sudo --login)Redirection ls등과 같은 것들의 결과를 따로 저장 가능 echo &#39;hello world&#39; &amp;gt; example.txt 화면에 출력하는 것이 아닌 해당 파일에 출력 ls &amp;gt; example.txt : ls의 결과를 터미널에 출력(stdout)하는 것이 아닌, 파일로 저장시켜줌 stdout을 redirection해주는 것. stderror는 redirection해주지 않고 그냥 모니터에 출력될 것 -&amp;gt; error.log에 저장 가능 http://slideplayer.com/slide/5126304 확인프로세스 ps or ps aux(컴퓨터 내 모든 프로세스를 보려면 후자) ps aux | grep apache 처럼 사용 가능 포트 사용하는 IP PID 찾기 : sudo lsof -i:15672 해당 IP 죽이기: sudo kill -9 1335 netstat -ano -a` : 모든 연결과 대기중인 포트 -n : 주소, 포트 표시 -o : PID -p : 프로토콜 연결을 표시 패키지 매니저 apt-get update : 내가 현재 설치할 수 있는 프로그램 목록을 최신 상태로 반영해주는 CLI apt-cache search ~~~ : ~~~가 들어간, 다운받을 수 있는 것들 조회 apt-get install whereis ~~ : 내가 설치한게 어디있는지 알고 싶을 때redis service 계속 켜지는 문제 HA를 위해 꺼지면 다시 켜지는것? /etc/init.d/redis-server stop 을 이용하자. 서비스 관련 CLI /etc/init.d/redis-server start /etc/init.d/redis-server restart redis-cli shutdown (mac에서)포트 열어주기 iptables -I INPUT 1 -p tcp --dport 6379 -j ACCEPT &amp;lt;-&amp;gt; ufw allow 2337과 같은 ufw와 구별해서 사용Reference)http://slideplayer.com/slide/5126304https://opentutorials.org/course/2598https://bottlecok.tistory.com/16" }, { "title": "NPM CLI", "url": "/posts/NPM_CLI/", "categories": "Study, Node.js", "tags": "node.js", "date": "2021-03-02 00:00:00 +0900", "snippet": "기본 CLI npm init : package.json 생성 npm install : 패키지 설치 현재의 package.json에 맞게 모듈 맞춰줌 --dev 를 붙이면 dev dependencies 에 등록된다. 프로덕션 환경에서는 적용되지 않음? 프로덕션 환경: 라이브 환경(실제 실행한 상황) npm start: 패키지 시작 npm update: 패키지 업데이트노드 버전 관리 nvm use 14.15.4 : 14.15.4 사용할 것이다.(현재의 터미널 탭에 한해서) 따라서, 새로운 bash에서 nvm version 을 쳐보면 이전 버전(default)를 사용하고 있다고 나오는 것 확인 nvm alias default node : 최신 버전을 디폴트로 nvm alias default node 14.15.4 해당 버전을 디폴트로 혹은 bashrc에서 스크립트를 수정하면, 새로운 bash가 뜰 때 해당 스크립트를 수행하고, 그 때마다 버전을 바꿔서 실행하게 된다. " }, { "title": "TCP / IP 프로토콜의 4계층", "url": "/posts/TCP_IP_4%EA%B3%84%EC%B8%B5/", "categories": "Study, Network", "tags": "network, tcp/ip", "date": "2021-03-01 00:00:00 +0900", "snippet": " OSI 계층과는 층을 구분하는 것이 다르고 실제 하는 일은 같다고 보면 된다.1계층: 네트워크 인터페이스 계층: TCP/IP 패킷을 받고, 보내는 역할 OSI의 1, 2계층 에러를 검출하는 역할, 물리적 목적지(mac 주소)를 알아내는 역할2계층: 인터넷 계층: Routing 역할로 목적지까지의 전달을 담당 OSI의 3(네트워크)계층 IP 프로토콜. 목적지 주소인 IP 헤더를 추가해 하위 layer로 전달한다.3계층: 전송 계층: 신뢰성있는 전송을 담당 OSI의 4(전송)계층 논리 주소인 포트를 가지고 있다. 포트를 갖고 여러 개의 TCP 커넥션(한 IP에서 각 Port를 통해 각 커넥션 구별)을 유지 TCP, UDP4계층: 응용 계층: 서비스에 접근할 수 있는 어플리케이션 제공 OSI의 5~7 계층 데이터들을 실제 사용자에게 사용성 있게 보여지도록하는 어플리케이션의 역할을 한다. HTTP, Telnet, SSH, FTP 등Reference)https://www.ibm.com/docs/ko/aix/7.1?topic=management-transmission-control-protocolinternet-protocol" }, { "title": "Javascript 기초, 문법", "url": "/posts/Javascript_basic/", "categories": "Study, JavaScript", "tags": "javascript, js", "date": "2021-03-01 00:00:00 +0900", "snippet": "JavaScript 타입 시스템이 없는 동적 프로그래밍 언어. 따라서 런타임 에러가 많이 발생할 수 있다. RTE: 프로그램에서 수행할 수 없는 동작을 시도할 때 발생 컴파일 error: 컴파일 타임에 발생. 주로 문법적 오류 비교적 유연하게 개발할 수 있는 환경 제공 동적 타입 언어 // javascript는 동적 타입 언어이기 때문에 이러한 경우에도 에러 발생 xlet message = &quot;hello&quot;;console.log(message); // hellomessage = 123456;console.log(message); // 123456 TypeScript TS는 JS 기반으로 만들어졌다.(컴파일 시 javascript 파일로 컴파일됨.) 정적 타입을 지원해서 컴파일 단계에서 오류를 포착 가능. 타입을 명시함으로써 가독성 또한 높다. 객체지향 언어로, 데이터 추상화에 중심을 두는 언어.Closure 콜백을 구현하는 이상적인 구조중요한 점 : 클로저가 참조하고 있는것이 실행될 때의 환경을 기억하고 있기 때문에, 이러한 성질로 비동기가 가능한 것. 콜백이 다른 시점, 다른 위치에서 호출된다 할지라도, 비동기 함수의 호출자의 Context를 그대로 유지 반환된 내부함수(생명주기가 끝난)가 자신이 선언되었을 때의 환경인 스코프를 기억해 선언되었을 때의 환경 밖에서 접근할 수 있다. var name = `Warning`;function outer() { var name = `closure`; return function inner() { console.log(name); };} var callFunc = outer();callFunc();// console&amp;gt; closure 여기서 outer 내부의 name 변수를 자유변수라고 한다. 어떤 데이터(환경)과 그 데이터를 조작하는 함수를 연관시킨다. function makeAdder(x) { var y = 1; return function(z) { y = 100; return x + y + z; };} var add5 = makeAdder(5);var add10 = makeAdder(10);//클로저에 x와 y의 환경이 저장됨 console.log(add5(2)); // 107 (x:5 + y:100 + z:2)console.log(add10(2)); // 112 (x:10 + y:100 + z:2) 이러한 맥락에서 객체지향과 비슷하다고도 말한다. 캡슐화: 어떠한 데이터 자체는 숨기고, 그 데이터를 조작하는 메서드는 노출 function redTeam() { score = 0; return function() { return score++; }} var goal = redTeam();console.log(goal());console.log(goal());console.log(goal());-------------------------결과:012 forEach() vs map() forEach 값 반환 X 각 요소에 대한 콜백을 수행. (현재 배열을 변경해서 반환). map보다 빠르다. JS에서는 for-loop가 더 빠르고, kotlin에서는 forEach(Collection의 경우)가 더 빠르다. 원래의 배열을 바꿀 염려 있음. 주로 DB 저장과 같은 일에 사용됨 map 값 반환 O 각 요소에서 함수를 호출하고, 결과로 새로운 배열을 만들어냄. 원래의 배열에 영향을 주지 않기 때문에 함수형 프로그래밍에 더 적합. forEach와 map 각각은 서로가 할 일을 대체할 수 있음Type(대, 소문자 차이점) 대문자는 Wrapper object이고, 소문자는 primitive type이다. 따라서 소문자 권장!! (Double Exclamation) Not 연산자인 !는 입력값을 boolean으로 변경해, true -&amp;gt; false, false -&amp;gt; true로 변환해주는 논리연산자 !!는 다른 타입의 데이터를 boolean 타입으로 명시적 형변환.var a;console.log(a); // undefinedconsole.log(!a); // true;console.log(!!a); // false;var a = &quot;test&quot;; //a: &quot;test&quot; (조건문 적용시 true) var b = !&quot;test&quot;; //b: false var c = !!&quot;test&quot;; //c: true출처:https://ifuwanna.tistory.com/278 [IfUwanna IT]https://hermeslog.tistory.com/279 boolean 타입이 아니면서 false가 되는 경우(이외에는 모두 기본적으로 true) ”” : 빈 문자열 NaN : Not a Number undefined null 0 Reference)모던 JavaScript 튜토리얼 https://ko.javascript.info/introNode.js 디자인패턴https://moollang.tistory.com/10https://ifuwanna.tistory.com/278https://hermeslog.tistory.com/279" }, { "title": "Kafka 이해하기 (vs rabbitMQ)", "url": "/posts/Kafka_%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0(vs_rabbitMQ)/", "categories": "Study, Kafka", "tags": "kafka, infra", "date": "2021-02-22 00:00:00 +0900", "snippet": "RabbitMQ와 가장 큰차이: Consumer가 Broker로부터 메시지를 pull하는 방식 single consumer가 아닌 multi consumer를 염두에 두고 설계되었기 때문에 그러한 환경에서 rabbitMQ보다 성능이 좋다. RabbitMQ에서는 하나의 일을 하나의 consumer가 처리하기 위해 work queue 정책 Pull 방식으로 Consumer가 처리할 수 있을 때 메시지를 가져오므로 자원을 효율적으로 사용 Kafka는 메시지를 disk에 저장(영속성?)하고, 과거의 offset을 통해 움직일 수 있으므로 batch 작업에서 자원의 낭비나 지연이 발생하지 않음 메시지를 쌓아두었다가 처리하는 batch Consumer 구현도 가능 Messaging system이라고 할 수 있다.동작 방식 pub/sub 모델 기반 동작. Producer, consumer, broker 구성. 특정 수신자에게 직접 보내주는 시스템이 아님. publisher는 메시지를 topic을 통해 카테고리화 consumer는 해당 topic을 subscribe해 메시지를 읽어올 수 있음.Zookeeper 클러스터 내의 broker 분산은 ZooKeeper가 담당 카프카의 노드 관리. Broker는 클러스터로 구성되어 동작 과반수 투표방식. 홀수로 구성장점 메시지를 파일시스템에 저장 - durability 보장. Producer 중심적. 많은 양의 데이터를 파티셔닝에 기반.RabbitMQ: Message Broker가 Consumer에게 메시지를 push하는 방식 Broker는 Consumer의 처리여부에 관계없이 push 따라서 메시지 소비 속도보다 생산 속도가 빠를 경우 Consumer에 부하를 주게 됨 RabbitMQ는 DRAM을 사용하므로 buffer를 사용하지만, DRAM을 다 사용하면 disk에 저장한다. 따라서 batch 같이 큰 작업에서는 disk로 메시지를 읽어올 경우 지연이 발생합니다. RPC, Queue, 여러 서버에 Routing 등등 여러가지로 활용 가능 개방형 프로토콜을 위한 AMQP 구현을 위해 개발RabbitMQ 장점 유연한 routing 가능 데이터 처리보단 관리적 측면이나 다양한 기능 구현을 위한 서비스를 구축할 때 사용Reference)https://www.popit.kr/kafka-%EC%9A%B4%EC%98%81%EC%9E%90%EA%B0%80-%EB%A7%90%ED%95%98%EB%8A%94-%EC%B2%98%EC%9D%8C-%EC%A0%91%ED%95%98%EB%8A%94-kafka/" }, { "title": "Web Socket이란", "url": "/posts/Web_Socket/", "categories": "Study, Web socket", "tags": "웹소켓, web socket", "date": "2021-02-15 00:00:00 +0900", "snippet": ": HTML 5 표준 기술로, 하나의 HTTP 접속을 통해 클라이언트, 서버 간 실시간 양방향 연결 채널을 구성. Web hook: 양방향 통신이기 때문에 서버쪽이 업데이트 되는 상황에서도 client쪽 화면을 refresh해줄 수 있다. 기존 방식 (client가 server로 AJAX 요청. 단방향) Traditional Polling: 주기적으로 client가 AJAX 요청해 결과를 확인한다. 너무 리소스 낭비가 크다. Long Polling: client가 AJAX 요청을 하면 server는 연결 안끊고 기다리다가 완료되면 response. 이 방식이 가장 보편적이었다고 한다. HTTP Streaming: 연결 안끊고 그냥 server쪽에서 응답 발생할때마다 response. 연결에 대한 오버헤드 존재해서 이 방식도 주기적으로 끊기는 한다. 많은 곳에서 Polling 방식을 대체하는 기술이라고 설명된다. 그러나, 모든 프록시나 방화벽에서 허용되는 것이 아니라서 보편적으로 사용되진 않는다. Stateful protocol. 한번 연결되면 같은 라인을 사용해 통신. -&amp;gt; HTTP 연결 트래픽 감소하지만 연결을 유지해야한다. HTTP와 같은 포트 사용한다. 연결 시 핸드쉐이크는 HTTP를 통해 이루어지고, 이후에는 WS 프로토콜로 통신. 일정 시간 뒤 HTTP 연결 disconnect 일반적으로 문제 발생으로 연결이 끊길 때를 대비해 reconnect 매커니즘을 제공한다.Rest와의 비교 REST에서는 많은 URI를 통해 application 설계되는데, 웹소켓은 하나의 URL로 Connection 생기고, 이후 해당 Connection으로만 통신 Handshake 완료되고 Connection 유지 REST(Http 통신)에서는 요청-응답 후 Connection close된다. 따라서 이론상 하나의 server가 port수의 한계(n &amp;lt; 65535) 를 넘는 client 요청 처리 가능 WebSocket 통신은 접속에 HTTP를 사용, 그 후는 WS 프로토콜을 이용 헤더가 작아 오버헤드 적다.라이브러리SockJS 구버전 브라우저에서는 websocket을 지원하지 않는데, spring에서는(Stomp를 사용할 때) sockjs-client를 사용하는 client와 합을 맞춰 webSocket을 사용할 수 있다.Socket.io Node.js 기반, WS를 안정적으로 사용하기 위한 것 WS가 비교적 최근에 나온 기술이라 구 버전의 웹 브라우저는 웹 소켓을 지원하지 않음HTML5 플러그인을 사용하지 않고 웹 서비스 제공(멀티미디어 등 많은 기능) Plug-in은 서비스 제공자의 편의성이 매우 높다는 장점 사용자는 Active-X와 같은 플러그인 설치로 서비스 이용 가능 Plugin은 i.e에서만 사용 가능. 웹소켓 지원.Ajax와의 비교 채팅 시스템이라고 한다면, Ajax에서는 10초마다 데이터를 갱신해 확인하는 방식 데이터 과부하적인 측면 WS에서는 서버에서 Client를 인지하는 상태 브라우저에서 호출해서 데이터를 가져가는 기능이 있기 때문에 서버측에서 PUSH 가능 Reference)https://edu.goorm.io/learn/lecture/557/%ED%95%9C-%EB%88%88%EC%97%90-%EB%81%9D%EB%82%B4%EB%8A%94-node-js/lesson/174379/web-socket%EC%9D%B4%EB%9E%80https://duckdevelope.tistory.com/19https://webclub.tistory.com/491https://supawer0728.github.io/2018/03/30/spring-websocket/" }, { "title": "JavaScript와 관련해 겪은 이슈들, 간단한 메모", "url": "/posts/Javascript_Issues/", "categories": "Study, JavaScript", "tags": "javascript, js", "date": "2021-02-15 00:00:00 +0900", "snippet": "200215 typeof (ABC) (x) → typeof ABC200223 나머지 매개변수는 가장 마지막 인자에 들어와야 한다. function foo(...rest) {} // O function foo2(arg1, ...rest, arg2) {} // X 에러 발생 200324 javascript에서 { 를 선언문과 같은 줄에서 시작해야 하는 이유 https://stackoverflow.com/questions/3641519/why-do-results-vary-based-on-curly-brace-placement " }, { "title": "개발하며 겪은 이슈들, 간단한 메모", "url": "/posts/Dev_Issues/", "categories": "Study, Develop", "tags": "develop", "date": "2021-02-15 00:00:00 +0900", "snippet": "210215 EOL 처리: 작성 file 끝에 new line 넣어주기(cat 관련 문제) 파일이 끝났다고 판단하지 못하는 문제 때문 ID라는 변수명 설정 ID vs Id : Id승. 가독성이 좋고 더 많이 쓰임 e. g) userIdWithRoom 처럼 카멜케이스 중간에 오는 경우 디렉토리 설계 컴포넌트 예: 자족적인 컴포넌트 기반으로 설계 역할별 예: 기술적인 역할별로 모으기 (DDD 관점) 210407lint vs prettier lint: 코드 정적 분석 코딩 컨벤션에 어긋나는지 안티패턴 검출 간단한 code formatting 여태 사용하던건 lint에 prettier의 포메팅 기능을 포함했던 것. prettier: 코드가 예쁘게 보이는지 코드 최대 길이 작은 따옴표 or 큰 따옴표 use prettier for formatting and linters for catching bugs! eslint-plugin-prettie Prettier를 ESLint 플러그인으로 추가한다. 즉, Prettier에서 인식하는 코드상의 포맷 오류를 ESLint 오류로 출력해준다. 210417 보고싶은 깃헙 레포지토리에서 URL에 github.com -&amp;gt; github1s.com으로 바꿔주면 vscode 웹으로 열린다(readonly) Github1s - GitHub코드를 VS Code로 1초만에 둘러보기reference)https://minz.dev/19https://github.com/goldbergyoni/nodebestpractices/blob/master/sections/projectstructre/breakintcomponents.korean.md" }, { "title": "this vs self", "url": "/posts/this_self/", "categories": "Study, JavaScript", "tags": "javascript, js", "date": "2021-02-12 00:00:00 +0900", "snippet": "this JS의 모든 함수는 기본적으로 실행될 때마다 함수 내부에 this 객체가 추가된다. 현재 컨텍스트를 참조 기본적으로 전역 객체 참조 객체의 메서드를 호출했을 때 - 호출 객체 참조var myObject = { name: &quot;foo&quot;, sayName: function() { console.log(this); }};myObject.sayName();// console&amp;gt; Object {name: &quot;foo&quot;, sayName: sayName()}// this는 myObject를 참조 new 키워드를 통해 생성자 함수를 호출할 때 - 생성하는 객체 참조var Person = function(name) { console.log(this); this.name = name;};var foo = new Person(&quot;foo&quot;); // Personconsole.log(foo.name); // foo apply(), bind(), call() 첫번째 인자로 넘겨받은 객체를 참조. apply: func.apply(this, [param1, param2]) bind: func {}.bind(this, param1, param2) call: func.call(this, param1, param2) e.g) bind 메서드 예시 var value = 100;var myObj = { value: 1, func1: function() { console.log(`func1&#39;s this.value: ${this.value}`); var func2 = function(val1, val2) { console.log(`func2&#39;s this.value ${this.value} and ${val1} and ${val2}`); }.bind(this, `param1`, `param2`); func2(); }};myObj.func1();// console&amp;gt; func1&#39;s this.value: 1// console&amp;gt; func2&#39;s this.value: 1 and param1 and param2self 예약어가 아니고 자주 사용되는 variable이다. 따라서 개발자가 그냥 정의해서 사용한다. var self 주로 window를 참조할 때 쓰인다 var self = this 중첩으로 함수를 리턴하는 곳에서 많이 사용(이전 컨텍스트의 this 를 유지하고 싶을 때) var a = { b: &quot;c&quot;, func: function(){ var self = this; console.log(&quot;outer this.b = &quot; + this.b); console.log(&quot;outer self.b = &quot; + self.b); (function(){ console.log(&quot;inner this.b = &quot; + this.b); console.log(&quot;inner self.b = &quot; + self.b); }()); }}a.func(); ------ 결과 outer this.b = c // this는 오브젝트 a를 가리킴outer self.b = c // self는 로컬 스코프(a 내부)를 가리킴inner this.b = undefined // this는 오브젝트를 가리켜야 하나, 이 내부함수를 invoke(call)하는 오브젝트가 없으므로 this는 글로벌 오브젝트 window(func 내부)를 가리킴. 하지만 window에는 b라는 속성이 없으므로 undefinedinner self.b = c // self는 로컬 스코프 a를 가리킴 출처 : https://velog.io/@woohyun_park/self-vs-this Reference)https://github.com/JaeYeopHan/Interview_Question_for_Beginner/tree/master/JavaScript#this-%EC%97%90-%EB%8C%80%ED%95%B4%EC%84%9Chttps://k9e4h.tistory.com/141https://velog.io/@woohyun_park/self-vs-thishttps://m.blog.naver.com/PostView.nhn?blogId=rjs5730&amp;amp;logNo=221093328140&amp;amp;proxyReferer=https:%2F%2Fwww.google.com%2F" }, { "title": "Redis와 관련해 겪은 이슈들, 간단한 메모", "url": "/posts/Redis_Issues/", "categories": "Study, Redis", "tags": "redis, 레디스", "date": "2021-02-11 00:00:00 +0900", "snippet": "200216 pub/sub(redis)에서 subscribe한 객체는 broadcasting을 받기 위해 무한히 blocking된다. → 이것이 sub을 또 다른 목적으로 사용할 수 없는 이유 ? 따라서 일반적으로 client를 정의할 때 pub / sub / client 세개를 정의하거나 sub / pub + client 두개를 사용. Socket server 여러개가 동작하고 broadcasting 하게 하려면 socket.io-redis 라이브러리 사용 각 node에게 event를 배포하기 위해 redis의 pub/sub을 이용 하나의 서버에서 pub/sub을 만들고 연결해놓고 나중에 현재서버에서 접속이 들어오면 다른 서버들에 publish해서 알려주고 다른 서버는 구독중. reference)https://github.com/socketio/socket.io-redis/issues/21#issuecomment-60315678" }, { "title": "Kotlin 특징", "url": "/posts/Kotlin_%ED%8A%B9%EC%A7%95/", "categories": "Study, Kotlin", "tags": "kotlin", "date": "2021-02-08 00:00:00 +0900", "snippet": "함수형 프로그래밍(함수가 일급 객체로서의 의미를 가짐): 함수를 side effect 없도록 선언하고 사용하는 선언형 프로그래밍.e.g ) forEach vs map : map이 함수형에 가깝다. forEach는 원 배열에 side effect가 발생할 가능성이 있지만, map의 경우 원래의 배열을 바꾸지 않고 새로운 배열을 만들어버린다.가장 큰 두가지 특징 Immutable 변경 불가능. 만약 변경이 필요하면 새로운 Immutable 변수 or 객체를 하나 만듦으로 해결. Persistent data structure 일급 객체 변수나 데이터에 함수를 담을 수 있다. 함수를 literal로(표현식) 바로 정의할 수 있다. 리턴값으로 전달 가능 함수를 파라미터로 전달 가능 val sum = fun Int.(other: Int): Int = this + other 연속 전달방식(Continuation-Passing Style): 결과를 계속 전달하는 방식 stream: filter().map()과 같이 결과를 계속 전달 자바스크립트에서 결과를 계속 콜백으로 전달하는 것Java와 동일한 타입안정성 + 타입 추론(Inference) 제공.(Smartcasting) val name = &quot;abced&quot; &amp;lt;- 이 경우 알아서 String으로 인식Null 체크 용이 Nullable var foo: String? = &quot;Hello&quot; foo?.bar()// foo != null ? foo.bat() : null Not-Null Assertion(!!) Elvis operator ?: val foo: String? = getString() return foo?.length ?: 0// return foo != null ? foo.length : 0 Extentionfun String.double(): String { return this + this}println(&quot;Hello&quot;.double()) // HelloHelloCompanion object 어떤 클래스의 모든 인스턴스가 공유하는 객체 만들 때. 자바에서 static 변수 / 메서드 사용했을 때와 동일 객체가 생성되기 전에 런타임시작하는 그 때 즉시 생성된다(Data영역에 할당). collection 함수 mutable과 immutable을 구분하여 지원한다 List: 기본적으로 immutable. &amp;lt;-&amp;gt; MutableList 이외에도 Set, Map, Array 등 존재코틀린에서 Array vs List Array에서는 Iterator를 내부적으로 지원하는데, List는 element가 불연속적인 메모리 공간으로 할당되어있다. Iterator는 구현에 의해 만들어진다. 배열은 크기가 정해져있고, List가 동적으로 할당 가능.(c++의 백터처럼 add, remove 가능)표현식 vs 구문 표현식은 값을 반환한다. 값을 (반환)만든다는 의미 따라서, 대입 연산자 오른쪽에 명시할 수 있다.(값을 저장) val foo = when { } 구문은 무언가가 실행되도록 명령을 지시하는 문장을 의미 값을 만들지는 않는다. when “표현식”에서는 항상 else를 필요로 한다.(값을 만들어야 하기 때문에) object 코틀린에서 싱글톤 객체를 사용하는 방법Inner class 내부(nested) 클래스 장점 내부에서 외부 클래스 멤버 접근 가능 서로 관련된 클래스를 논리적으로 묶어 표현해, 코드의 캡슐화 증가 외부에선 내부에 접근 불가. 따라서 코드 복잡성 감소. inner vs nested Kotlin에서는 nested가 default inner를 쓰려면 명시를 해야함. (TODO)차이점 명확하게 구분하기 enum class 열거형(클래스처럼 보이게 하는 상수) 관련 있는 상수들을 모아 심볼릭한 명칭의 집합으로 java에서의 static 변수 효과 이러한 상수 타입으로 어떠한 변수를 할당했을 때 그 변수를 수정함으로써 얻는 런타임에서의 에러를 방지할 수 있다.Time 시간 관련 API Instant.now() 한 점을 나타냄. 따라서 비교 가능 Duration.ofHours(2) - 2시간 차이 테스트에 유용하게 쓰일 수도 LocalDateTime : 시간대 포함하지 않음. LocalDate, LocalTime 도 존재 ZonedDateTime : 시간대 개념 추가 Local에서 시간대면 추가되면 Zoned. 반대도 가능 Reference)https://yangbox.tistory.com/24" }, { "title": "Node.js와 관련해 겪은 이슈들, 간단한 메모", "url": "/posts/Node.js_Issues/", "categories": "Study, Node.js", "tags": "node.js", "date": "2021-02-05 00:00:00 +0900", "snippet": "200216 npm으로 무언가를 도입하거나 업데이트했을 때 변경 이력을 보니 package.json에 생소한 모듈이 보인다면 npmjs에서 새로 도입한 무언가의 패키지 의존성을 찾아보면 된다.200222func().then(async () =&amp;gt; { if (foo()) { await promise() // first } await promise() // second })​ 이와 같은 코드에서 first → second 순서 보장. If() 조건절의 판별은 call stack에서 그 즉시 일어난다.200420 kafka-node 모듈 설치 중 cannot find module ‘kafka-node’ 에러 발생 설치 에러? npm install –save kafka-node 이후에도 같은 에러 발생 가장 먼저 오탈자 있는지 확인 없으면 rm -rf node_module &amp;amp;&amp;amp; rm -rf package-lock.json 일단 다 지우기 캐시 비우기 npm cache clean --force 다시 설치 npm install 이래도 안되면 npm 이슈 가보기 " }, { "title": "Spring Reactive stream과 Webflux", "url": "/posts/Webflux%EC%99%80_Reactive/", "categories": "Study, Spring boot", "tags": "spring, spring boot, 스프링, 스프링부트", "date": "2021-02-03 00:00:00 +0900", "snippet": "Reactive programming: 기본적으로 Data == Stream, event 로 보는 관점, 비동기 데이터 스트림을 이용해 데이터를 전달하는 방식의 ProgrammingReactive Streams Backpressure방식의 stream으로 처리함으로써 비동기적인 수행을 가능하게 한다. Reactive Stream의 구현체가 바로 Webflux에서의 Reactor이다. 리액터 패턴: 이벤트 핸들링의 일반적인 패턴. Node.js에서 이벤트 디멀티플렉서가 이 패턴으로 되어있다. Backpressure? (== dynamic pull 방식)push 방식: publisher가 전달하고자하는 데이터가 쌓이면 바로 subscriber에게 push하는 방식 subscriber 처리율이 떨어지면 OOM 문제가 발생할 우려 있다.pull 방식: subscriber가 처리할 수 있는 만큼 publisher에게 요청한다. Dynamic pull: subscriber 처리가능한 태스크가 n개가 되면 n개 pull 땡겨오는 방식Reactive Streams의 백프레셔 스트리밍 흐름 Subscriber 가 특정 이벤트에 대해 구독 요청 이벤트 발생 시 Subscription은 양 측을 연결하는 매체 역할 수행 작은 단위의 스트림으로 계속해서 스트리밍Publisher component 두가지 mono: 0 ~ 1개 데이터 전달 flux: 0 ~ N개 데이터 전달Cold seq vs Hot seq: 데이터 생성 시점의 차이 Cold: 구독 시점에 데이터 생성 e.g) API 호출하는 경우. 구독 때마다 새로운 요청을 server에 전송한다. Hot: 구독자 고려하지 않고 그냥 데이터 생성. 계속 데이터는 생성 되고 있고 구독 후 부터 구독자가 받게 된다.Reference)https://javacan.tistory.com/entry/Reactor-Start-1-RS-Flux-Mono-Subscriber https://engineering.linecorp.com/ko/blog/reactive-streams-with-armeria-1/ https://www.nurinamu.com/dev/2020/04/09/why-webflux-1/" }, { "title": "REST API 디자인하기", "url": "/posts/REST_API_%EB%94%94%EC%9E%90%EC%9D%B8/", "categories": "Study, REST API", "tags": "rest, rest api", "date": "2021-02-03 00:00:00 +0900", "snippet": "BasicPOST /users HTTP/1.1{ “users”:{ “name”:”Joo” }} /users 라는 Resource에 Request body에 맞게 새로운 리소스를 생성 POST해라HTTP method란? POST, GET, DELETE, PUT, PATCH, HEAD, OPTIONS 등 멱등성 (Idempotent) : POST 는 멱등하지 않아서 일반적으로 계속 요청하면 계속 side effect가 있을 것이라고 기대하고 나머진 멱등하게 구성한다. safe method: GET, HEAD 는 resource에 side effect를 주지 않는다. CORS 정책의 simple request는 해당 메소드들이 가능하다. 덧붙이면 POST도 기존의 resource를 변경하지 않기 때문에 safe하다고 판단한다. 형태: Method /resource/{resourceId}좋은 API 디자인 각각의 http method 성격을 위반하지 않아야 한다. e.g) GET 메서드는 어떠한 상태를 변경하지 않고, POST는 리소스를 생성한다. get 메서드가 uri에 리소스를 노출한다고해서 조회 API에 post를 사용하면 혼동이 올 수 있다. URI만 보고도 무슨 API인지 알도록 직관적으로 작성해야한다. Resource간의 관계를 표현한다고 생각하면 편하다. /rooms/{roomId}/participants/{participantId} Resource는 대상은 명사, 복수형을 사용한다. 의미상 이게 명확하다. /rooms/{roomId} : 모든 rooms 중 roomId에 해당하는 room /rooms/ : 모든 rooms 나쁜 예)POST /getDogsPOST /setDogOwner좋은 예)GET /dogsPOST /dogs/{dogID}/owner http status code를 의미에 맞게 적절히 사용해야 명확하다. 예를 들어, 클라이언트 에러인데 500번대 status를 전달하면 올바르지 않은 설계이다. 보안을 위해 Error stack은 response 메시지에 포함 시키지 않는다. 적절한 비즈니스 에러를 던지는 편이 좋아보인다. 페이징: 많은 도큐먼트 리턴시 잘라서 리턴하는 페이징 처리 필요 /records?offset=100&amp;amp;limit=25 (100번째 record부터 25개 출력) ``/records?page=5&amp;amp;rpp=25` /records?start=50&amp;amp;count=25 부하를 낮추기 위한 부분 응답 방식. 패킷 사이즈를 줄일 수 있다. 이러한 비즈니스적인 처리가 좋은 설계를 만들 것 같다. /people:(id,first-name,last-name,industry) - 파싱에 어려움 /terry/friends?fields=id,name - 직관적 ?fields=title,media.address.city API version을 갖게 하는 것도 관리 측면에서 좋다. URI에 /v1/rooms와 같이 버전을 명시해, 각각의 버전으로 맵핑될 수 있도록한다. 버전 설계에는 항상 하위호환을 고려해야한다. camel case보다는 dash나 snake case가 좋아보인다. 팀원과의 상의 필요하고 컨벤션을 정해놓는게 나중에 관리가 편하다. 개발자 뿐 아니라 일반 사용자들도 브라우저에서 접근 할수 있음을 염두한다. HATEOAS - restful하게 만드는 대표적인 특징 중 하나이다. client는 link를 통해서 api에 접근 가능하게 되고, client와 server가 독립적으로 분리 가능해진다. 그런데, 일반적으로 api 서버가 커질 수록 관리 포인트가 많아지고 hateoas가 지켜지기 어렵다. Stateless를 유지해야한다. -&amp;gt; 토큰, 쿠키 활용 혹은 세션 서버(redis 등) 문서화: Swagger UI는 뚱컨이 될 우려가 있고, Restdocs는 동시에 테스트 코드 작성이 가능하다.Reference)https://www.slideshare.net/Byungwook/rest-api-60505484https://developer.mozilla.org/ko/docs/Web/HTTP/Methodshttps://www.slideshare.net/brotherjinho/restful-api-64494716" }, { "title": "Coroutine", "url": "/posts/Coroutine/", "categories": "Study, Kotlin", "tags": "kotlin, coroutine", "date": "2021-02-01 00:00:00 +0900", "snippet": "특징 Task 단위가 Object이다. (= 경량 thread이다.) 메모리 heap에 적재(multi thread의 경우 stack에 적재)하기 때문에 교체시 object만 교체하고, 그 object는 heap을 공유한다. 이러한 과정이 단일 Thread위에서 발생. 따라서, OS 레벨의 context switch 발생하지 않음 No context switch 장점을 살리기 위해 단일 thread 위에서 여러 object 실행하는 것이 좋다. 루틴 실행과 종료 시기를 개발자가 정한다. Java의 Future / JS의 Promise와 Generator / Kotlin의 DeferedCancellation and Timeouts job.cancel()을 통해 진행되던 coroutine이 취소될 수 있다. coroutine의 모든 suspend function은 취소 가능. cancellationException을 throw 부모 scope에서 취소 → 자식 scope에서도 취소. GlobalScope로 생성된 coroutine은 자신이 실행된 스코프가 취소되어도 영향을 받지 않음. withTimeout() { … }` → timeout거는 용도 위에서 delay(500L) : suspend 기능. 취소가 가능한 상태.Composing Suspending functions 순차적 처리 async 처리(위 방식보다 두배 빠름) async를 통해 Defferd를 반환받음. 두 xxxxAsync()는 suspend가 아님에도 Defered를 반환받는다. 즉, 외부에서 사용될 때 Async로 사용 바로 위의 async를 사용한 예제 아래와 같이 동시성을 부여하여 사용한다면 외부에서 사용하다가 예외 발생시 범위 내의 모든 코루틴 취소 가능해 보다 안정적. Coroutine Context and Dispatchers launch { … } 에 매개변수 없는 경우: 실행중인 CoroutineScope에서 context(+Dispatcher) 상속받음. Dispatchers.Default: 코루틴이 Globalscope에서 실행될 경우에 사용. Dispatchers.Unconfined: 호출한 thread에서 코루틴 시작. 중간에 suspend function을 호출한다면 해당 func을 마치고 코루틴이 결된 후 다시 시작. 결국 공유 데이터를 update하지 않는 경우에 사용 → 따라서 Unconfined는 일반적인 경우에 사용하지 않음. Dispatchers.NewSingleThreadContext: 새로운 스레드 생성. 더이상 사용 안할시 close(). .use()와 함께 쓰면 필요 없을 때 알아서 지워줌. 디버깅을 위해 naming. var v1 = async(CoroutineName(“v1coroutine”)){ … } → 로깅시 유용 job: 수명주기를 직접 관리 가능 job을 print찍으면 현재의 job 상태 및 id?를 알 수 있다. isActive는 coroutineContext[Job]?.isActive == true 를 간략화한 것. join을 통해 해당 job 완료를 기다릴 수 있다. var job1 : Job = launch { … } job1.join() start - 동작상태 반환(Boolean) Job별로 컨트롤, 통합 컨트롤 가능 Job별로 별도 control하는 것이 필요한 경우 val job = CoroutineScope() 형태 여러 코드 반영하여 컨트롤 var job = Job() Coroutine(Scope(Dispatchers.Default + job).launch{ … } withContext: coroutine의 context 전환Asynchronous Flow자세한 예제 ref) https://charko.tistory.com/17?category=887416 비동기로 처리 된 값이나 리스트 리턴하는 경우. List 처럼 list로 묶어서 Sequence(비동기 X) 이 경우 return되는 것은 seq의 주소값. 해당 메소드에서 yield()로 발생시켜 return suspending function. flows: sequence의 비동기형 (emit()을 통해 return) Flows are cold: sequence와 비슷한 stream. flow 내부의 builder가 flow가 쌓이기 전에 실행하지 않음. Flow cancellation flow는 별도의 취소지점 없음. 여기서는 delay(suspend기능)이 있을 때 취소가 됨. 자세한 문법적 부분은 필요할때 링크 참조Reference)https://kotlinlang.org/docs/reference/coroutines/basics.htmlhttps://aaronryu.github.io/2019/05/27/coroutine-and-thread/https://www.letmecompile.com/kotlin-coroutine-vs-javascript-async-comparison/" }, { "title": "모던 JavaScript 튜토리얼 - Promise 5 - MicroTask", "url": "/posts/%EB%AA%A8%EB%8D%98_Javascript_%ED%8A%9C%ED%86%A0%EB%A6%AC%EC%96%BC_Promise_5_MicroTask/", "categories": "Study, JavaScript", "tags": "javascript, js, promise, microtask", "date": "2021-01-28 00:00:00 +0900", "snippet": "Microtask Promise handler는 항상 비동기적으로 실행let promise = Promise.resolve();promise.then(() =&amp;gt; alert(&quot;프라미스 성공!&quot;));alert(&quot;코드 종료&quot;);이 코드에서 “코드 종료”가 먼저 출력. 그 이유는? 현재 코드에서 자유로운 상태(콜스택이 비었을 때)가 되었을 때 JS engine은 queue(microtask queue)에서 작업을 꺼내 실행(이행된 Promise의 핸들러 .then부분)Promise.resolve() .then(() =&amp;gt; alert(&quot;프라미스 성공!&quot;)) .then(() =&amp;gt; alert(&quot;코드 종료&quot;));이와 같이 변경하면 의도대로 출력 가능.처리되지 못한 거부 unhandledrejection event는 microtask queue에 있는 모든 작업이 완료되고서도 error가 잡히지 않는다면 발생한다. let promise = Promise.reject(new Error(&quot;프라미스 실패!&quot;));setTimeout(() =&amp;gt; promise.catch(err =&amp;gt; alert(&#39;잡았다!&#39;)), 1000); // Error: 프라미스 실패!window.addEventListener(&#39;unhandledrejection&#39;, event =&amp;gt; alert(event.reason)); catch에서 에러를 잡는데도 unhandledrejection가 발생하는 이유: “프라미스 실패”가 발생하면 마이크로태스크 큐가 비워지게 되는데, 이 때 unhandledrejection 핸들러가 트리거 되고, 이후에 catch가 스택에 올라가면서 “잡았다!”가 발생하는 것 Reference) 모던 JavaScript 튜토리얼 https://ko.javascript.info" }, { "title": "모던 JavaScript 튜토리얼 - async / await", "url": "/posts/%EB%AA%A8%EB%8D%98_Javascript_%ED%8A%9C%ED%86%A0%EB%A6%AC%EC%96%BC_Async_Await/", "categories": "Study, JavaScript", "tags": "javascript, js, promise, async await", "date": "2021-01-28 00:00:00 +0900", "snippet": "asyncasync function f() { return 1;} function 앞에 async를 붙이면 해당 함수는 반환 값을 fulfilled 상태 Promise로 감싸 반환await: async 함수 안에서만 동작. JS는 await 키워드를 만나면 Promise가 처리될 때까지 기다림. await은 최상위 레벨 코드에서 사용 불가.(익명 async 함수로 감싸면 가능) await은 thenable 객체를 받을 수 있음. 이 때 await는 일반 Promise executor가 하는 일과 동일 Error handling Promise가 정상 이행 시 await promise는 Promise의 result에 저장된 값을 반환. 거부 시 throw 문 처럼 Error 던져짐. → try...catch 이용해 에러 잡을 수 있음. 아래처럼 catch를 추가하지 않거나, async함수에서 try ... catch 를 하지 않으면 처리되지 못한 거부가 발생 async function f() { let response = await fetch(&#39;http://유효하지-않은-url&#39;);} // f()는 거부 상태의 프라미스가 됩니다.f().catch(alert); // TypeError: failed to fetch // (*) Reference)모던 JavaScript 튜토리얼 https://ko.javascript.info" }, { "title": "모던 JavaScript 튜토리얼 - Promise 4 - 프라미스화", "url": "/posts/%EB%AA%A8%EB%8D%98_Javascript_%ED%8A%9C%ED%86%A0%EB%A6%AC%EC%96%BC_Promise_4_%ED%94%84%EB%9D%BC%EB%AF%B8%EC%8A%A4%ED%99%94/", "categories": "Study, JavaScript", "tags": "javascript, js, promise", "date": "2021-01-26 00:00:00 +0900", "snippet": ": 콜백만 지원해주는 API 등 콜백 함수를 프라미스를 반환하도록 프라미스로 감싸는 것프라미스화(Promisify) 콜백을 그대로 써도 되지만, 기존 코드가 프라미스 기반으로 작성되어있으면 프라미스로 바꾸는 것이 일관성있고 좋을 것 같다. 특히, Async/await 패턴과 함께 사용하면 더 좋다. 그러나, 프라미스와는 다르게 콜백은 여러번 호출될 수 있기 때문에, 콜백을 단 한번 호출하는 함수에만 적용할 것 e.g) redis api 프라미스화 npm의 redis를 까보면 윗 이미지와 같이 Callback을 지원하도록 되어있다. Promisify: 이러한 콜백기반 API를 Promise로 한번 더 감싸서 따로 메서드로 만들어 놓는 것. 사용할 때 훨씬 편하고 가독성이 좋다. function redisGet(client: RedisClient, hash: string, key: string): Promise&amp;lt;string&amp;gt; { return new Promise&amp;lt;string&amp;gt;((resolve, reject) =&amp;gt; { client.hget(hash, key, (error: any, value: string) =&amp;gt; { if (error) reject(error); resolve(value); }); });} 헬퍼 함수 위와 같이 매번 Promise화 할 것인가? - 여러개의 함수를 프라미스화 해야한다면 util성 헬퍼 함수를 따로 구현해두는 것도 사용성 측면에서 좋을 것 같다. - 코드 이해하기 // 콜백의 성공 결과를 담은 배열을 얻게 해주는 promisify(f, true)function promisify(f, manyArgs = false) { return function (...args) { return new Promise((resolve, reject) =&amp;gt; { function callback(err, ...results) { // f에 사용할 커스텀 콜백 if (err) { reject(err); } else { // manyArgs가 구체적으로 명시되었다면, 콜백의 성공 케이스와 함께 이행 상태가 됩니다. resolve(manyArgs ? results : results[0]); } } args.push(callback); f.call(this, ...args); }); };}; // 사용법:f = promisify(f, true);f(...).then(arrayOfResults =&amp;gt; ..., err =&amp;gt; ...) 추가적인 Promisify 도구 참고: https://github.com/mikehall314/es6-promisify Reference)모던 JavaScript 튜토리얼 https://ko.javascript.info" }, { "title": "모던 JavaScript 튜토리얼 - Promise 3 - Promise API", "url": "/posts/%EB%AA%A8%EB%8D%98_Javascript_%ED%8A%9C%ED%86%A0%EB%A6%AC%EC%96%BC_Promise_3_Promise_API/", "categories": "Study, JavaScript", "tags": "javascript, js, promise", "date": "2021-01-23 00:00:00 +0900", "snippet": "Promise.all Promise 배열을 받고, 모두 처리되면 각 Promise의 결과를 담은 배열이 Promise 로 반환 됨.Promise.all([ new Promise(resolve =&amp;gt; setTimeout(() =&amp;gt; resolve(1), 3000)), // 1 new Promise(resolve =&amp;gt; setTimeout(() =&amp;gt; resolve(2), 2000)), // 2 new Promise(resolve =&amp;gt; setTimeout(() =&amp;gt; resolve(3), 1000)) // 3]).then(alert); // 프라미스 전체가 처리되면 “순서대로” 1, 2, 3이 반환됩니다. 각 프라미스는 배열을 구성하는 요소가 됩니다. 이 때 Promise 하나라도 거부되면 Promise.all은 거부됨 에러 발생 시 다른 promise 무시됨. Iterable 객체 아닌 [1, 2, 3] 과 같은 ‘일반’ 값도 전달 가능. 이 때 요소가 그대로 결과 배열로 전달 됨. Promise.race : Promise.all과 비슷하지만, 가장 먼저 처리되는 프라미스 결과만을 반환한다. 예측하기 어렵다. Promise.allSettledPromise.all 과 달리 실패 시에도 모든 프라미스 처리를 기다리고, 이후 결과는 각각 Promise 상태 fulfilled 또는 rejected와 value 또는 error를 받는다. polyfill: 브라우저 Promise.allSettled 지원 안 될 경우 폴리필 구현 Promise.race: 가장 먼저 처리되는 Promise 결과 반환allSettled 폴리필(polyfill) 브라우저가 Promise.allSettled를 지원하지 않는 버전이라면 아래와 같은 폴리필 구현(코드 이해하기)if(!Promise.allSettled) { Promise.allSettled = function(promises) { return Promise.all(promises.map(p =&amp;gt; Promise.resolve(p).then(value =&amp;gt; ({ status: &#39;fulfilled&#39;, value }), reason =&amp;gt; ({ status: &#39;rejected&#39;, reason })))); };}Promise.resolve/rejectasync/await 문법 후로 거의 사용하지 않음 Promise.resolve: 결과가 value인 fulfilled Promise 생성 Promise.resolve: 결과 error인 rejected Promise 생성 Reference)모던 JavaScript 튜토리얼 https://ko.javascript.info" }, { "title": "모던 JavaScript 튜토리얼 - Promise 2 - Error 처리", "url": "/posts/%EB%AA%A8%EB%8D%98_Javascript_%ED%8A%9C%ED%86%A0%EB%A6%AC%EC%96%BC_Promise_2_Error_%EC%B2%98%EB%A6%AC/", "categories": "Study, JavaScript", "tags": "javascript, js, promise", "date": "2021-01-22 00:00:00 +0900", "snippet": "Promise error handling: Chaining에서 여러 then 중 Promise가 하나라도 거부된다면 .catch 트리거 따라서, 체이닝 되어있는 모든 then에서의 에러를 한 catch에서 처리 할 수 있다. 세부적인 에러 처리를 위해 각 task(then)마다 catch 하나씩 둘 수도 있다. 암시적 try…catch 예외가 발생하면 예외를 잡고, reject처럼 다룸(거부상태의 promise로 변경시킴) executor 주위에는 보이지 않는(암시적) try ... catch가 있다. 따라서, 예외가 발생하면 try ... catch에서 예외를 잡고 이를 reject처럼 다룬다. new Promise((resolve, reject) =&amp;gt; { throw new Error(&quot;에러 발생!&quot;); }).catch(alert); // Error: 에러 발생!throw를 사용해 에러를 던지거나 모든 종류의 에러가 발생하면 거부된 Promise를 의미하기 때문에 아래와 똑같이 동작new Promise((resolve, reject) =&amp;gt; { reject(new Error(&quot;에러 발생!&quot;));}).catch(alert); // Error: 에러 발생!동기적 에러, 비동기적 에러new Promise(function(resolve, reject) { setTimeout(() =&amp;gt; { throw new Error(&quot;에러 발생!&quot;); }, 1000);}).catch(alert); 위의 예제에서 catch는 트리거되지 않는다. 동기적 에러: 윗 윗 예시처럼, 암시적 try ... catch가 함수 코드를 감싸고 있으므로 처리가 잘 된다. 비동기적 에러: executor(실행자, 실행 함수)가 실행되는 동안이 아니라 나중에 에러가 발생한다. (executor의 실행동안 try ... catch가 잡아주는데, 그 이후에 발생한다.) 이는 Node.js의 콜백 규칙에서 보았듯 실행 스택과 에러가 발생한 스택이 다르기 때문. 에러는 이벤트 루프로 그대로 이동하고 uncaughtException (or unhandledrejection) 에러 다시 던지기new Promise((resolve, reject) =&amp;gt; { throw new Error(&quot;에러 발생!&quot;); // 혹은 reject 처리}).catch(function(error) { // Error 처리 alert(&quot;에러가 잘 처리되었습니다. 정상적으로 실행이 이어집니다.&quot;);}).then(() =&amp;gt; alert(&quot;다음 핸들러가 실행됩니다.&quot;)); catch { ... } 에서 잘 처리 -&amp;gt; then catch { ... } 에서 처리되지 않는 에러라서 또다시 throw -&amp;gt; 해당 에러를 받는 또다른 catch { ... } 에서 처리처리되지 못한 에러(혹은 reject) 처리할 수 없는 에러 일 때 .catch 안에서 throw를 사용하면 제어 흐름이 가장 가까운 error handler로 넘어감. → 에러 처리 시 가장 가까운 .then handler로 제어가 넘어감. 처리되지 못한 거부: .catch를 추가하지 않고 에러가 발생할 때 일단은 가장 가까운 rejection handler로 넘어감. 그러나 만약 이 때 처리할 rejection handler가 없으면 에러가 갇히고, 전역 에러가 발생해 script가 죽게 됨. → 브라우저 환경에서 unhandledrejection event(HTML의 표준 이벤트) Reference)모던 JavaScript 튜토리얼 https://ko.javascript.info" }, { "title": "모던 JavaScript 튜토리얼 - Promise 1 - Promise 기초", "url": "/posts/%EB%AA%A8%EB%8D%98_Javascript_%ED%8A%9C%ED%86%A0%EB%A6%AC%EC%96%BC_Promise_1_Promise_%EA%B8%B0%EC%B4%88/", "categories": "Study, JavaScript", "tags": "javascript, js, promise", "date": "2021-01-22 00:00:00 +0900", "snippet": ": 처리 성공 여부에 따라 resolve or reject 호출Basic Promise는 성공 또는 실패만 한다. 이 때 변경된 상태는 더이상 변하지 않는다. resolve(value): 일이 성공적으로 끝난 경우 value(하나 혹은 없음)와 함께 호출 reject(error): 에러 시 error(Error 객체 혹은 Error 상속받은 객체)와 함께 호출 내부 프로퍼티(개발자가 접근 불가) state: 초기 pending/ resolve() 시 fulfilled, reject 시 rejected result: 초기 undefined / resolve() 시 value, reject 시 error then, catch, finally: 각각의 Handler들.(항상 비동기적 실행)then: .then(result, error) 에서 Promise 이행 시 result, 거부 시 errore.g)let promise = new Promise(function(resolve, reject) { setTimeout(() =&amp;gt; resolve(&quot;done!&quot;), 1000); }); // resolve 함수는 .then의 첫 번째 함수(인수)를 실행합니다.promise.then(result =&amp;gt; alert(result), // 1초 후 &quot;done!&quot;을 출력error =&amp;gt; alert(error) // 실행되지 않음 ); 성공적으로 처리된 경우만 다룬다면 인자 하나catch에러가 발생한 경우 then(null, errorHandlingFunction), .catch(errorHandlingFunction) 이와같이 사용finally .finally(f)는 .then(f, f)와 유사. Promise가 처리(이행되건 거부되건)된다면 f가 항상 실행됨. finally 핸들러에는 인수가 없음. Promise의 이행 여부도 알 수 없음(보편적인 동작 만을 수행) finally는 자동으로 다음 handler에게 Promise의 결과, 에러 전달Chaining 순차적으로 처리해야하는 비동기 작업이 여러개 있을 때 사용(중첩 Callback을 대체 가능) Handler가 Promise를 반환하면, 나머지 체인은 Promise가 처리될 때까지 대기하다가 처리가 완료되면 result(값 또는 에러)가 다음 체인으로 전달됨 .then은 Promise를 반환 하나의 Promise 이후 여러개의 handler(.then())에 전달 가능. 이 때 각각은 독립적으로 수행 추후 손쉬운 확장을 위해 항상 Promise를 반환하도록 개발하는 것이 좋음 Reference)모던 JavaScript 튜토리얼 https://ko.javascript.info" }, { "title": "모던 JavaScript 튜토리얼 - Callback", "url": "/posts/%EB%AA%A8%EB%8D%98_Javascript_%ED%8A%9C%ED%86%A0%EB%A6%AC%EC%96%BC_Callback/", "categories": "Study, JavaScript", "tags": "javascript, js, callback, 콜백", "date": "2021-01-21 00:00:00 +0900", "snippet": "콜백 기반 비동기 프로그래밍 함수 내부의 모든 작업을 수행하고 실행할 함수를 callback으로 전달 c.f) script, module 로딩하는 과정 또한 비동기 과정 → loadScript 내부에서 해당하는 script를 callback한다. Callback in callback 콜백의 중첩. 코드를 복잡하게 만들며 지양해야 한다(콜백 지옥) 해결방법 각각 독립적으로 함수화(재사용 불가, 비가시적) Promise 사용 Error handling: 에러를 고려하는 방법script.onload = () =&amp;gt; callback(null, script);script.onerror = () =&amp;gt; callback(new Error(`${src}를 불러오는 도중에 에러가 발생했습니다.`));Reference)모던 JavaScript 튜토리얼 https://ko.javascript.info" }, { "title": "Git과 관련해 겪은 이슈들, 간단한 메모", "url": "/posts/Git_Issues/", "categories": "Study, Git", "tags": "git, trouble shooting", "date": "2021-01-20 00:00:00 +0900", "snippet": "200301 git config --list author등 현재의 상태 볼 수 있음. git config --global --user.name=&quot;hungryjay&quot; author 변경 user.name 대신 다른 것(email 등)도 변경 가능 global option 없을 경우 현재의 디렉토리 한정 commit 기록들에서 모두 author 변경하기 github과 다른 author일 경우 contribution 안찍힘. 바꾸고 싶은 commit으로 git rebase -i -p {commitID} pick을 edit으로 변경 전부 commit --amend --author=&quot;hungryjay &amp;lt;aaa@aaa.com&amp;gt;&quot; Git 레포지토리 합치는 방법상황: B -&amp;gt; A로 병합 git remote add sub(remote) B git fetch sub git merge --allow-unrelated-histories sub/main(branch이름) A에서 remote까지 지워주기reference)https://mansoo-sw.blogspot.com/2017/08/git-repository-merge.html" }, { "title": "Redis란", "url": "/posts/Redis%EB%9E%80/", "categories": "Study, Redis", "tags": "redis, 레디스", "date": "2021-01-11 00:00:00 +0900", "snippet": "장점 성능: In memory data store라서 초고속 성능을 제공한다. Disk 참조 하지 않기 때문에 엔진 대기 시간이 마이크로초 단위까지 줄어든다. 유연한 데이터 구조: Key value쌍의 다양한 Data structure: 문자열, 목록, 세트, 해시 비트맵 등 단순성: 다른 DB의 쿼리구조와 다르게, 단순하다. get set del 등의 직관적인 API를 제공한다. 복제: 비동기식 복제(Replication)를 지원한다. 따라서, 서버 장애 상황에서 요청이 분산될 수 있다. 지속성: Redis가 특정 시점에 스냅샷 백업(Redis 데이터 집합을 디스크로 복사)를 지원한다. 자식프로세스를 하나 만들어서 저장을 수행하도록 한다. 확장성 및 고가용성: 클러스터링이 가능하고, 기본 복제 아키텍처가 제공된다. 클러스터링에서는 스케일업, 인, 아웃이 가능하다. 오픈소스이다. 그 외: (Node환경)Socket.io 패키지 -&amp;gt; Redis가 브로커 역할 수행해 스케일링에 적합한 웹소켓 환경 구성 가능하다.특징Single Thread 싱글 스레드 기반이다. 따라서, I/O가 많아 의미있는 block이 발생할만한 작업을 조심해야한다. Redis 장애는 getKeys() , flush() 처럼 다건의 레코드 처리 커멘드때문에 발생하는 경우일 때가 꽤 있다고 한다. 이러한 다건의 문제를 해결하기 위해서는 cursor 매커니즘을 활용한다. scan을 이용해 일정 개수만큼만 조회하고, task 쌓여있으면 그거부터 처리하는 방식. 복제 Sentinel: Master - Slave 매커니즘 제공. 장애 상황에서 회복이 빨라질 수 있다. Clustering: 클러스터링(분산) 환경에서도 기본 복제 아키텍처가 제공된다.지속성(Persistence): In memory로 언제든 휘발할 가능성이 있다. 지속성의 특징을 위해선 Disk에 저장해야한다.RDB(Redis Database) 특정 시점의 스냅샷을 디스크에(파일시스템에 binary 파일로) 저장한다. redis.conf 에서 dbfilename dump.rdb 설정으로 파일 이름을 설정할 수 있고, 설정을 통해 언제 저장할지 시점도 설정 가능하다. 파일 로드: 파일 압축이 가능하다. 일반적으로 AOF보다 파일 사이즈가 작아 파일 로딩 속도가 빠르다고 한다. 성능 이슈: redis는 싱글스레드 기반인데 저장 작업이 오래걸리고, 그동안 block상태라 이것때문에 redis 장애가 발생하는 경우가 많다고 한다. 디스크에 저장하다가 실패해도 다른 모든 동작을 정상적으로 처리하던지, 혹은 조치를 기다리던지를 수행해야한다.(conf 수정)AOF(Append Only File) 입력, 수정, 삭제(조회 제외) 때마다 계속 기록된다. AOF를 사용해도 성능이 크게 안나빠지기 때문에 AOF가 default. appendonly.aof 파일에 저장된다. AOF 계속 추가 기록하는데, 특정 시점에는 데이터 전체를 rewrite한다. 계속 추가만 하다보면 파일이 무한히 커지는데, rewrite를 하면 이전 쓸데없는 diff는 사라지고, 최종 데이터가 기록된다. rewrite도 conf로 설정 가능하다. Replication환경에서 master는 AOF를 사용하는 것이 안전하다. 왜냐하면, 자동 재시작 후, 몇 분 전의 RDB(기록 유실)만 있다면 slave들도 마스터와 같이 해당 RDB를 받기 때문이다.Memcached와의 비교 둘다 key-value이다. Memcached의 장점 Memcached는 멀티스레드이다. 따라서 scale up이 가능하고, Race condition에 관해서는 global cache lock을 사용해 해결 가능하다. Memcached는 메타데이터에 대한 메모리 리소스를 적게 소비하기 때문에 HTML과 같은 작은 정적 데이터 캐싱에 더 좋다고 한다. Redis 장점 캐시 측면에서 redis가 우수하다. memcached에서는 LRU를 사용하고, redis는 6가지나 되는 다양한 매커니즘을 갖고 있으며 상황에 따라 적절히 선택한다고 한다. 데이터구조가 유연하고, 복제를 통한 HA도 가능하다. 레퍼런스가 많고, 지원하는 많은 모듈들이 있다.(Socket.io, 모니터링, 통계 등) Reference)https://github.com/redis/redishttps://aws.amazon.com/ko/redis/http://redisgate.kr/redis/configuration/persistence.phphttps://postitforhooney.tistory.com/entry/DBRedisRedis%EC%97%90-%EB%8C%80%ED%95%B4%EC%84%9C-%EA%B3%B5%EB%B6%80%ED%95%98%EA%B8%B0-Redis-vs-Ehcache-vs-Memcached-%EB%B9%84%EA%B5%90%ED%95%98%EB%A9%B0-%ED%8C%8C%EC%95%85%ED%95%98%EA%B8%B0" }, { "title": "Docker를 통해 LB / REDIS로 scaled-server 리소스 공유", "url": "/posts/Docker_LB_REDIS%EB%A1%9C_scaled-server_%EC%97%B0%EA%B2%B0/", "categories": "Study, Redis", "tags": "redis, 레디스", "date": "2021-01-03 00:00:00 +0900", "snippet": "Redis docker-compose 설정 default로 6379 포트를 갖는다. redis-cli에 ping날리는 정도로 간단하게 헬스체킹이 가능하다. 애플리케이션 서버 디펜던시 설정에 redis 헬스체크도 추가해주면 더 좋을 것 같다.Server Load Balancing $ ping 결과: 172.28.0.4와 172.28.0.5 두 애플리케이션 서버에 적절히 LB해주는 것을 볼 수 있고, Redis로 scalablity를 제공한다. 도커를 통한 스케일링은 컴포즈 설정에 scale=2을 명시하거나 실행 커맨드에 옵션값을 부여하면 가능하다. $ docker-compose ps 결과레디스 리소스 공유: 별도로 레디스를 통한 소켓서버 스케일링을 확인하려면 A서버에 소켓 연결된 유저에 대해 B 서버를 통해 소켓메시지 emit이 되는 것을 확인하면 된다." }, { "title": "Redis를 통해 서버 Scale out에서 자원 공유", "url": "/posts/Redis%EB%A5%BC_%EC%9D%B4%EC%9A%A9%ED%95%B4_scaleout/", "categories": "Study, Redis", "tags": "redis, 레디스", "date": "2020-12-29 00:00:00 +0900", "snippet": "Scale out : 접속한 서버의 대수를 늘려 처리 능력 향상 시키는 것: 서버의 수를 늘림. 복수의 서버를 구축해 Scale out 수평 확장(horizontal scaling) 공유 자원에 대해 고려해야 한다.Scale up: 서버 자체를 증강: 인스턴스를 더 좋은 인스턴스로 변경. 수직 확장(vertical scaling) 비용 부담이 크다. e.g) EC2를 사용하다가 더 성능좋은것으로 이관하는 것.c.f) 일반적으로 클라우드환경에서 Auto scaling 한다는 것은 트래픽에 따라 scale out / in 한다는 의미로 쓰인다.Adapter: Redis: Redis가 어댑터로써 서버간 브로커 역할을 수행한다. 소켓서버의 특정 Room에 메시지를 보내면, Redis는 브로커가 되고 각 서버들에게 전달된다. 여러 서버가 redis로 연결될 때 채널 개념이 발생하고 이 채널 정보는 socket server에서 들고 있는다. 각 socket server는 메시지를 받으면 서버에서 구독하고 있는 채널에 메시지가 해당하는지를 찾고 맞으면 메시지를 해당 Room에 준다. Pub/Sub 매커니즘이 있다. 각 socket server는 n개의 채널을 subscribe할 수 있다. Adapter 역할 일종의 cluster처럼 연결된 각 서버에 broadcast routing message의 역할을 수행하는 Interface Redis Adapter code exampleconst redisAdapter = require(&#39;socket.io-redis&#39;);const io = require(&#39;socket.io&#39;);socketServer = io(baseServer) .adapter(redisAdapter({ host: &#39;redis&#39;, port: 6379 // default port}));Code level exampleconst redis = require(&#39;redis&#39;);// default port 6379const client = redis.createClient({ host: &#39;redis&#39;, port: 6379 });// Unhandled Error를 방지하기 위해 아래 error 이벤트에 대한 핸들링을 꼭 해야한다.client.on(&#39;error&#39;, (error: any) =&amp;gt; { debug(error);});client.hset(hash, key, val, (err, res) =&amp;gt; { console.log(res); // 1 or 0}client.hget(hash, key, (err, res) =&amp;gt; { console.log(res); // value} Promisify: 위 코드를 깔끔하게 Promise로 이용하기 위해 아래와 같이 구현(이와 같이 여러 method 구현해 놓고 필요에 따라 사용) public set(hash: string, key: string, value: string) { return new Promise((resolve) =&amp;gt; { client.hset(hash, key, value, (err, result) =&amp;gt; { resolve(reply); }) })} Reference)https://socket.io/docs/v3 https://socket.io/docs/v3/using-multiple-nodes/Redis 로컬 설치: https://redis.io/topics/quickstart" }, { "title": "웹소켓과 socket.io", "url": "/posts/%EC%9B%B9%EC%86%8C%EC%BC%93_socketIO/", "categories": "Study, Web socket", "tags": "웹소켓, web socket", "date": "2020-12-28 00:00:00 +0900", "snippet": "양 방향 통신?: 이전에는 Polling, Long polling, HTTP Streaming 방식 등 여러 방법을 통해 Client, server 양 방향 통신을 구현했었다. Traditional Polling: 주기적으로 client가 AJAX 요청해 결과를 확인한다. 너무 리소스 낭비가 크다. Long Polling: client가 AJAX 요청을 하면 server는 연결 안끊고 기다리다가 완료되면 response. 이 방식이 가장 보편적이었다고 한다. HTTP Streaming: 연결 안끊고 그냥 server쪽에서 응답 발생할때마다 response. 연결에 대한 오버헤드 존재해서 이 방식도 주기적으로 끊기는 한다. 많은 곳에서 Polling 방식을 대체하는 기술이라고 설명된다. 그러나, 모든 프록시나 방화벽에서 허용되는 것이 아니라서 보편적으로 사용되진 않는다.Web Socket HTML5에서 소켓 연결을 통해 서버와 클라이언트간 양방향 통신환경 제공. port: http 포트(80)를 통해 웹 서버 연결하므로 추가적인 방화벽 설정(인, 아웃바운드)이 필요하지 않는다. 소켓을 이용해 데이터를 주고 받음. http 연결 후에는 프로토콜을 변경해 통신한다. http:// → ws:// 다양한 서버 구현체가 있다. Socket.io, stomp 등등Socket.io Web socket 처럼 클라이언트, 서버간 양방향 통신을 가능하게 해주는 NPM 모듈 정확하게는 통신을 시작할 때 각 브라우저에 대해 websocket, polling, streaming, flash socket 등에서 가장 적절한 방법을 찾아 보내줌 Socket Server는 소켓과 논리적 room의 관계 정보를 들고있다.API 구성 Redis 어댑터(브로커): const redisAdapter = require(&#39;socket.io-redis&#39;); redis + socketIO(adapter): const sockerServer = SocketIO().adapter(redisAdatper( ... )); 소켓서버에 broadcast: socketServer.emit(eventName, data); Namespace지정: socketServer.of(nameSpace),emit(eventName, data); 특정 유저: socketServer.to(socketID).emit(eventName, data); 특정 Room(논리적 구별단위) 입장: socket.join(roomID) 특정 방 전체에 emit 1.: socketServer.io(roomID).emit(eventName, data); 특정 방 전체에 emit 2.:socket.broadcast.to(roomID).emit(eventName, data);Room?소켓이 join 과 leave 를 할 수 있는 논리적 단위(채널)이다. 소켓을 통해 client들에게 event를 broadcast할 수 있다.이 때 client의 입장에선 room 들에 대한 정보를 모른다.(사실 서버쪽에서만 신경 쓸 일)API 예시 io.to(‘some room’).emit(‘some event’); io.to(‘room1’).to(‘room2’).to(‘room3’).emit(‘some event’); Room에 입장 후 방 전체에 emitio.on(&#39;connection&#39;, async (socket) =&amp;gt; { const userId = await fetchUserId(socket); socket.join(userId); // and then later io.to(userId).emit(&#39;hi&#39;);});Reference)https://socket.io/docs/v3https://socket.io/docs/v3/using-multiple-nodes/" }, { "title": "Event loop, 비동기 처리의 흐름", "url": "/posts/%EC%9D%B4%EB%B2%A4%ED%8A%B8%EB%A3%A8%ED%94%84_%EB%B9%84%EB%8F%99%EA%B8%B0/", "categories": "Study, Node.js", "tags": "node.js", "date": "2020-12-14 00:00:00 +0900", "snippet": "Javascript 싱글스레드 기반, Event loop를 기반으로 하는 Node.js Javascript engine은 JS를 해석하고 실행하는 엔진(콜 스택과 이벤트 큐가 있는)Javascript engine과 이벤트 루프Event Loop 아래의 방식으로 이벤트루프가 현재 실행중인 task가 없는지, task queue에 task가 있는지 반복적으로 확인while(queue.waitForMessage()) { queue.processNextMessage();}Call stack JS는 단 하나의 call stack 사용 자바스크립트 엔진의 call stack 따라서 JS가 실행되는 방식은 Run to completion. 하나의 함수가 실행되면 다른 task는 수행될 수 없다. 메서드 실행시 call stack에 새로운 stack frame 생성하고 return시 stack에서 해당 frame을 pop한다. 혹은 비동기적인 처리가 필요할 때 pop되고 Web API로 Heap: 동적으로 생성된 객체(인스턴스)는 힙에 할당.Microtask queue task queue보다 여기를 우선적으로 확인 mutation observer(?), promise가 여기로 들어감. Promise의 핸들러는 항상 이 queue를 통과해야 한다. 처리되지 못한 에러: microtask queue가 빈 후 처리하지 못한 error에 대해 unhandledrejection 발생. Task Queue(event queue) JS 런타임환경에는 (비동기적으로)처리해야하는 Task를 임시저장하는 대기 큐가 존재. 그것이 Task queue( == event queue.) Call stack이 비어졌을 때 queue에 먼저 들어온 task가 stack으로 들어간다. 비동기로 호출되는 함수는 (Web API에서 수행된 후)Task queue에 enqueue된다. 여기서 지워지는 타이밍은 stack에서 수행 후 pop 되고 나서.web API or 백그라운드 자바스크립트의 엔진(실제 코드가 수행되는 쓰레드)와는 별도의 쓰레드 Ajax 요청, setTimeout(), 이벤트 리스너 등록 과 같은 것들이 이 곳에서 수행 Settimeout에서 n초가 다 수행되기 전까지, event handler에서 해당 event가 발생하기 전까지 기다리는 곳 이후 발생하거나 완료 되면 task queue(자바스크립트 엔진의 쓰레드)로 보낸다.queue 우선순위 micrortask queue -&amp;gt; animation frames -&amp;gt; task queue 직접적인 작업들은 Web API에서 처리한다. animation frame : 브라우저 랜더링 관련c. f) 예시function aaa() { setTimeout(() =&amp;gt; { console.log(&#39;d&#39;); }, 0); console.log(&#39;c&#39;);}setTimeout(() =&amp;gt; { console.log(&#39;a&#39;); aaa();}, 0);Promise.resolve().then(() =&amp;gt; { aaa(); console.log(&#39;b&#39;);}); 출력순서 예상해보기. 답 c b a c d dAsync / Await, microtask await을 만나면 해당 async 함수 실행이 일시정지되고 async 컨택스트 전체가 microtask queue로 삽입된다. 이 후, await 된 함수가 resolve된 promise를 리턴할 때 까지 지연된다. const hello = () =&amp;gt; Promise.resolve(&#39;Hello world&#39;); async function myFunc() { console.log(&#39;In function!&#39;); const rest = await hello(); console.log(res);}console.log(&#39;Before&#39;);myFunc();console.log(&#39;After&#39;); 결과는 Before -&amp;gt; In function -&amp;gt; After -&amp;gt; One #### Reference)https://it-eldorado.tistory.com/86http://asfirstalways.tistory.com/362https://it-eldorado.tistory.com/86http://sculove.github.io/blog/2018/01/18/javascriptflow/https://kkangdda.tistory.com/77" }, { "title": "RPC 통신", "url": "/posts/RPC_%ED%86%B5%EC%8B%A0/", "categories": "Study, Network", "tags": "network, rpc", "date": "2020-12-12 00:00:00 +0900", "snippet": "RPC (vs restapi) IDL(Interface Definition Language)을 활용하며, 다른 프로세스의 함수나 프로시저를 마치 로컬처럼 이용 인터페이스(request parameter, response parameter)를 알고 코드를 짜야하기 때문에 필연적으로 client, server간 의존성이 증가한다. 계층간 함수명 등이 그대로 노출되는 구조라서 서비스 내부 시스템, 디자인이 그대로 노출된다. 네트워크를 통한 자료교환을 포함하기 때문에 Local에서의 일반적인 method call 보다는 더 많은 시간을 소모한다.Skeleton, Stub: 서로 다른 주소공간을 사용하는 일종의 통신이므로 skeleton, stub을 통해 매개변수를 변환해주어야 한다.Stub 클라이언트 보조객체 클라이언트는 stub의 method를 불러내면 stub이 대신하여 원격 개체의 method 수행 marshalling하여 원격 서버로 전달하고 결과를 기다림 원격으로부터 결과를 받으면 unmarshalling하여 클라이언트에게 되돌려줌. client가 스텁의 method를 호출하면 호출된 method명과 매개변수로 전달된 값들이 stream 형태로 skeleton에 전달Skeleton 서버 보조객체 marshalling된 파라미터를 unmarshaling해 실제 개체에 전달하고 호출 대상 메소드를 불러냄 이후 메소드로부터 받은 결과를 skeleton에서 marshalling 해 전달 스텁으로부터 Stream을 받으면 이를 분석해 어떤 메소드가 요청되었는지 파악, 서버에 있는 객체의 비즈니스 메소드 호출Reference)https://velog.io/@bmh8993/REST%EC%99%80-RPCgRPC%EA%B0%80-%EB%93%B1%EC%9E%A5%ED%95%98%EA%B8%B0%EA%B9%8C%EC%A7%80https://mindock.github.io/network/rest-rpc/https://www.slideshare.net/WonchangSong1/rpc-restsimpleintrohttps://vascocenter.tistory.com/entry/%EB%B6%84%EC%82%B0%EA%B0%9C%EC%B2%B4-%EC%95%A0%ED%94%8C%EB%A6%AC%EC%BC%80%EC%9D%B4%EC%85%98%EC%97%90%EC%84%9C%EC%9D%98-%EC%8A%A4%ED%85%81stub-%EC%8A%A4%EC%BC%88%EB%A0%88%ED%86%A4Skeleton" }, { "title": "RabbitMQ를 이용한 RPC 통신", "url": "/posts/RabbitMQ%EB%A5%BC_%EC%9D%B4%EC%9A%A9%ED%95%9C_RPC_%ED%86%B5%EC%8B%A0/", "categories": "Study, RabbitMQ", "tags": "rabbitmq, message queue, rpc", "date": "2020-12-06 00:00:00 +0900", "snippet": " 서버 투 서버에서의 queue 역할인 RPC가 죽는 경우를 고려해 에러 처리를 잘해야 한다. 아래의 작업들은 모두 RabbitTemplate을 통해 자동으로 동작한다.과정 Configuration이 새로운 DirectExchange 와 client set up client는 convertSendAndReceive 메서드를 통해 exchange name, routing Key, message를 queue(rpc_queue)로 보낸다. RPC worker(server)는 request를 기다리다가 queue에서 request가 오면 작업을 수행하고, queue를 통해 결과 message를 reply_to에 명시되어있는 client에게 보낸다. client는 callback queue를 기다리다가 message가 오면 correlationId 를 체크한다. request에서의 value와 일치한다면 application으로 response를 return한다.Reference)https://www.rabbitmq.com/tutorials/tutorial-six-javascript.html" }, { "title": "Kotlin &amp; RabbitMQ를 이용한 RPC 통신 서버 개발 기록", "url": "/posts/RabbitMQ_Kotlin_RPC%EC%84%9C%EB%B2%84_%EA%B5%AC%EC%B6%95/", "categories": "Study, RabbitMQ", "tags": "rabbitmq, message queue, kotlin", "date": "2020-12-04 00:00:00 +0900", "snippet": "201204Kotlin Kotlin 가변인수 활용을 위해 vararg 적절히 이용 Kotlin에서의 JSON: receiver 입장에선 JSON의 구조를 모른다. put을 사용했지만, 별도 객체를 구성하는 것이 좋다.RabbitMQ 핵심 연결 역할: convertSendAndReceive() JSON으로 전달 안된다. 나중에 다시 확인할 필요가 있어보인다. sendAndReceive는 message로 자동 convert 지원하지 않는다. Kotlin -&amp;gt; JSON 쉽게 변환하는 방법 &quot;&quot;&quot; &quot;&quot;&quot; 이용 가변인자로 받은 경우 각각 parsing시 as Int, as String 등 명시 RabbitTemplatevs AsyncRabbitTemplate 차이점 비교201207 AsyncRabbit, Rabbit 차이 비교 Queue name 설정하면 bind 안되는이유는?좋은 예제 https://reflectoring.io/amqp-request-response/https://cheese10yun.github.io/spring-rabbitmq/https://devahea.github.io/2019/04/30/AMQ-%EB%AA%A8%EB%8D%B8%EA%B3%BC-Exchange-Queue-Binding-%EC%97%90-%EB%8C%80%ED%95%B4/201210 연구 끝. Service &amp;lt;-&amp;gt; MQ(broker) JSON MQ(broker)-&amp;gt; Agent(receiver) String Agent가 parsing 후 처리 convertSendAndReceive() JSON 전달 불가 JSONObject().toString() 전달 Unit test에 Coroutine 사용해야 완전한 비동기 테스트### RabbitTemplate vs AsyncRabbitTemplateTest 1 ) RabbitTemplateTest 2) AsyncRabbitTemplateReference)https://reflectoring.io/amqp-request-response/https://cheese10yun.github.io/spring-rabbitmq/https://devahea.github.io/2019/04/30/AMQ-%EB%AA%A8%EB%8D%B8%EA%B3%BC-Exchange-Queue-Binding-%EC%97%90-%EB%8C%80%ED%95%B4/" }, { "title": "RabbitMQ란?", "url": "/posts/RabbitMQ%EB%9E%80/", "categories": "Study, RabbitMQ", "tags": "rabbitmq, message queue", "date": "2020-11-29 00:00:00 +0900", "snippet": ": 오픈소스 메시지 브로커이다. 가볍고 쉬우며 다양한 messaging protocol을 지원한다.특징 Async messaging을 지원한다. Docker 환경에 적합. 설정을 통해 많은 컨트롤 가능 높은 성숙도(기능이 많다), 처리율 높은 편 Auth 매커니즘 지원. (TLS, LDAP)주요 개념Producer 메시지 생성, 발송하는 역할 메시지가 Queue에 저장되고, Producer는 Exchange를 통해 Queue에 접근.Consumer 메시지 수신하는 역할 Queue에서 직접 가져옴.Queue Producer에 의해 발송된 메시지가 저장되는 곳 미들웨어 역할 Server 종료시 queue 리셋 (유지하려면 Durable = true / PERSISTENT_TEXT_PLAIN옵션 설정)Exchange Queue에 종류가 있기 때문에 여기서 적절한 Queue로 메시지 전달(Routing) Router 역할.Exchange 종류 Direct: Routing key를 통해 보냄. 하나의 큐에 여러 routing key 가능. (유니캐스트) Topic: Routing pattern이 일치하는 곳에. (멀티캐스트) Headers: Topic과 비슷. header를 쓴다. (멀티캐스트) Fanout: Exchange에 등록된 모든 Queue에 전송. (브로드캐스트)Binding Exchange에게 메시지를 routing 할 규칙 지정.Reference)https://www.rabbitmq.com/tutorials/amqp-concepts.html#exchangeshttps://blog.dudaji.com/general/2020/05/25/rabbitmq.html" } ]
